log_500_740.xes normal
21/08/28 12:27:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/28 12:27:15 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 12:27:15 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/28 12:27:16 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 12:27:16 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 12:27:36 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 12:30:05 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 12:30:05 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 12:30:05 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 12:31:32 INFO TableWriter: Wrote 24205 rows to sequencedetection.log_500_740_idx in 86.670 s.
21/08/28 12:31:37 INFO TableWriter: Wrote 24227 rows to sequencedetection.log_500_740_idx in 92.006 s.
21/08/28 12:31:37 INFO TableWriter: Wrote 24228 rows to sequencedetection.log_500_740_idx in 92.343 s.
21/08/28 12:31:38 INFO TableWriter: Wrote 24456 rows to sequencedetection.log_500_740_idx in 92.838 s.
21/08/28 12:31:38 INFO TableWriter: Wrote 24306 rows to sequencedetection.log_500_740_idx in 93.081 s.
21/08/28 12:31:38 INFO TableWriter: Wrote 24320 rows to sequencedetection.log_500_740_idx in 93.102 s.
21/08/28 12:31:38 INFO TableWriter: Wrote 24446 rows to sequencedetection.log_500_740_idx in 93.105 s.
21/08/28 12:31:38 INFO TableWriter: Wrote 24304 rows to sequencedetection.log_500_740_idx in 93.146 s.
21/08/28 12:31:38 INFO TableWriter: Wrote 24216 rows to sequencedetection.log_500_740_idx in 93.332 s.
21/08/28 12:31:38 INFO TableWriter: Wrote 24137 rows to sequencedetection.log_500_740_idx in 93.413 s.
21/08/28 12:31:38 INFO TableWriter: Wrote 24267 rows to sequencedetection.log_500_740_idx in 93.488 s.
21/08/28 12:31:39 INFO TableWriter: Wrote 24372 rows to sequencedetection.log_500_740_idx in 93.531 s.
21/08/28 12:31:39 INFO TableWriter: Wrote 24350 rows to sequencedetection.log_500_740_idx in 93.696 s.
21/08/28 12:31:39 INFO TableWriter: Wrote 24345 rows to sequencedetection.log_500_740_idx in 93.715 s.
21/08/28 12:31:39 INFO TableWriter: Wrote 24620 rows to sequencedetection.log_500_740_idx in 93.720 s.
21/08/28 12:31:39 INFO TableWriter: Wrote 24688 rows to sequencedetection.log_500_740_idx in 93.953 s.
21/08/28 12:31:48 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 12:32:58 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 12:32:58 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 12:32:58 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 12:32:59 INFO TableWriter: Wrote 43 rows to sequencedetection.log_500_740_count in 0.920 s.
21/08/28 12:32:59 INFO TableWriter: Wrote 43 rows to sequencedetection.log_500_740_count in 1.092 s.
21/08/28 12:32:59 INFO TableWriter: Wrote 44 rows to sequencedetection.log_500_740_count in 1.093 s.
21/08/28 12:32:59 INFO TableWriter: Wrote 42 rows to sequencedetection.log_500_740_count in 1.092 s.
21/08/28 12:32:59 INFO TableWriter: Wrote 50 rows to sequencedetection.log_500_740_count in 1.254 s.
21/08/28 12:32:59 INFO TableWriter: Wrote 45 rows to sequencedetection.log_500_740_count in 1.265 s.
21/08/28 12:32:59 INFO TableWriter: Wrote 46 rows to sequencedetection.log_500_740_count in 1.275 s.
21/08/28 12:32:59 INFO TableWriter: Wrote 47 rows to sequencedetection.log_500_740_count in 1.294 s.
21/08/28 12:32:59 INFO TableWriter: Wrote 45 rows to sequencedetection.log_500_740_count in 1.308 s.
21/08/28 12:32:59 INFO TableWriter: Wrote 45 rows to sequencedetection.log_500_740_count in 1.316 s.
21/08/28 12:32:59 INFO TableWriter: Wrote 47 rows to sequencedetection.log_500_740_count in 1.334 s.
21/08/28 12:32:59 INFO TableWriter: Wrote 48 rows to sequencedetection.log_500_740_count in 1.338 s.
21/08/28 12:32:59 INFO TableWriter: Wrote 45 rows to sequencedetection.log_500_740_count in 1.341 s.
21/08/28 12:32:59 INFO TableWriter: Wrote 50 rows to sequencedetection.log_500_740_count in 1.347 s.
21/08/28 12:32:59 INFO TableWriter: Wrote 50 rows to sequencedetection.log_500_740_count in 1.353 s.
21/08/28 12:32:59 INFO TableWriter: Wrote 49 rows to sequencedetection.log_500_740_count in 1.373 s.
21/08/28 12:33:00 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_740_seq in 0.247 s.
21/08/28 12:33:00 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_740_seq in 0.269 s.
21/08/28 12:33:00 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_740_seq in 0.270 s.
21/08/28 12:33:00 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_740_seq in 0.278 s.
21/08/28 12:33:00 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_740_seq in 0.278 s.
21/08/28 12:33:00 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_740_seq in 0.285 s.
21/08/28 12:33:00 INFO TableWriter: Wrote 30 rows to sequencedetection.log_500_740_seq in 0.299 s.
21/08/28 12:33:00 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_740_seq in 0.299 s.
21/08/28 12:33:00 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_740_seq in 0.302 s.
21/08/28 12:33:00 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_740_seq in 0.308 s.
21/08/28 12:33:00 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_740_seq in 0.342 s.
21/08/28 12:33:00 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_740_seq in 0.343 s.
21/08/28 12:33:00 INFO TableWriter: Wrote 30 rows to sequencedetection.log_500_740_seq in 0.342 s.
21/08/28 12:33:00 INFO TableWriter: Wrote 28 rows to sequencedetection.log_500_740_seq in 0.345 s.
21/08/28 12:33:00 INFO TableWriter: Wrote 40 rows to sequencedetection.log_500_740_seq in 0.347 s.
21/08/28 12:33:00 INFO TableWriter: Wrote 30 rows to sequencedetection.log_500_740_seq in 0.359 s.
21/08/28 12:33:07 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 12:33:08 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_10000_346.xes normal
21/08/28 12:33:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/28 12:33:13 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 12:33:13 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/28 12:33:14 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 12:33:14 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 12:33:22 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 12:33:40 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 12:33:40 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 12:33:40 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 12:33:52 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 12:33:54 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 12:33:54 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 12:33:54 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 12:34:01 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 12:44:44 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 12:44:44 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 12:44:44 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 12:48:14 ERROR Executor: Exception in task 14.0 in stage 5.0 (TID 138)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/28 12:48:14 ERROR Executor: Exception in task 12.0 in stage 5.0 (TID 136)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/28 12:48:14 ERROR Executor: Exception in task 15.0 in stage 5.0 (TID 139)
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.io.ObjectStreamClass.newInstance(ObjectStreamClass.java:1102)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2171)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)
	at sun.reflect.GeneratedMethodAccessor46.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:158)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:188)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:185)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:156)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
21/08/28 12:48:14 ERROR Executor: Exception in task 5.0 in stage 5.0 (TID 129)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/28 12:48:16 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 136,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/28 12:48:16 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 139,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.io.ObjectStreamClass.newInstance(ObjectStreamClass.java:1102)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2171)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)
	at sun.reflect.GeneratedMethodAccessor46.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:158)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:188)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:185)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:156)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
21/08/28 12:48:16 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 129,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/28 12:48:16 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 138,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/28 12:48:16 ERROR TaskSetManager: Task 15 in stage 5.0 failed 1 times; aborting job
21/08/28 12:48:16 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
Exception in thread "main" java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
auth.datalab.sequenceDetection.CassandraConnectionTrait$class.startSpark(CassandraConnectionTrait.scala:54)
auth.datalab.sequenceDetection.CassandraConnection.startSpark(CassandraConnection.scala:19)
auth.datalab.sequenceDetection.SequenceDetection$.main(SequenceDetection.scala:44)
auth.datalab.sequenceDetection.Main$.main(Main.scala:7)
auth.datalab.sequenceDetection.Main.main(Main.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

The currently active SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
auth.datalab.sequenceDetection.CassandraConnectionTrait$class.startSpark(CassandraConnectionTrait.scala:54)
auth.datalab.sequenceDetection.CassandraConnection.startSpark(CassandraConnection.scala:19)
auth.datalab.sequenceDetection.SequenceDetection$.main(SequenceDetection.scala:44)
auth.datalab.sequenceDetection.Main$.main(Main.scala:7)
auth.datalab.sequenceDetection.Main.main(Main.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
         
	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:100)
	at org.apache.spark.sql.SparkSession.<init>(SparkSession.scala:91)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:957)
	at auth.datalab.sequenceDetection.CassandraConnectionTrait$class.closeSpark(CassandraConnectionTrait.scala:74)
	at auth.datalab.sequenceDetection.CassandraConnection.closeSpark(CassandraConnection.scala:19)
	at auth.datalab.sequenceDetection.SequenceDetection$.main(SequenceDetection.scala:92)
	at auth.datalab.sequenceDetection.Main$.main(Main.scala:7)
	at auth.datalab.sequenceDetection.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
21/08/28 12:48:16 ERROR TaskSchedulerImpl: Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$4@653a17e rejected from java.util.concurrent.ThreadPoolExecutor@4f6cad12[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 134]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueFailedTask(TaskResultGetter.scala:131)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:560)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:539)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/08/28 12:48:16 ERROR TaskSchedulerImpl: Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$4@8b73170 rejected from java.util.concurrent.ThreadPoolExecutor@4f6cad12[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 134]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueFailedTask(TaskResultGetter.scala:131)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:560)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:539)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
log_1000_740.xes normal
21/08/28 12:48:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/28 12:48:23 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 12:48:23 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/28 12:48:23 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 12:48:23 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 12:48:31 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 12:48:31 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 12:48:31 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 12:48:32 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 12:48:45 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 12:54:14 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 12:54:14 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 12:54:14 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 12:58:53 INFO TableWriter: Wrote 24952 rows to sequencedetection.log_1000_740_idx in 279.404 s.
21/08/28 12:58:55 INFO TableWriter: Wrote 24597 rows to sequencedetection.log_1000_740_idx in 281.435 s.
21/08/28 12:58:55 INFO TableWriter: Wrote 24670 rows to sequencedetection.log_1000_740_idx in 281.449 s.
21/08/28 12:58:57 INFO TableWriter: Wrote 24573 rows to sequencedetection.log_1000_740_idx in 282.830 s.
21/08/28 12:58:57 INFO TableWriter: Wrote 24856 rows to sequencedetection.log_1000_740_idx in 283.390 s.
21/08/28 12:58:57 INFO TableWriter: Wrote 24805 rows to sequencedetection.log_1000_740_idx in 283.461 s.
21/08/28 12:58:57 INFO TableWriter: Wrote 24696 rows to sequencedetection.log_1000_740_idx in 283.540 s.
21/08/28 12:58:58 INFO TableWriter: Wrote 24585 rows to sequencedetection.log_1000_740_idx in 283.937 s.
21/08/28 12:58:58 INFO TableWriter: Wrote 24666 rows to sequencedetection.log_1000_740_idx in 283.951 s.
21/08/28 12:58:58 INFO TableWriter: Wrote 24586 rows to sequencedetection.log_1000_740_idx in 283.993 s.
21/08/28 12:58:58 INFO TableWriter: Wrote 24552 rows to sequencedetection.log_1000_740_idx in 284.171 s.
21/08/28 12:58:58 INFO TableWriter: Wrote 24702 rows to sequencedetection.log_1000_740_idx in 284.189 s.
21/08/28 12:58:58 INFO TableWriter: Wrote 24713 rows to sequencedetection.log_1000_740_idx in 284.241 s.
21/08/28 12:58:58 INFO TableWriter: Wrote 24703 rows to sequencedetection.log_1000_740_idx in 284.511 s.
21/08/28 12:58:58 INFO TableWriter: Wrote 25062 rows to sequencedetection.log_1000_740_idx in 284.603 s.
21/08/28 12:58:58 INFO TableWriter: Wrote 24503 rows to sequencedetection.log_1000_740_idx in 284.708 s.
21/08/28 12:59:07 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 13:02:17 ERROR Executor: Exception in task 9.0 in stage 8.0 (TID 149)
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at sun.reflect.ByteVectorImpl.resize(ByteVectorImpl.java:84)
	at sun.reflect.ByteVectorImpl.add(ByteVectorImpl.java:63)
	at sun.reflect.ClassFileAssembler.emitByte(ClassFileAssembler.java:74)
	at sun.reflect.ClassFileAssembler.emitConstantPoolUTF8(ClassFileAssembler.java:107)
	at sun.reflect.AccessorGenerator.emitCommonConstantPoolEntries(AccessorGenerator.java:144)
	at sun.reflect.MethodAccessorGenerator.generate(MethodAccessorGenerator.java:349)
	at sun.reflect.MethodAccessorGenerator.generateMethod(MethodAccessorGenerator.java:75)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:53)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeWriteReplace(ObjectStreamClass.java:1244)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1136)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at scala.collection.immutable.List$SerializationProxy.writeObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor96.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:1154)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
21/08/28 13:02:23 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 149,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at sun.reflect.ByteVectorImpl.resize(ByteVectorImpl.java:84)
	at sun.reflect.ByteVectorImpl.add(ByteVectorImpl.java:63)
	at sun.reflect.ClassFileAssembler.emitByte(ClassFileAssembler.java:74)
	at sun.reflect.ClassFileAssembler.emitConstantPoolUTF8(ClassFileAssembler.java:107)
	at sun.reflect.AccessorGenerator.emitCommonConstantPoolEntries(AccessorGenerator.java:144)
	at sun.reflect.MethodAccessorGenerator.generate(MethodAccessorGenerator.java:349)
	at sun.reflect.MethodAccessorGenerator.generateMethod(MethodAccessorGenerator.java:75)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:53)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeWriteReplace(ObjectStreamClass.java:1244)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1136)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at scala.collection.immutable.List$SerializationProxy.writeObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor96.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:1154)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
21/08/28 13:02:36 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
21/08/28 13:02:58 ERROR Executor: Exception in task 4.0 in stage 8.0 (TID 144)
java.lang.NullPointerException
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2309)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:158)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:188)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:185)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:156)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:191)
	at org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/08/28 13:03:03 ERROR TaskSetManager: Task 9 in stage 8.0 failed 1 times; aborting job
Exception in thread "main" java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
auth.datalab.sequenceDetection.CassandraConnectionTrait$class.startSpark(CassandraConnectionTrait.scala:54)
auth.datalab.sequenceDetection.CassandraConnection.startSpark(CassandraConnection.scala:19)
auth.datalab.sequenceDetection.SequenceDetection$.main(SequenceDetection.scala:44)
auth.datalab.sequenceDetection.Main$.main(Main.scala:7)
auth.datalab.sequenceDetection.Main.main(Main.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

The currently active SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
auth.datalab.sequenceDetection.CassandraConnectionTrait$class.startSpark(CassandraConnectionTrait.scala:54)
auth.datalab.sequenceDetection.CassandraConnection.startSpark(CassandraConnection.scala:19)
auth.datalab.sequenceDetection.SequenceDetection$.main(SequenceDetection.scala:44)
auth.datalab.sequenceDetection.Main$.main(Main.scala:7)
auth.datalab.sequenceDetection.Main.main(Main.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
         
	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:100)
	at org.apache.spark.sql.SparkSession.<init>(SparkSession.scala:91)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:957)
	at auth.datalab.sequenceDetection.CassandraConnectionTrait$class.closeSpark(CassandraConnectionTrait.scala:74)
	at auth.datalab.sequenceDetection.CassandraConnection.closeSpark(CassandraConnection.scala:19)
	at auth.datalab.sequenceDetection.SequenceDetection$.main(SequenceDetection.scala:92)
	at auth.datalab.sequenceDetection.Main$.main(Main.scala:7)
	at auth.datalab.sequenceDetection.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
log_100000_346.xes normal
21/08/28 13:03:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/28 13:03:19 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 13:03:19 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/28 13:03:20 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 13:03:20 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 13:03:28 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 13:15:30 ERROR TaskSchedulerImpl: Lost an executor driver (already removed): Executor heartbeat timed out after 241546 ms
Exception in thread "spark-listener-group-appStatus" Exception in thread "main" java.lang.OutOfMemoryError: Java heap space
java.lang.OutOfMemoryError: Java heap space
	at java.util.Calendar$Builder.build(Calendar.java:1482)
	at sun.util.locale.provider.CalendarProviderImpl.getInstance(CalendarProviderImpl.java:88)
	at java.util.Calendar.createCalendar(Calendar.java:1666)
	at java.util.Calendar.getInstance(Calendar.java:1613)
	at org.deckfour.xes.util.XsDateTimeConversion.parseXsDateTime(XsDateTimeConversion.java:95)
	at org.deckfour.xes.util.XsDateTimeConversionJava7.parseXsDateTime(XsDateTimeConversionJava7.java:85)
	at org.deckfour.xes.in.XesXmlParser$XesXmlHandler.startElement(XesXmlParser.java:292)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at javax.xml.parsers.SAXParser.parse(SAXParser.java:195)
	at org.deckfour.xes.in.XesXmlParser.parse(XesXmlParser.java:175)
	at auth.datalab.sequenceDetection.Utils$.readFromXes(Utils.scala:62)
	at auth.datalab.sequenceDetection.Utils$.readLog(Utils.scala:35)
	at auth.datalab.sequenceDetection.SequenceDetection$$anonfun$main$1.apply(SequenceDetection.scala:59)
	at auth.datalab.sequenceDetection.SequenceDetection$$anonfun$main$1.apply(SequenceDetection.scala:58)
	at org.apache.spark.sql.SparkSession.time(SparkSession.scala:677)
	at auth.datalab.sequenceDetection.SequenceDetection$.main(SequenceDetection.scala:58)
	at auth.datalab.sequenceDetection.Main$.main(Main.scala:7)
	at auth.datalab.sequenceDetection.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
21/08/28 22:15:22 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_1000_346.xes normal
21/08/28 22:15:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/28 22:15:32 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:15:32 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/28 22:15:32 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:15:32 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:15:51 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:16:48 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:16:48 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:16:48 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:17:25 INFO TableWriter: Wrote 4248 rows to sequencedetection.log_1000_346_idx in 36.202 s.
21/08/28 22:17:25 INFO TableWriter: Wrote 4235 rows to sequencedetection.log_1000_346_idx in 36.217 s.
21/08/28 22:17:25 INFO TableWriter: Wrote 4276 rows to sequencedetection.log_1000_346_idx in 36.233 s.
21/08/28 22:17:25 INFO TableWriter: Wrote 4314 rows to sequencedetection.log_1000_346_idx in 36.324 s.
21/08/28 22:17:25 INFO TableWriter: Wrote 4281 rows to sequencedetection.log_1000_346_idx in 36.336 s.
21/08/28 22:17:25 INFO TableWriter: Wrote 4303 rows to sequencedetection.log_1000_346_idx in 36.352 s.
21/08/28 22:17:25 INFO TableWriter: Wrote 4326 rows to sequencedetection.log_1000_346_idx in 36.373 s.
21/08/28 22:17:25 INFO TableWriter: Wrote 4350 rows to sequencedetection.log_1000_346_idx in 36.379 s.
21/08/28 22:17:25 INFO TableWriter: Wrote 4432 rows to sequencedetection.log_1000_346_idx in 36.394 s.
21/08/28 22:17:25 INFO TableWriter: Wrote 4433 rows to sequencedetection.log_1000_346_idx in 36.411 s.
21/08/28 22:17:25 INFO TableWriter: Wrote 4395 rows to sequencedetection.log_1000_346_idx in 36.435 s.
21/08/28 22:17:25 INFO TableWriter: Wrote 4435 rows to sequencedetection.log_1000_346_idx in 36.459 s.
21/08/28 22:17:26 INFO TableWriter: Wrote 4287 rows to sequencedetection.log_1000_346_idx in 37.257 s.
21/08/28 22:17:26 INFO TableWriter: Wrote 4308 rows to sequencedetection.log_1000_346_idx in 37.542 s.
21/08/28 22:17:26 INFO TableWriter: Wrote 4410 rows to sequencedetection.log_1000_346_idx in 37.581 s.
21/08/28 22:17:26 INFO TableWriter: Wrote 4399 rows to sequencedetection.log_1000_346_idx in 37.609 s.
21/08/28 22:17:43 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:18:17 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:18:17 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:18:17 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:18:18 INFO TableWriter: Wrote 21 rows to sequencedetection.log_1000_346_count in 0.235 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 20 rows to sequencedetection.log_1000_346_count in 0.238 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 22 rows to sequencedetection.log_1000_346_count in 0.251 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 21 rows to sequencedetection.log_1000_346_count in 0.252 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 23 rows to sequencedetection.log_1000_346_count in 0.253 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 23 rows to sequencedetection.log_1000_346_count in 0.254 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 21 rows to sequencedetection.log_1000_346_count in 0.255 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 24 rows to sequencedetection.log_1000_346_count in 0.256 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 21 rows to sequencedetection.log_1000_346_count in 0.260 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 20 rows to sequencedetection.log_1000_346_count in 0.259 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 22 rows to sequencedetection.log_1000_346_count in 0.282 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 21 rows to sequencedetection.log_1000_346_count in 0.287 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 21 rows to sequencedetection.log_1000_346_count in 0.302 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 21 rows to sequencedetection.log_1000_346_count in 0.301 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 23 rows to sequencedetection.log_1000_346_count in 0.312 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 21 rows to sequencedetection.log_1000_346_count in 0.321 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_346_seq in 0.305 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_346_seq in 0.315 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_346_seq in 0.315 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_346_seq in 0.325 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_346_seq in 0.344 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_346_seq in 0.342 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_346_seq in 0.342 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_346_seq in 0.353 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_346_seq in 0.356 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 55 rows to sequencedetection.log_1000_346_seq in 0.358 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 72 rows to sequencedetection.log_1000_346_seq in 0.362 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 72 rows to sequencedetection.log_1000_346_seq in 0.369 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 76 rows to sequencedetection.log_1000_346_seq in 0.372 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 76 rows to sequencedetection.log_1000_346_seq in 0.376 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 76 rows to sequencedetection.log_1000_346_seq in 0.409 s.
21/08/28 22:18:18 INFO TableWriter: Wrote 72 rows to sequencedetection.log_1000_346_seq in 0.424 s.
21/08/28 22:18:26 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:18:27 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100_740.xes normal
21/08/28 22:18:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/28 22:18:32 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:18:32 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/28 22:18:32 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:18:32 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:18:48 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:19:19 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:19:19 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:19:19 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:19:35 INFO TableWriter: Wrote 21532 rows to sequencedetection.log_100_740_idx in 15.685 s.
21/08/28 22:19:35 INFO TableWriter: Wrote 21490 rows to sequencedetection.log_100_740_idx in 15.705 s.
21/08/28 22:19:35 INFO TableWriter: Wrote 21474 rows to sequencedetection.log_100_740_idx in 15.710 s.
21/08/28 22:19:35 INFO TableWriter: Wrote 21470 rows to sequencedetection.log_100_740_idx in 15.713 s.
21/08/28 22:19:35 INFO TableWriter: Wrote 21592 rows to sequencedetection.log_100_740_idx in 15.719 s.
21/08/28 22:19:35 INFO TableWriter: Wrote 21464 rows to sequencedetection.log_100_740_idx in 15.720 s.
21/08/28 22:19:35 INFO TableWriter: Wrote 21579 rows to sequencedetection.log_100_740_idx in 15.724 s.
21/08/28 22:19:35 INFO TableWriter: Wrote 21615 rows to sequencedetection.log_100_740_idx in 15.729 s.
21/08/28 22:19:35 INFO TableWriter: Wrote 21570 rows to sequencedetection.log_100_740_idx in 15.743 s.
21/08/28 22:19:35 INFO TableWriter: Wrote 21506 rows to sequencedetection.log_100_740_idx in 15.743 s.
21/08/28 22:19:35 INFO TableWriter: Wrote 21519 rows to sequencedetection.log_100_740_idx in 15.768 s.
21/08/28 22:19:35 INFO TableWriter: Wrote 21775 rows to sequencedetection.log_100_740_idx in 15.789 s.
21/08/28 22:19:35 INFO TableWriter: Wrote 21679 rows to sequencedetection.log_100_740_idx in 15.794 s.
21/08/28 22:19:35 INFO TableWriter: Wrote 21796 rows to sequencedetection.log_100_740_idx in 15.796 s.
21/08/28 22:19:35 INFO TableWriter: Wrote 21677 rows to sequencedetection.log_100_740_idx in 15.798 s.
21/08/28 22:19:35 INFO TableWriter: Wrote 21962 rows to sequencedetection.log_100_740_idx in 15.816 s.
21/08/28 22:19:41 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:19:41 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:19:41 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:19:42 INFO TableWriter: Wrote 43 rows to sequencedetection.log_100_740_count in 0.800 s.
21/08/28 22:19:42 INFO TableWriter: Wrote 44 rows to sequencedetection.log_100_740_count in 0.919 s.
21/08/28 22:19:42 INFO TableWriter: Wrote 40 rows to sequencedetection.log_100_740_count in 0.943 s.
21/08/28 22:19:42 INFO TableWriter: Wrote 43 rows to sequencedetection.log_100_740_count in 0.943 s.
21/08/28 22:19:42 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:19:42 INFO TableWriter: Wrote 47 rows to sequencedetection.log_100_740_count in 1.242 s.
21/08/28 22:19:42 INFO TableWriter: Wrote 49 rows to sequencedetection.log_100_740_count in 1.274 s.
21/08/28 22:19:42 INFO TableWriter: Wrote 45 rows to sequencedetection.log_100_740_count in 1.272 s.
21/08/28 22:19:42 INFO TableWriter: Wrote 47 rows to sequencedetection.log_100_740_count in 1.273 s.
21/08/28 22:19:42 INFO TableWriter: Wrote 45 rows to sequencedetection.log_100_740_count in 1.276 s.
21/08/28 22:19:42 INFO TableWriter: Wrote 49 rows to sequencedetection.log_100_740_count in 1.276 s.
21/08/28 22:19:42 INFO TableWriter: Wrote 50 rows to sequencedetection.log_100_740_count in 1.278 s.
21/08/28 22:19:42 INFO TableWriter: Wrote 50 rows to sequencedetection.log_100_740_count in 1.280 s.
21/08/28 22:19:42 INFO TableWriter: Wrote 46 rows to sequencedetection.log_100_740_count in 1.280 s.
21/08/28 22:19:42 INFO TableWriter: Wrote 45 rows to sequencedetection.log_100_740_count in 1.282 s.
21/08/28 22:19:42 INFO TableWriter: Wrote 48 rows to sequencedetection.log_100_740_count in 1.289 s.
21/08/28 22:19:42 INFO TableWriter: Wrote 45 rows to sequencedetection.log_100_740_count in 1.292 s.
21/08/28 22:19:43 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_seq in 0.069 s.
21/08/28 22:19:43 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_seq in 0.071 s.
21/08/28 22:19:43 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_seq in 0.073 s.
21/08/28 22:19:43 INFO TableWriter: Wrote 3 rows to sequencedetection.log_100_740_seq in 0.073 s.
21/08/28 22:19:43 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_seq in 0.076 s.
21/08/28 22:19:43 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_740_seq in 0.076 s.
21/08/28 22:19:43 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_seq in 0.082 s.
21/08/28 22:19:43 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_seq in 0.084 s.
21/08/28 22:19:43 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_seq in 0.086 s.
21/08/28 22:19:43 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_seq in 0.086 s.
21/08/28 22:19:43 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_740_seq in 0.085 s.
21/08/28 22:19:43 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_740_seq in 0.093 s.
21/08/28 22:19:43 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_740_seq in 0.096 s.
21/08/28 22:19:43 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_seq in 0.095 s.
21/08/28 22:19:43 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_seq in 0.099 s.
21/08/28 22:19:43 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_740_seq in 0.104 s.
21/08/28 22:19:50 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:19:51 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_500_346.xes normal
21/08/28 22:19:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/28 22:19:56 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:19:56 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/28 22:19:57 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:19:57 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:20:14 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:20:41 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:20:41 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:20:41 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:20:51 INFO TableWriter: Wrote 4281 rows to sequencedetection.log_500_346_idx in 9.710 s.
21/08/28 22:20:51 INFO TableWriter: Wrote 4327 rows to sequencedetection.log_500_346_idx in 9.723 s.
21/08/28 22:20:51 INFO TableWriter: Wrote 4341 rows to sequencedetection.log_500_346_idx in 9.744 s.
21/08/28 22:20:51 INFO TableWriter: Wrote 4296 rows to sequencedetection.log_500_346_idx in 9.766 s.
21/08/28 22:20:51 INFO TableWriter: Wrote 4339 rows to sequencedetection.log_500_346_idx in 9.773 s.
21/08/28 22:20:51 INFO TableWriter: Wrote 4249 rows to sequencedetection.log_500_346_idx in 9.797 s.
21/08/28 22:20:51 INFO TableWriter: Wrote 4439 rows to sequencedetection.log_500_346_idx in 9.802 s.
21/08/28 22:20:51 INFO TableWriter: Wrote 4441 rows to sequencedetection.log_500_346_idx in 9.810 s.
21/08/28 22:20:51 INFO TableWriter: Wrote 4378 rows to sequencedetection.log_500_346_idx in 9.826 s.
21/08/28 22:20:51 INFO TableWriter: Wrote 4310 rows to sequencedetection.log_500_346_idx in 9.828 s.
21/08/28 22:20:51 INFO TableWriter: Wrote 4399 rows to sequencedetection.log_500_346_idx in 9.851 s.
21/08/28 22:20:51 INFO TableWriter: Wrote 4314 rows to sequencedetection.log_500_346_idx in 9.852 s.
21/08/28 22:20:51 INFO TableWriter: Wrote 4342 rows to sequencedetection.log_500_346_idx in 9.859 s.
21/08/28 22:20:51 INFO TableWriter: Wrote 4426 rows to sequencedetection.log_500_346_idx in 9.876 s.
21/08/28 22:20:51 INFO TableWriter: Wrote 4408 rows to sequencedetection.log_500_346_idx in 9.911 s.
21/08/28 22:20:51 INFO TableWriter: Wrote 4458 rows to sequencedetection.log_500_346_idx in 9.925 s.
21/08/28 22:20:56 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:20:56 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:20:56 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:20:57 INFO TableWriter: Wrote 21 rows to sequencedetection.log_500_346_count in 0.315 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 20 rows to sequencedetection.log_500_346_count in 0.324 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 21 rows to sequencedetection.log_500_346_count in 0.327 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 21 rows to sequencedetection.log_500_346_count in 0.334 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 21 rows to sequencedetection.log_500_346_count in 0.334 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 23 rows to sequencedetection.log_500_346_count in 0.334 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 20 rows to sequencedetection.log_500_346_count in 0.334 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 21 rows to sequencedetection.log_500_346_count in 0.331 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 23 rows to sequencedetection.log_500_346_count in 0.334 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 22 rows to sequencedetection.log_500_346_count in 0.335 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 21 rows to sequencedetection.log_500_346_count in 0.335 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 21 rows to sequencedetection.log_500_346_count in 0.337 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 24 rows to sequencedetection.log_500_346_count in 0.339 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 22 rows to sequencedetection.log_500_346_count in 0.339 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 21 rows to sequencedetection.log_500_346_count in 0.339 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 23 rows to sequencedetection.log_500_346_count in 0.337 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_346_seq in 0.112 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_346_seq in 0.170 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 28 rows to sequencedetection.log_500_346_seq in 0.183 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_346_seq in 0.181 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 30 rows to sequencedetection.log_500_346_seq in 0.185 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_346_seq in 0.191 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_346_seq in 0.192 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 30 rows to sequencedetection.log_500_346_seq in 0.193 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_346_seq in 0.199 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 30 rows to sequencedetection.log_500_346_seq in 0.199 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 40 rows to sequencedetection.log_500_346_seq in 0.203 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_346_seq in 0.201 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_346_seq in 0.204 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_346_seq in 0.211 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_346_seq in 0.210 s.
21/08/28 22:20:57 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_346_seq in 0.211 s.
21/08/28 22:20:58 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:21:04 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:21:05 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100000_113.xes normal
21/08/28 22:21:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/28 22:21:11 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:21:11 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/28 22:21:11 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:21:11 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:21:19 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:21:53 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:21:53 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:21:53 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:22:06 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:22:06 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:22:06 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:22:06 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:22:14 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:27:50 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:27:50 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:27:50 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:31:08 INFO TableWriter: Wrote 360 rows to sequencedetection.log_100000_113_idx in 197.395 s.
21/08/28 22:31:15 INFO TableWriter: Wrote 296 rows to sequencedetection.log_100000_113_idx in 205.046 s.
21/08/28 22:31:27 INFO TableWriter: Wrote 314 rows to sequencedetection.log_100000_113_idx in 217.094 s.
21/08/28 22:31:36 INFO TableWriter: Wrote 326 rows to sequencedetection.log_100000_113_idx in 225.849 s.
21/08/28 22:31:50 INFO TableWriter: Wrote 311 rows to sequencedetection.log_100000_113_idx in 240.149 s.
21/08/28 22:31:54 INFO TableWriter: Wrote 353 rows to sequencedetection.log_100000_113_idx in 243.631 s.
21/08/28 22:32:17 INFO TableWriter: Wrote 334 rows to sequencedetection.log_100000_113_idx in 266.706 s.
21/08/28 22:32:22 INFO TableWriter: Wrote 337 rows to sequencedetection.log_100000_113_idx in 271.679 s.
21/08/28 22:32:23 INFO TableWriter: Wrote 302 rows to sequencedetection.log_100000_113_idx in 272.787 s.
21/08/28 22:32:25 INFO TableWriter: Wrote 329 rows to sequencedetection.log_100000_113_idx in 275.200 s.
21/08/28 22:32:30 INFO TableWriter: Wrote 327 rows to sequencedetection.log_100000_113_idx in 280.349 s.
21/08/28 22:32:31 INFO TableWriter: Wrote 298 rows to sequencedetection.log_100000_113_idx in 281.081 s.
21/08/28 22:32:42 INFO TableWriter: Wrote 321 rows to sequencedetection.log_100000_113_idx in 291.416 s.
21/08/28 22:32:42 INFO TableWriter: Wrote 345 rows to sequencedetection.log_100000_113_idx in 291.428 s.
21/08/28 22:32:42 INFO TableWriter: Wrote 321 rows to sequencedetection.log_100000_113_idx in 291.560 s.
21/08/28 22:32:48 INFO TableWriter: Wrote 349 rows to sequencedetection.log_100000_113_idx in 297.514 s.
21/08/28 22:32:55 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:37:14 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:37:14 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:37:14 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:37:15 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100000_113_count in 0.099 s.
21/08/28 22:37:15 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100000_113_count in 0.099 s.
21/08/28 22:37:15 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100000_113_count in 0.098 s.
21/08/28 22:37:15 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100000_113_count in 0.100 s.
21/08/28 22:37:15 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100000_113_count in 0.100 s.
21/08/28 22:37:15 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100000_113_count in 0.102 s.
21/08/28 22:37:15 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100000_113_count in 0.101 s.
21/08/28 22:37:15 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100000_113_count in 0.103 s.
21/08/28 22:37:15 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100000_113_count in 0.103 s.
21/08/28 22:37:15 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100000_113_count in 0.102 s.
21/08/28 22:37:15 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100000_113_count in 0.104 s.
21/08/28 22:37:15 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100000_113_count in 0.103 s.
21/08/28 22:37:15 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100000_113_count in 0.107 s.
21/08/28 22:37:15 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100000_113_count in 0.106 s.
21/08/28 22:37:15 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100000_113_count in 0.107 s.
21/08/28 22:37:15 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100000_113_count in 0.109 s.
21/08/28 22:37:22 INFO TableWriter: Wrote 5556 rows to sequencedetection.log_100000_113_seq in 7.776 s.
21/08/28 22:37:22 INFO TableWriter: Wrote 5556 rows to sequencedetection.log_100000_113_seq in 7.780 s.
21/08/28 22:37:22 INFO TableWriter: Wrote 5556 rows to sequencedetection.log_100000_113_seq in 7.781 s.
21/08/28 22:37:22 INFO TableWriter: Wrote 5556 rows to sequencedetection.log_100000_113_seq in 7.809 s.
21/08/28 22:37:22 INFO TableWriter: Wrote 5556 rows to sequencedetection.log_100000_113_seq in 7.810 s.
21/08/28 22:37:22 INFO TableWriter: Wrote 5556 rows to sequencedetection.log_100000_113_seq in 7.813 s.
21/08/28 22:37:22 INFO TableWriter: Wrote 5556 rows to sequencedetection.log_100000_113_seq in 7.815 s.
21/08/28 22:37:22 INFO TableWriter: Wrote 5556 rows to sequencedetection.log_100000_113_seq in 7.820 s.
21/08/28 22:37:23 INFO TableWriter: Wrote 5556 rows to sequencedetection.log_100000_113_seq in 7.982 s.
21/08/28 22:37:23 INFO TableWriter: Wrote 5553 rows to sequencedetection.log_100000_113_seq in 8.006 s.
21/08/28 22:37:25 INFO TableWriter: Wrote 7408 rows to sequencedetection.log_100000_113_seq in 9.946 s.
21/08/28 22:37:25 INFO TableWriter: Wrote 7404 rows to sequencedetection.log_100000_113_seq in 9.969 s.
21/08/28 22:37:25 INFO TableWriter: Wrote 7408 rows to sequencedetection.log_100000_113_seq in 10.047 s.
21/08/28 22:37:25 INFO TableWriter: Wrote 7407 rows to sequencedetection.log_100000_113_seq in 10.144 s.
21/08/28 22:37:25 INFO TableWriter: Wrote 7408 rows to sequencedetection.log_100000_113_seq in 10.172 s.
21/08/28 22:37:25 INFO TableWriter: Wrote 7408 rows to sequencedetection.log_100000_113_seq in 10.350 s.
21/08/28 22:37:32 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:37:33 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100_113.xes normal
21/08/28 22:37:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/28 22:37:39 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:37:39 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/28 22:37:39 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:37:39 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:37:52 INFO TableWriter: Wrote 254 rows to sequencedetection.log_100_113_idx in 0.926 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 262 rows to sequencedetection.log_100_113_idx in 0.926 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 260 rows to sequencedetection.log_100_113_idx in 0.946 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 280 rows to sequencedetection.log_100_113_idx in 0.952 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 256 rows to sequencedetection.log_100_113_idx in 0.953 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 280 rows to sequencedetection.log_100_113_idx in 0.957 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 277 rows to sequencedetection.log_100_113_idx in 0.965 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 279 rows to sequencedetection.log_100_113_idx in 0.969 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 290 rows to sequencedetection.log_100_113_idx in 0.973 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 304 rows to sequencedetection.log_100_113_idx in 0.979 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 289 rows to sequencedetection.log_100_113_idx in 0.981 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 303 rows to sequencedetection.log_100_113_idx in 0.981 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 293 rows to sequencedetection.log_100_113_idx in 0.982 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 295 rows to sequencedetection.log_100_113_idx in 0.982 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 311 rows to sequencedetection.log_100_113_idx in 0.984 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 318 rows to sequencedetection.log_100_113_idx in 0.985 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_113_count in 0.045 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_count in 0.050 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100_113_count in 0.049 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_113_count in 0.055 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_113_count in 0.057 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_113_count in 0.061 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100_113_count in 0.062 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_113_count in 0.072 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_113_count in 0.071 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_count in 0.071 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_113_count in 0.069 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100_113_count in 0.074 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100_113_count in 0.073 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_113_count in 0.078 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_113_count in 0.082 s.
21/08/28 22:37:52 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100_113_count in 0.081 s.
21/08/28 22:37:53 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_seq in 0.027 s.
21/08/28 22:37:53 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_seq in 0.022 s.
21/08/28 22:37:53 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_113_seq in 0.029 s.
21/08/28 22:37:53 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_seq in 0.028 s.
21/08/28 22:37:53 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_seq in 0.032 s.
21/08/28 22:37:53 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_seq in 0.034 s.
21/08/28 22:37:53 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_113_seq in 0.034 s.
21/08/28 22:37:53 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_seq in 0.037 s.
21/08/28 22:37:53 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_113_seq in 0.034 s.
21/08/28 22:37:53 INFO TableWriter: Wrote 3 rows to sequencedetection.log_100_113_seq in 0.038 s.
21/08/28 22:37:53 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_seq in 0.044 s.
21/08/28 22:37:53 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_113_seq in 0.046 s.
21/08/28 22:37:53 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_seq in 0.044 s.
21/08/28 22:37:53 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_113_seq in 0.046 s.
21/08/28 22:37:53 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_seq in 0.054 s.
21/08/28 22:37:53 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_seq in 0.061 s.
21/08/28 22:38:00 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:38:01 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_1000_113.xes normal
21/08/28 22:38:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/28 22:38:06 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:38:06 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/28 22:38:06 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:38:06 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:38:19 INFO TableWriter: Wrote 292 rows to sequencedetection.log_1000_113_idx in 1.492 s.
21/08/28 22:38:19 INFO TableWriter: Wrote 299 rows to sequencedetection.log_1000_113_idx in 1.516 s.
21/08/28 22:38:19 INFO TableWriter: Wrote 295 rows to sequencedetection.log_1000_113_idx in 1.517 s.
21/08/28 22:38:19 INFO TableWriter: Wrote 307 rows to sequencedetection.log_1000_113_idx in 1.530 s.
21/08/28 22:38:19 INFO TableWriter: Wrote 311 rows to sequencedetection.log_1000_113_idx in 1.535 s.
21/08/28 22:38:19 INFO TableWriter: Wrote 322 rows to sequencedetection.log_1000_113_idx in 1.553 s.
21/08/28 22:38:19 INFO TableWriter: Wrote 322 rows to sequencedetection.log_1000_113_idx in 1.557 s.
21/08/28 22:38:19 INFO TableWriter: Wrote 333 rows to sequencedetection.log_1000_113_idx in 1.559 s.
21/08/28 22:38:19 INFO TableWriter: Wrote 333 rows to sequencedetection.log_1000_113_idx in 1.563 s.
21/08/28 22:38:19 INFO TableWriter: Wrote 315 rows to sequencedetection.log_1000_113_idx in 1.567 s.
21/08/28 22:38:19 INFO TableWriter: Wrote 320 rows to sequencedetection.log_1000_113_idx in 1.567 s.
21/08/28 22:38:19 INFO TableWriter: Wrote 343 rows to sequencedetection.log_1000_113_idx in 1.571 s.
21/08/28 22:38:19 INFO TableWriter: Wrote 323 rows to sequencedetection.log_1000_113_idx in 1.572 s.
21/08/28 22:38:19 INFO TableWriter: Wrote 355 rows to sequencedetection.log_1000_113_idx in 1.572 s.
21/08/28 22:38:19 INFO TableWriter: Wrote 349 rows to sequencedetection.log_1000_113_idx in 1.574 s.
21/08/28 22:38:19 INFO TableWriter: Wrote 342 rows to sequencedetection.log_1000_113_idx in 1.577 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 4 rows to sequencedetection.log_1000_113_count in 0.042 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 5 rows to sequencedetection.log_1000_113_count in 0.045 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 6 rows to sequencedetection.log_1000_113_count in 0.045 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 5 rows to sequencedetection.log_1000_113_count in 0.049 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 4 rows to sequencedetection.log_1000_113_count in 0.048 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 8 rows to sequencedetection.log_1000_113_count in 0.050 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 9 rows to sequencedetection.log_1000_113_count in 0.055 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 9 rows to sequencedetection.log_1000_113_count in 0.055 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 4 rows to sequencedetection.log_1000_113_count in 0.056 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 9 rows to sequencedetection.log_1000_113_count in 0.056 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 9 rows to sequencedetection.log_1000_113_count in 0.054 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 8 rows to sequencedetection.log_1000_113_count in 0.061 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 9 rows to sequencedetection.log_1000_113_count in 0.060 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 8 rows to sequencedetection.log_1000_113_count in 0.063 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 7 rows to sequencedetection.log_1000_113_count in 0.063 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 8 rows to sequencedetection.log_1000_113_count in 0.063 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_113_seq in 0.140 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_113_seq in 0.150 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_113_seq in 0.162 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_113_seq in 0.164 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_113_seq in 0.167 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_113_seq in 0.168 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_113_seq in 0.175 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_113_seq in 0.176 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 55 rows to sequencedetection.log_1000_113_seq in 0.182 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_113_seq in 0.186 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 72 rows to sequencedetection.log_1000_113_seq in 0.189 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 72 rows to sequencedetection.log_1000_113_seq in 0.191 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 72 rows to sequencedetection.log_1000_113_seq in 0.191 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 76 rows to sequencedetection.log_1000_113_seq in 0.191 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 76 rows to sequencedetection.log_1000_113_seq in 0.193 s.
21/08/28 22:38:20 INFO TableWriter: Wrote 76 rows to sequencedetection.log_1000_113_seq in 0.197 s.
21/08/28 22:38:28 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:38:29 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_200000_113.xes normal
21/08/28 22:38:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/28 22:38:34 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:38:34 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/28 22:38:34 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:38:34 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:38:43 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:40:32 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:40:32 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:40:32 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:40:45 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:40:53 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:40:53 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:40:53 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 22:41:00 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 22:54:47 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 22:54:47 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 22:54:47 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 23:09:51 ERROR TaskSchedulerImpl: Lost executor driver on localhost: Executor heartbeat timed out after 455421 ms
21/08/28 23:12:32 ERROR Executor: Exception in task 5.0 in stage 5.0 (TID 129)
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$$anonfun$sampleArray$1.apply$mcVI$sp(SizeEstimator.scala:285)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:261)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:165)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
21/08/28 23:12:32 ERROR Executor: Exception in task 13.0 in stage 5.0 (TID 137)
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$$anonfun$sampleArray$1.apply$mcVI$sp(SizeEstimator.scala:285)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:262)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:165)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
21/08/28 23:12:32 ERROR Executor: Exception in task 9.0 in stage 5.0 (TID 133)
java.lang.OutOfMemoryError: Java heap space
21/08/28 23:12:32 ERROR TaskSetManager: Task 13 in stage 5.0 failed 1 times; aborting job
21/08/28 23:12:36 ERROR TaskSchedulerImpl: Ignoring update with state FAILED for TID 137 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
21/08/28 23:12:36 ERROR TaskSchedulerImpl: Ignoring update with state FAILED for TID 133 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
21/08/28 23:12:36 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 133,5,main]
java.lang.OutOfMemoryError: Java heap space
21/08/28 23:12:36 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 137,5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$$anonfun$sampleArray$1.apply$mcVI$sp(SizeEstimator.scala:285)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:262)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:165)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
21/08/28 23:12:36 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 129,5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$$anonfun$sampleArray$1.apply$mcVI$sp(SizeEstimator.scala:285)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:261)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:165)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
21/08/28 23:12:36 ERROR TaskSchedulerImpl: Ignoring update with state FAILED for TID 129 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
21/08/28 23:12:36 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100_346.xes normal
21/08/28 23:12:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/28 23:12:43 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 23:12:43 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/28 23:12:43 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 23:12:43 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 23:13:01 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 23:13:01 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 23:13:01 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 23:13:01 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 23:13:06 INFO TableWriter: Wrote 3989 rows to sequencedetection.log_100_346_idx in 4.354 s.
21/08/28 23:13:06 INFO TableWriter: Wrote 3973 rows to sequencedetection.log_100_346_idx in 4.369 s.
21/08/28 23:13:06 INFO TableWriter: Wrote 4045 rows to sequencedetection.log_100_346_idx in 4.378 s.
21/08/28 23:13:06 INFO TableWriter: Wrote 4025 rows to sequencedetection.log_100_346_idx in 4.381 s.
21/08/28 23:13:06 INFO TableWriter: Wrote 4033 rows to sequencedetection.log_100_346_idx in 4.385 s.
21/08/28 23:13:06 INFO TableWriter: Wrote 4041 rows to sequencedetection.log_100_346_idx in 4.392 s.
21/08/28 23:13:06 INFO TableWriter: Wrote 4054 rows to sequencedetection.log_100_346_idx in 4.400 s.
21/08/28 23:13:06 INFO TableWriter: Wrote 4058 rows to sequencedetection.log_100_346_idx in 4.405 s.
21/08/28 23:13:06 INFO TableWriter: Wrote 4127 rows to sequencedetection.log_100_346_idx in 4.415 s.
21/08/28 23:13:06 INFO TableWriter: Wrote 4092 rows to sequencedetection.log_100_346_idx in 4.419 s.
21/08/28 23:13:06 INFO TableWriter: Wrote 4039 rows to sequencedetection.log_100_346_idx in 4.419 s.
21/08/28 23:13:06 INFO TableWriter: Wrote 4115 rows to sequencedetection.log_100_346_idx in 4.422 s.
21/08/28 23:13:06 INFO TableWriter: Wrote 4120 rows to sequencedetection.log_100_346_idx in 4.422 s.
21/08/28 23:13:06 INFO TableWriter: Wrote 4178 rows to sequencedetection.log_100_346_idx in 4.431 s.
21/08/28 23:13:06 INFO TableWriter: Wrote 4166 rows to sequencedetection.log_100_346_idx in 4.435 s.
21/08/28 23:13:06 INFO TableWriter: Wrote 4192 rows to sequencedetection.log_100_346_idx in 4.440 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 20 rows to sequencedetection.log_100_346_count in 0.187 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 21 rows to sequencedetection.log_100_346_count in 0.198 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 23 rows to sequencedetection.log_100_346_count in 0.195 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 21 rows to sequencedetection.log_100_346_count in 0.205 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 21 rows to sequencedetection.log_100_346_count in 0.206 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 23 rows to sequencedetection.log_100_346_count in 0.208 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 20 rows to sequencedetection.log_100_346_count in 0.223 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 23 rows to sequencedetection.log_100_346_count in 0.225 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 21 rows to sequencedetection.log_100_346_count in 0.228 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 22 rows to sequencedetection.log_100_346_count in 0.233 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 21 rows to sequencedetection.log_100_346_count in 0.234 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 21 rows to sequencedetection.log_100_346_count in 0.234 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 21 rows to sequencedetection.log_100_346_count in 0.239 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 24 rows to sequencedetection.log_100_346_count in 0.249 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 22 rows to sequencedetection.log_100_346_count in 0.252 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 21 rows to sequencedetection.log_100_346_count in 0.256 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_346_seq in 0.030 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_seq in 0.031 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_seq in 0.029 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_seq in 0.038 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_seq in 0.061 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_346_seq in 0.059 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_346_seq in 0.064 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 3 rows to sequencedetection.log_100_346_seq in 0.062 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_seq in 0.066 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_seq in 0.065 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_seq in 0.072 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_seq in 0.072 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_seq in 0.074 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_346_seq in 0.073 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_seq in 0.078 s.
21/08/28 23:13:08 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_346_seq in 0.078 s.
21/08/28 23:13:15 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 23:13:16 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_10000_740.xes normal
21/08/28 23:13:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/28 23:13:21 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 23:13:22 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/28 23:13:22 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 23:13:22 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 23:13:30 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 23:14:18 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 23:14:18 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 23:14:18 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 23:14:30 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/28 23:14:43 INFO ClockFactory: Using native clock to generate timestamps.
21/08/28 23:14:43 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/28 23:14:43 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/28 23:14:50 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 00:13:36 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 00:13:36 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 00:13:36 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 04:31:02 INFO TableWriter: Wrote 24937 rows to sequencedetection.log_10000_740_idx in 15445.979 s.
21/08/29 04:32:33 INFO TableWriter: Wrote 25050 rows to sequencedetection.log_10000_740_idx in 15537.689 s.
21/08/29 04:32:51 INFO TableWriter: Wrote 25023 rows to sequencedetection.log_10000_740_idx in 15554.820 s.
21/08/29 04:33:21 INFO TableWriter: Wrote 24944 rows to sequencedetection.log_10000_740_idx in 15585.790 s.
21/08/29 04:33:23 INFO TableWriter: Wrote 25413 rows to sequencedetection.log_10000_740_idx in 15587.358 s.
21/08/29 04:33:29 INFO TableWriter: Wrote 24871 rows to sequencedetection.log_10000_740_idx in 15592.890 s.
21/08/29 04:33:32 INFO TableWriter: Wrote 24948 rows to sequencedetection.log_10000_740_idx in 15596.429 s.
21/08/29 04:33:50 INFO TableWriter: Wrote 25181 rows to sequencedetection.log_10000_740_idx in 15614.449 s.
21/08/29 04:33:56 INFO TableWriter: Wrote 25035 rows to sequencedetection.log_10000_740_idx in 15620.357 s.
21/08/29 04:33:57 INFO TableWriter: Wrote 25073 rows to sequencedetection.log_10000_740_idx in 15620.849 s.
21/08/29 04:34:03 INFO TableWriter: Wrote 24970 rows to sequencedetection.log_10000_740_idx in 15626.874 s.
21/08/29 04:34:08 INFO TableWriter: Wrote 24909 rows to sequencedetection.log_10000_740_idx in 15632.244 s.
21/08/29 04:34:08 INFO TableWriter: Wrote 25214 rows to sequencedetection.log_10000_740_idx in 15632.450 s.
21/08/29 04:34:10 INFO TableWriter: Wrote 25082 rows to sequencedetection.log_10000_740_idx in 15634.311 s.
21/08/29 04:34:11 INFO TableWriter: Wrote 25041 rows to sequencedetection.log_10000_740_idx in 15635.313 s.
21/08/29 04:34:14 INFO TableWriter: Wrote 25302 rows to sequencedetection.log_10000_740_idx in 15638.321 s.
21/08/29 04:34:27 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 04:58:29 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 04:58:29 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 04:58:29 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 04:58:30 INFO TableWriter: Wrote 42 rows to sequencedetection.log_10000_740_count in 1.066 s.
21/08/29 04:58:30 INFO TableWriter: Wrote 44 rows to sequencedetection.log_10000_740_count in 1.118 s.
21/08/29 04:58:30 INFO TableWriter: Wrote 43 rows to sequencedetection.log_10000_740_count in 1.118 s.
21/08/29 04:58:30 INFO TableWriter: Wrote 43 rows to sequencedetection.log_10000_740_count in 1.121 s.
21/08/29 04:58:30 INFO TableWriter: Wrote 45 rows to sequencedetection.log_10000_740_count in 1.252 s.
21/08/29 04:58:30 INFO TableWriter: Wrote 45 rows to sequencedetection.log_10000_740_count in 1.256 s.
21/08/29 04:58:30 INFO TableWriter: Wrote 45 rows to sequencedetection.log_10000_740_count in 1.312 s.
21/08/29 04:58:30 INFO TableWriter: Wrote 47 rows to sequencedetection.log_10000_740_count in 1.334 s.
21/08/29 04:58:30 INFO TableWriter: Wrote 48 rows to sequencedetection.log_10000_740_count in 1.343 s.
21/08/29 04:58:30 INFO TableWriter: Wrote 47 rows to sequencedetection.log_10000_740_count in 1.346 s.
21/08/29 04:58:30 INFO TableWriter: Wrote 45 rows to sequencedetection.log_10000_740_count in 1.360 s.
21/08/29 04:58:30 INFO TableWriter: Wrote 50 rows to sequencedetection.log_10000_740_count in 1.360 s.
21/08/29 04:58:30 INFO TableWriter: Wrote 46 rows to sequencedetection.log_10000_740_count in 1.386 s.
21/08/29 04:58:30 INFO TableWriter: Wrote 50 rows to sequencedetection.log_10000_740_count in 1.389 s.
21/08/29 04:58:30 INFO TableWriter: Wrote 49 rows to sequencedetection.log_10000_740_count in 1.393 s.
21/08/29 04:58:30 INFO TableWriter: Wrote 50 rows to sequencedetection.log_10000_740_count in 1.403 s.
21/08/29 04:58:35 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 04:58:35 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 04:58:35 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 04:58:37 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 04:58:52 INFO TableWriter: Wrote 558 rows to sequencedetection.log_10000_740_seq in 16.388 s.
21/08/29 04:58:52 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_740_seq in 17.055 s.
21/08/29 04:58:52 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_740_seq in 17.167 s.
21/08/29 04:58:52 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_740_seq in 17.246 s.
21/08/29 04:58:53 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_740_seq in 17.609 s.
21/08/29 04:58:53 INFO TableWriter: Wrote 558 rows to sequencedetection.log_10000_740_seq in 17.664 s.
21/08/29 04:58:53 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_740_seq in 17.672 s.
21/08/29 04:58:53 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_740_seq in 17.876 s.
21/08/29 04:58:54 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_740_seq in 18.376 s.
21/08/29 04:58:54 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_740_seq in 18.443 s.
21/08/29 04:58:57 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_740_seq in 21.886 s.
21/08/29 04:58:57 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_740_seq in 22.029 s.
21/08/29 04:58:57 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_740_seq in 22.115 s.
21/08/29 04:58:58 INFO TableWriter: Wrote 744 rows to sequencedetection.log_10000_740_seq in 22.374 s.
21/08/29 04:58:58 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_740_seq in 22.386 s.
21/08/29 04:58:58 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_740_seq in 22.505 s.
21/08/29 04:59:05 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 04:59:06 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_10000_113.xes normal
21/08/29 04:59:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 04:59:12 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 04:59:12 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 04:59:12 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 04:59:12 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 04:59:19 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 04:59:19 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 04:59:19 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 04:59:20 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 04:59:34 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 04:59:48 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 04:59:48 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 04:59:48 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 04:59:55 INFO TableWriter: Wrote 296 rows to sequencedetection.log_10000_113_idx in 6.643 s.
21/08/29 04:59:55 INFO TableWriter: Wrote 314 rows to sequencedetection.log_10000_113_idx in 6.874 s.
21/08/29 04:59:55 INFO TableWriter: Wrote 325 rows to sequencedetection.log_10000_113_idx in 7.185 s.
21/08/29 04:59:57 INFO TableWriter: Wrote 360 rows to sequencedetection.log_10000_113_idx in 8.374 s.
21/08/29 04:59:57 INFO TableWriter: Wrote 353 rows to sequencedetection.log_10000_113_idx in 8.401 s.
21/08/29 04:59:57 INFO TableWriter: Wrote 311 rows to sequencedetection.log_10000_113_idx in 8.537 s.
21/08/29 04:59:57 INFO TableWriter: Wrote 327 rows to sequencedetection.log_10000_113_idx in 8.625 s.
21/08/29 04:59:57 INFO TableWriter: Wrote 337 rows to sequencedetection.log_10000_113_idx in 8.905 s.
21/08/29 04:59:57 INFO TableWriter: Wrote 334 rows to sequencedetection.log_10000_113_idx in 8.968 s.
21/08/29 04:59:57 INFO TableWriter: Wrote 297 rows to sequencedetection.log_10000_113_idx in 8.974 s.
21/08/29 04:59:57 INFO TableWriter: Wrote 321 rows to sequencedetection.log_10000_113_idx in 9.002 s.
21/08/29 04:59:57 INFO TableWriter: Wrote 328 rows to sequencedetection.log_10000_113_idx in 9.022 s.
21/08/29 04:59:57 INFO TableWriter: Wrote 321 rows to sequencedetection.log_10000_113_idx in 9.037 s.
21/08/29 04:59:57 INFO TableWriter: Wrote 302 rows to sequencedetection.log_10000_113_idx in 9.058 s.
21/08/29 04:59:57 INFO TableWriter: Wrote 349 rows to sequencedetection.log_10000_113_idx in 9.112 s.
21/08/29 04:59:57 INFO TableWriter: Wrote 344 rows to sequencedetection.log_10000_113_idx in 9.184 s.
21/08/29 05:00:04 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:00:04 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:00:04 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:00:04 INFO TableWriter: Wrote 4 rows to sequencedetection.log_10000_113_count in 0.117 s.
21/08/29 05:00:04 INFO TableWriter: Wrote 4 rows to sequencedetection.log_10000_113_count in 0.116 s.
21/08/29 05:00:04 INFO TableWriter: Wrote 5 rows to sequencedetection.log_10000_113_count in 0.118 s.
21/08/29 05:00:04 INFO TableWriter: Wrote 5 rows to sequencedetection.log_10000_113_count in 0.116 s.
21/08/29 05:00:04 INFO TableWriter: Wrote 8 rows to sequencedetection.log_10000_113_count in 0.119 s.
21/08/29 05:00:04 INFO TableWriter: Wrote 4 rows to sequencedetection.log_10000_113_count in 0.119 s.
21/08/29 05:00:04 INFO TableWriter: Wrote 9 rows to sequencedetection.log_10000_113_count in 0.120 s.
21/08/29 05:00:04 INFO TableWriter: Wrote 7 rows to sequencedetection.log_10000_113_count in 0.120 s.
21/08/29 05:00:04 INFO TableWriter: Wrote 8 rows to sequencedetection.log_10000_113_count in 0.121 s.
21/08/29 05:00:04 INFO TableWriter: Wrote 9 rows to sequencedetection.log_10000_113_count in 0.121 s.
21/08/29 05:00:04 INFO TableWriter: Wrote 8 rows to sequencedetection.log_10000_113_count in 0.121 s.
21/08/29 05:00:04 INFO TableWriter: Wrote 9 rows to sequencedetection.log_10000_113_count in 0.120 s.
21/08/29 05:00:04 INFO TableWriter: Wrote 6 rows to sequencedetection.log_10000_113_count in 0.123 s.
21/08/29 05:00:04 INFO TableWriter: Wrote 8 rows to sequencedetection.log_10000_113_count in 0.125 s.
21/08/29 05:00:04 INFO TableWriter: Wrote 9 rows to sequencedetection.log_10000_113_count in 0.123 s.
21/08/29 05:00:04 INFO TableWriter: Wrote 9 rows to sequencedetection.log_10000_113_count in 0.126 s.
21/08/29 05:00:05 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:00:05 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_113_seq in 1.199 s.
21/08/29 05:00:05 INFO TableWriter: Wrote 558 rows to sequencedetection.log_10000_113_seq in 1.321 s.
21/08/29 05:00:05 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_113_seq in 1.322 s.
21/08/29 05:00:05 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_113_seq in 1.339 s.
21/08/29 05:00:05 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_113_seq in 1.348 s.
21/08/29 05:00:05 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_113_seq in 1.352 s.
21/08/29 05:00:05 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_113_seq in 1.353 s.
21/08/29 05:00:05 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_113_seq in 1.366 s.
21/08/29 05:00:05 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_113_seq in 1.376 s.
21/08/29 05:00:05 INFO TableWriter: Wrote 558 rows to sequencedetection.log_10000_113_seq in 1.376 s.
21/08/29 05:00:05 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_113_seq in 1.463 s.
21/08/29 05:00:05 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_113_seq in 1.472 s.
21/08/29 05:00:05 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_113_seq in 1.478 s.
21/08/29 05:00:05 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_113_seq in 1.492 s.
21/08/29 05:00:05 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_113_seq in 1.504 s.
21/08/29 05:00:05 INFO TableWriter: Wrote 744 rows to sequencedetection.log_10000_113_seq in 1.506 s.
21/08/29 05:00:13 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:00:14 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_500_740.xes signature
21/08/29 05:00:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 05:00:19 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:00:19 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 05:00:20 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:00:20 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:00:29 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:04:21 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:04:21 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:04:21 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:04:22 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.682 s.
21/08/29 05:04:22 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_740_sign_seq in 0.723 s.
21/08/29 05:04:22 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_740_sign_seq in 0.723 s.
21/08/29 05:04:22 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_740_sign_seq in 0.728 s.
21/08/29 05:04:22 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.697 s.
21/08/29 05:04:22 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_740_sign_seq in 0.728 s.
21/08/29 05:04:22 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.720 s.
21/08/29 05:04:22 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.723 s.
21/08/29 05:04:22 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.728 s.
21/08/29 05:04:22 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.729 s.
21/08/29 05:04:22 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.700 s.
21/08/29 05:04:22 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.728 s.
21/08/29 05:04:22 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.730 s.
21/08/29 05:04:22 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.702 s.
21/08/29 05:04:22 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.697 s.
21/08/29 05:04:22 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.735 s.
21/08/29 05:04:29 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:04:45 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:04:45 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:04:45 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:04:48 INFO TableWriter: Wrote 28 rows to sequencedetection.log_500_740_sign_idx in 2.383 s.
21/08/29 05:04:48 INFO TableWriter: Wrote 25 rows to sequencedetection.log_500_740_sign_idx in 2.472 s.
21/08/29 05:04:48 INFO TableWriter: Wrote 28 rows to sequencedetection.log_500_740_sign_idx in 2.658 s.
21/08/29 05:04:48 INFO TableWriter: Wrote 28 rows to sequencedetection.log_500_740_sign_idx in 2.700 s.
21/08/29 05:04:48 INFO TableWriter: Wrote 28 rows to sequencedetection.log_500_740_sign_idx in 2.714 s.
21/08/29 05:04:48 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_740_sign_idx in 2.751 s.
21/08/29 05:04:48 INFO TableWriter: Wrote 33 rows to sequencedetection.log_500_740_sign_idx in 2.893 s.
21/08/29 05:04:48 INFO TableWriter: Wrote 30 rows to sequencedetection.log_500_740_sign_idx in 2.901 s.
21/08/29 05:04:48 INFO TableWriter: Wrote 33 rows to sequencedetection.log_500_740_sign_idx in 2.910 s.
21/08/29 05:04:48 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_idx in 2.942 s.
21/08/29 05:04:48 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_740_sign_idx in 2.942 s.
21/08/29 05:04:48 INFO TableWriter: Wrote 29 rows to sequencedetection.log_500_740_sign_idx in 2.959 s.
21/08/29 05:04:48 INFO TableWriter: Wrote 34 rows to sequencedetection.log_500_740_sign_idx in 2.988 s.
21/08/29 05:04:48 INFO TableWriter: Wrote 33 rows to sequencedetection.log_500_740_sign_idx in 2.986 s.
21/08/29 05:04:48 INFO TableWriter: Wrote 35 rows to sequencedetection.log_500_740_sign_idx in 3.002 s.
21/08/29 05:04:48 INFO TableWriter: Wrote 42 rows to sequencedetection.log_500_740_sign_idx in 3.024 s.
21/08/29 05:04:56 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:04:57 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_10000_346.xes signature
21/08/29 05:05:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 05:05:02 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:05:02 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 05:05:03 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:05:03 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:05:11 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:12:57 ERROR Executor: Exception in task 13.0 in stage 0.0 (TID 13)
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingVector.$plus$eq(SizeTrackingVector.scala:31)
	at org.apache.spark.storage.memory.DeserializedValuesHolder.storeValue(MemoryStore.scala:665)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
21/08/29 05:13:02 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 13,5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingVector.$plus$eq(SizeTrackingVector.scala:31)
	at org.apache.spark.storage.memory.DeserializedValuesHolder.storeValue(MemoryStore.scala:665)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
21/08/29 05:13:02 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
21/08/29 05:13:02 ERROR TaskSetManager: Task 13 in stage 0.0 failed 1 times; aborting job
Exception in thread "main" org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:932)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:930)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:930)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2128)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2041)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:944)
	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:309)
	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)
	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:151)
	at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:62)
	at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:61)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.OrderedRDDFunctions.sortByKey(OrderedRDDFunctions.scala:61)
	at org.apache.spark.rdd.RDD$$anonfun$sortBy$1.apply(RDD.scala:623)
	at org.apache.spark.rdd.RDD$$anonfun$sortBy$1.apply(RDD.scala:624)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.sortBy(RDD.scala:621)
	at auth.datalab.sequenceDetection.Signatures.Signature$$anonfun$main$1.apply(Signature.scala:50)
	at auth.datalab.sequenceDetection.Signatures.Signature$$anonfun$main$1.apply(Signature.scala:39)
	at org.apache.spark.sql.SparkSession.time(SparkSession.scala:677)
	at auth.datalab.sequenceDetection.Signatures.Signature$.main(Signature.scala:39)
	at auth.datalab.sequenceDetection.Main$.main(Main.scala:9)
	at auth.datalab.sequenceDetection.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
log_1000_740.xes signature
21/08/29 05:13:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 05:13:07 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:13:07 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 05:13:08 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:13:08 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:13:16 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:16:03 ERROR Executor: Exception in task 2.0 in stage 0.0 (TID 2)
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingVector.$plus$eq(SizeTrackingVector.scala:31)
	at org.apache.spark.storage.memory.DeserializedValuesHolder.storeValue(MemoryStore.scala:665)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
21/08/29 05:16:03 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 2,5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingVector.$plus$eq(SizeTrackingVector.scala:31)
	at org.apache.spark.storage.memory.DeserializedValuesHolder.storeValue(MemoryStore.scala:665)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
21/08/29 05:16:03 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
21/08/29 05:16:03 ERROR TaskSetManager: Task 2 in stage 0.0 failed 1 times; aborting job
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 0.0 failed 1 times, most recent failure: Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingVector.$plus$eq(SizeTrackingVector.scala:31)
	at org.apache.spark.storage.memory.DeserializedValuesHolder.storeValue(MemoryStore.scala:665)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:944)
	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:309)
	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)
	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:151)
	at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:62)
	at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:61)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.OrderedRDDFunctions.sortByKey(OrderedRDDFunctions.scala:61)
	at org.apache.spark.rdd.RDD$$anonfun$sortBy$1.apply(RDD.scala:623)
	at org.apache.spark.rdd.RDD$$anonfun$sortBy$1.apply(RDD.scala:624)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.sortBy(RDD.scala:621)
	at auth.datalab.sequenceDetection.Signatures.Signature$$anonfun$main$1.apply(Signature.scala:50)
	at auth.datalab.sequenceDetection.Signatures.Signature$$anonfun$main$1.apply(Signature.scala:39)
	at org.apache.spark.sql.SparkSession.time(SparkSession.scala:677)
	at auth.datalab.sequenceDetection.Signatures.Signature$.main(Signature.scala:39)
	at auth.datalab.sequenceDetection.Main$.main(Main.scala:9)
	at auth.datalab.sequenceDetection.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingVector.$plus$eq(SizeTrackingVector.scala:31)
	at org.apache.spark.storage.memory.DeserializedValuesHolder.storeValue(MemoryStore.scala:665)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
log_100000_346.xes signature
21/08/29 05:16:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 05:16:25 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:16:25 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 05:16:26 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:16:26 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:16:34 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
Exception in thread "main" java.lang.OutOfMemoryError: GC overhead limit exceeded
	at org.apache.xerces.jaxp.datatype.XMLGregorianCalendarImpl.toGregorianCalendar(Unknown Source)
	at javax.xml.bind.DatatypeConverterImpl._parseDateTime(DatatypeConverterImpl.java:422)
	at javax.xml.bind.DatatypeConverterImpl.parseDateTime(DatatypeConverterImpl.java:417)
	at javax.xml.bind.DatatypeConverter.parseDateTime(DatatypeConverter.java:327)
	at org.deckfour.xes.util.XsDateTimeConversion.parseXsDateTime(XsDateTimeConversion.java:96)
	at org.deckfour.xes.util.XsDateTimeConversionJava7.parseXsDateTime(XsDateTimeConversionJava7.java:85)
	at org.deckfour.xes.in.XesXmlParser$XesXmlHandler.startElement(XesXmlParser.java:292)
	at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
	at org.apache.xerces.parsers.AbstractXMLDocumentParser.emptyElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanStartElement(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
	at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
	at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
	at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
	at org.apache.xerces.jaxp.SAXParserImpl.parse(Unknown Source)
	at javax.xml.parsers.SAXParser.parse(SAXParser.java:195)
	at org.deckfour.xes.in.XesXmlParser.parse(XesXmlParser.java:175)
	at auth.datalab.sequenceDetection.Utils$.readFromXes(Utils.scala:62)
	at auth.datalab.sequenceDetection.Utils$.readLog(Utils.scala:35)
	at auth.datalab.sequenceDetection.Signatures.Signature$$anonfun$main$1.apply(Signature.scala:40)
	at auth.datalab.sequenceDetection.Signatures.Signature$$anonfun$main$1.apply(Signature.scala:39)
	at org.apache.spark.sql.SparkSession.time(SparkSession.scala:677)
	at auth.datalab.sequenceDetection.Signatures.Signature$.main(Signature.scala:39)
	at auth.datalab.sequenceDetection.Main$.main(Main.scala:9)
	at auth.datalab.sequenceDetection.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
21/08/29 05:20:24 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_1000_346.xes signature
21/08/29 05:20:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 05:20:34 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:20:34 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 05:20:35 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:20:35 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:20:43 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:21:16 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:21:16 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:21:16 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:21:17 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_sign_seq in 0.509 s.
21/08/29 05:21:17 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_sign_seq in 0.511 s.
21/08/29 05:21:17 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_sign_seq in 0.512 s.
21/08/29 05:21:17 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_sign_seq in 0.513 s.
21/08/29 05:21:17 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_sign_seq in 0.513 s.
21/08/29 05:21:17 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_sign_seq in 0.513 s.
21/08/29 05:21:17 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_sign_seq in 0.514 s.
21/08/29 05:21:17 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_sign_seq in 0.516 s.
21/08/29 05:21:17 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_sign_seq in 0.516 s.
21/08/29 05:21:17 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_sign_seq in 0.516 s.
21/08/29 05:21:17 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_sign_seq in 0.516 s.
21/08/29 05:21:17 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_sign_seq in 0.517 s.
21/08/29 05:21:17 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_sign_seq in 0.511 s.
21/08/29 05:21:17 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_sign_seq in 0.517 s.
21/08/29 05:21:17 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_sign_seq in 0.517 s.
21/08/29 05:21:17 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_sign_seq in 0.518 s.
21/08/29 05:21:20 INFO TableWriter: Wrote 30 rows to sequencedetection.log_1000_346_sign_idx in 0.859 s.
21/08/29 05:21:20 INFO TableWriter: Wrote 33 rows to sequencedetection.log_1000_346_sign_idx in 1.025 s.
21/08/29 05:21:21 INFO TableWriter: Wrote 45 rows to sequencedetection.log_1000_346_sign_idx in 1.392 s.
21/08/29 05:21:21 INFO TableWriter: Wrote 51 rows to sequencedetection.log_1000_346_sign_idx in 1.425 s.
21/08/29 05:21:21 INFO TableWriter: Wrote 50 rows to sequencedetection.log_1000_346_sign_idx in 1.487 s.
21/08/29 05:21:21 INFO TableWriter: Wrote 49 rows to sequencedetection.log_1000_346_sign_idx in 1.496 s.
21/08/29 05:21:21 INFO TableWriter: Wrote 61 rows to sequencedetection.log_1000_346_sign_idx in 1.606 s.
21/08/29 05:21:21 INFO TableWriter: Wrote 66 rows to sequencedetection.log_1000_346_sign_idx in 1.704 s.
21/08/29 05:21:21 INFO TableWriter: Wrote 59 rows to sequencedetection.log_1000_346_sign_idx in 1.720 s.
21/08/29 05:21:21 INFO TableWriter: Wrote 58 rows to sequencedetection.log_1000_346_sign_idx in 1.780 s.
21/08/29 05:21:21 INFO TableWriter: Wrote 66 rows to sequencedetection.log_1000_346_sign_idx in 1.800 s.
21/08/29 05:21:21 INFO TableWriter: Wrote 78 rows to sequencedetection.log_1000_346_sign_idx in 1.831 s.
21/08/29 05:21:21 INFO TableWriter: Wrote 70 rows to sequencedetection.log_1000_346_sign_idx in 1.832 s.
21/08/29 05:21:21 INFO TableWriter: Wrote 81 rows to sequencedetection.log_1000_346_sign_idx in 1.858 s.
21/08/29 05:21:21 INFO TableWriter: Wrote 86 rows to sequencedetection.log_1000_346_sign_idx in 1.878 s.
21/08/29 05:21:21 INFO TableWriter: Wrote 100 rows to sequencedetection.log_1000_346_sign_idx in 1.940 s.
21/08/29 05:21:29 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:21:30 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100_740.xes signature
21/08/29 05:21:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 05:21:35 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:21:35 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 05:21:36 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:21:36 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:21:45 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:21:56 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:21:56 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:21:56 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:21:57 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.195 s.
21/08/29 05:21:57 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.198 s.
21/08/29 05:21:57 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_sign_seq in 0.188 s.
21/08/29 05:21:57 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.198 s.
21/08/29 05:21:57 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.199 s.
21/08/29 05:21:57 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_sign_seq in 0.199 s.
21/08/29 05:21:57 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.200 s.
21/08/29 05:21:57 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_sign_seq in 0.200 s.
21/08/29 05:21:57 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.201 s.
21/08/29 05:21:57 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.201 s.
21/08/29 05:21:57 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.201 s.
21/08/29 05:21:57 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.201 s.
21/08/29 05:21:57 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.201 s.
21/08/29 05:21:57 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.201 s.
21/08/29 05:21:57 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_sign_seq in 0.200 s.
21/08/29 05:21:57 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.200 s.
21/08/29 05:21:58 INFO TableWriter: Wrote 0 rows to sequencedetection.log_100_740_sign_idx in 0.029 s.
21/08/29 05:21:58 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_740_sign_idx in 0.126 s.
21/08/29 05:21:58 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_idx in 0.130 s.
21/08/29 05:21:58 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_sign_idx in 0.186 s.
21/08/29 05:21:59 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_740_sign_idx in 0.271 s.
21/08/29 05:21:59 INFO TableWriter: Wrote 3 rows to sequencedetection.log_100_740_sign_idx in 0.299 s.
21/08/29 05:21:59 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_740_sign_idx in 0.358 s.
21/08/29 05:21:59 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_740_sign_idx in 0.435 s.
21/08/29 05:21:59 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_sign_idx in 0.450 s.
21/08/29 05:21:59 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_idx in 0.455 s.
21/08/29 05:21:59 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_idx in 0.487 s.
21/08/29 05:21:59 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100_740_sign_idx in 0.502 s.
21/08/29 05:21:59 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_740_sign_idx in 0.511 s.
21/08/29 05:21:59 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_sign_idx in 0.510 s.
21/08/29 05:21:59 INFO TableWriter: Wrote 10 rows to sequencedetection.log_100_740_sign_idx in 0.518 s.
21/08/29 05:21:59 INFO TableWriter: Wrote 12 rows to sequencedetection.log_100_740_sign_idx in 0.559 s.
21/08/29 05:22:06 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:22:07 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_500_346.xes signature
21/08/29 05:22:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 05:22:12 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:22:13 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 05:22:13 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:22:13 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:22:22 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:22:36 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:22:36 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:22:36 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:22:37 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.409 s.
21/08/29 05:22:37 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.409 s.
21/08/29 05:22:37 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.412 s.
21/08/29 05:22:37 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.413 s.
21/08/29 05:22:37 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.413 s.
21/08/29 05:22:37 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_sign_seq in 0.415 s.
21/08/29 05:22:37 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.415 s.
21/08/29 05:22:37 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.415 s.
21/08/29 05:22:37 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.415 s.
21/08/29 05:22:37 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.416 s.
21/08/29 05:22:37 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.416 s.
21/08/29 05:22:37 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.416 s.
21/08/29 05:22:37 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_sign_seq in 0.416 s.
21/08/29 05:22:37 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.416 s.
21/08/29 05:22:37 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_sign_seq in 0.416 s.
21/08/29 05:22:37 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_sign_seq in 0.417 s.
21/08/29 05:22:38 INFO TableWriter: Wrote 14 rows to sequencedetection.log_500_346_sign_idx in 0.171 s.
21/08/29 05:22:38 INFO TableWriter: Wrote 25 rows to sequencedetection.log_500_346_sign_idx in 0.582 s.
21/08/29 05:22:38 INFO TableWriter: Wrote 19 rows to sequencedetection.log_500_346_sign_idx in 0.602 s.
21/08/29 05:22:38 INFO TableWriter: Wrote 24 rows to sequencedetection.log_500_346_sign_idx in 0.626 s.
21/08/29 05:22:38 INFO TableWriter: Wrote 28 rows to sequencedetection.log_500_346_sign_idx in 0.639 s.
21/08/29 05:22:38 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_sign_idx in 0.679 s.
21/08/29 05:22:39 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_idx in 0.860 s.
21/08/29 05:22:39 INFO TableWriter: Wrote 28 rows to sequencedetection.log_500_346_sign_idx in 0.869 s.
21/08/29 05:22:39 INFO TableWriter: Wrote 30 rows to sequencedetection.log_500_346_sign_idx in 0.878 s.
21/08/29 05:22:39 INFO TableWriter: Wrote 34 rows to sequencedetection.log_500_346_sign_idx in 0.891 s.
21/08/29 05:22:39 INFO TableWriter: Wrote 35 rows to sequencedetection.log_500_346_sign_idx in 0.921 s.
21/08/29 05:22:39 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_sign_idx in 0.936 s.
21/08/29 05:22:39 INFO TableWriter: Wrote 34 rows to sequencedetection.log_500_346_sign_idx in 0.932 s.
21/08/29 05:22:39 INFO TableWriter: Wrote 39 rows to sequencedetection.log_500_346_sign_idx in 0.966 s.
21/08/29 05:22:39 INFO TableWriter: Wrote 46 rows to sequencedetection.log_500_346_sign_idx in 1.054 s.
21/08/29 05:22:39 INFO TableWriter: Wrote 43 rows to sequencedetection.log_500_346_sign_idx in 1.055 s.
21/08/29 05:22:46 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:22:47 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100000_113.xes signature
21/08/29 05:22:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 05:22:52 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:22:52 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 05:22:53 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:22:53 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:23:01 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:26:12 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:26:12 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:26:12 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:26:23 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:26:23 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:26:23 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:26:30 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:26:57 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 33.835 s.
21/08/29 05:26:57 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 33.834 s.
21/08/29 05:26:57 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 33.827 s.
21/08/29 05:26:57 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 33.853 s.
21/08/29 05:26:57 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 33.834 s.
21/08/29 05:26:57 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 33.863 s.
21/08/29 05:26:57 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 33.856 s.
21/08/29 05:26:57 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 33.823 s.
21/08/29 05:26:57 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 33.820 s.
21/08/29 05:26:57 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 33.871 s.
21/08/29 05:26:57 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 33.874 s.
21/08/29 05:26:57 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 33.869 s.
21/08/29 05:26:57 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 33.870 s.
21/08/29 05:26:57 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 33.880 s.
21/08/29 05:26:57 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 33.844 s.
21/08/29 05:26:57 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 33.849 s.
21/08/29 05:27:06 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:28:02 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:28:02 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:28:02 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:28:02 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100000_113_sign_idx in 0.208 s.
21/08/29 05:28:02 INFO TableWriter: Wrote 10 rows to sequencedetection.log_100000_113_sign_idx in 0.216 s.
21/08/29 05:28:02 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100000_113_sign_idx in 0.180 s.
21/08/29 05:28:02 INFO TableWriter: Wrote 10 rows to sequencedetection.log_100000_113_sign_idx in 0.210 s.
21/08/29 05:28:02 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100000_113_sign_idx in 0.193 s.
21/08/29 05:28:02 INFO TableWriter: Wrote 12 rows to sequencedetection.log_100000_113_sign_idx in 0.257 s.
21/08/29 05:28:02 INFO TableWriter: Wrote 10 rows to sequencedetection.log_100000_113_sign_idx in 0.205 s.
21/08/29 05:28:02 INFO TableWriter: Wrote 12 rows to sequencedetection.log_100000_113_sign_idx in 0.254 s.
21/08/29 05:28:02 INFO TableWriter: Wrote 18 rows to sequencedetection.log_100000_113_sign_idx in 0.191 s.
21/08/29 05:28:02 INFO TableWriter: Wrote 19 rows to sequencedetection.log_100000_113_sign_idx in 0.215 s.
21/08/29 05:28:02 INFO TableWriter: Wrote 16 rows to sequencedetection.log_100000_113_sign_idx in 0.231 s.
21/08/29 05:28:02 INFO TableWriter: Wrote 21 rows to sequencedetection.log_100000_113_sign_idx in 0.257 s.
21/08/29 05:28:02 INFO TableWriter: Wrote 14 rows to sequencedetection.log_100000_113_sign_idx in 0.198 s.
21/08/29 05:28:02 INFO TableWriter: Wrote 18 rows to sequencedetection.log_100000_113_sign_idx in 0.153 s.
21/08/29 05:28:02 INFO TableWriter: Wrote 22 rows to sequencedetection.log_100000_113_sign_idx in 0.068 s.
21/08/29 05:28:02 INFO TableWriter: Wrote 22 rows to sequencedetection.log_100000_113_sign_idx in 0.049 s.
21/08/29 05:28:09 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:28:10 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100_113.xes signature
21/08/29 05:28:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 05:28:16 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:28:16 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 05:28:16 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:28:16 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:28:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.169 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.169 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.170 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.169 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_sign_seq in 0.170 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.170 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.169 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.170 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.169 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.169 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_sign_seq in 0.169 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.169 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_sign_seq in 0.169 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.169 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_sign_seq in 0.172 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.172 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 1 rows to sequencedetection.log_100_113_sign_idx in 0.041 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 2 rows to sequencedetection.log_100_113_sign_idx in 0.036 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 1 rows to sequencedetection.log_100_113_sign_idx in 0.041 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 0 rows to sequencedetection.log_100_113_sign_idx in 0.040 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_113_sign_idx in 0.056 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_113_sign_idx in 0.063 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 2 rows to sequencedetection.log_100_113_sign_idx in 0.066 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_113_sign_idx in 0.076 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_113_sign_idx in 0.073 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_sign_idx in 0.097 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_sign_idx in 0.109 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 2 rows to sequencedetection.log_100_113_sign_idx in 0.112 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_113_sign_idx in 0.109 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_idx in 0.122 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 3 rows to sequencedetection.log_100_113_sign_idx in 0.121 s.
21/08/29 05:28:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_idx in 0.122 s.
21/08/29 05:28:35 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:28:36 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_1000_113.xes signature
21/08/29 05:28:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 05:28:41 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:28:41 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 05:28:42 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:28:42 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:28:49 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:28:49 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:28:49 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:28:50 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_sign_seq in 0.372 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_sign_seq in 0.373 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_sign_seq in 0.373 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_sign_seq in 0.372 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_sign_seq in 0.372 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_sign_seq in 0.372 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_sign_seq in 0.372 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_sign_seq in 0.372 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_sign_seq in 0.372 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_sign_seq in 0.372 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_sign_seq in 0.372 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_sign_seq in 0.373 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_sign_seq in 0.372 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_sign_seq in 0.373 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_sign_seq in 0.373 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_sign_seq in 0.373 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 4 rows to sequencedetection.log_1000_113_sign_idx in 0.040 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_1000_113_sign_idx in 0.044 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 7 rows to sequencedetection.log_1000_113_sign_idx in 0.055 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_1000_113_sign_idx in 0.060 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 12 rows to sequencedetection.log_1000_113_sign_idx in 0.162 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_1000_113_sign_idx in 0.166 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 9 rows to sequencedetection.log_1000_113_sign_idx in 0.166 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 15 rows to sequencedetection.log_1000_113_sign_idx in 0.174 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 10 rows to sequencedetection.log_1000_113_sign_idx in 0.184 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 10 rows to sequencedetection.log_1000_113_sign_idx in 0.190 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 15 rows to sequencedetection.log_1000_113_sign_idx in 0.199 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 11 rows to sequencedetection.log_1000_113_sign_idx in 0.196 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 13 rows to sequencedetection.log_1000_113_sign_idx in 0.201 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 12 rows to sequencedetection.log_1000_113_sign_idx in 0.198 s.
21/08/29 05:28:50 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:28:50 INFO TableWriter: Wrote 20 rows to sequencedetection.log_1000_113_sign_idx in 0.205 s.
21/08/29 05:28:50 INFO TableWriter: Wrote 15 rows to sequencedetection.log_1000_113_sign_idx in 0.204 s.
21/08/29 05:28:58 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:28:59 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_200000_113.xes signature
21/08/29 05:29:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 05:29:04 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:29:04 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 05:29:05 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:29:05 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:29:13 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:36:38 ERROR Executor: Exception in task 8.0 in stage 0.0 (TID 8)
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$$anonfun$sampleArray$1.apply$mcVI$sp(SizeEstimator.scala:285)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:262)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingVector.$plus$eq(SizeTrackingVector.scala:31)
	at org.apache.spark.storage.memory.DeserializedValuesHolder.storeValue(MemoryStore.scala:665)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager.maybeCacheDiskValuesInMemory(BlockManager.scala:1312)
	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:612)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:886)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
21/08/29 05:36:45 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 8,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$$anonfun$sampleArray$1.apply$mcVI$sp(SizeEstimator.scala:285)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:262)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingVector.$plus$eq(SizeTrackingVector.scala:31)
	at org.apache.spark.storage.memory.DeserializedValuesHolder.storeValue(MemoryStore.scala:665)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager.maybeCacheDiskValuesInMemory(BlockManager.scala:1312)
	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:612)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:886)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
21/08/29 05:36:59 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
21/08/29 05:36:59 ERROR TaskSetManager: Task 8 in stage 0.0 failed 1 times; aborting job
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 0.0 failed 1 times, most recent failure: Lost task 8.0 in stage 0.0 (TID 8, localhost, executor driver): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$$anonfun$sampleArray$1.apply$mcVI$sp(SizeEstimator.scala:285)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:262)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingVector.$plus$eq(SizeTrackingVector.scala:31)
	at org.apache.spark.storage.memory.DeserializedValuesHolder.storeValue(MemoryStore.scala:665)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager.maybeCacheDiskValuesInMemory(BlockManager.scala:1312)
	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:612)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:886)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:944)
	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:309)
	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)
	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:151)
	at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:62)
	at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:61)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.OrderedRDDFunctions.sortByKey(OrderedRDDFunctions.scala:61)
	at org.apache.spark.rdd.RDD$$anonfun$sortBy$1.apply(RDD.scala:623)
	at org.apache.spark.rdd.RDD$$anonfun$sortBy$1.apply(RDD.scala:624)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.sortBy(RDD.scala:621)
	at auth.datalab.sequenceDetection.Signatures.Signature$$anonfun$main$1.apply(Signature.scala:50)
	at auth.datalab.sequenceDetection.Signatures.Signature$$anonfun$main$1.apply(Signature.scala:39)
	at org.apache.spark.sql.SparkSession.time(SparkSession.scala:677)
	at auth.datalab.sequenceDetection.Signatures.Signature$.main(Signature.scala:39)
	at auth.datalab.sequenceDetection.Main$.main(Main.scala:9)
	at auth.datalab.sequenceDetection.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
Caused by: java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$$anonfun$sampleArray$1.apply$mcVI$sp(SizeEstimator.scala:285)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:262)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingVector.$plus$eq(SizeTrackingVector.scala:31)
	at org.apache.spark.storage.memory.DeserializedValuesHolder.storeValue(MemoryStore.scala:665)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager.maybeCacheDiskValuesInMemory(BlockManager.scala:1312)
	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:612)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:886)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
21/08/29 05:37:15 ERROR TaskSchedulerImpl: Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$4@49102b59 rejected from java.util.concurrent.ThreadPoolExecutor@4d2fb6a3[Shutting down, pool size = 3, active threads = 1, queued tasks = 0, completed tasks = 2]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueFailedTask(TaskResultGetter.scala:131)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:560)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:539)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
log_100_346.xes signature
21/08/29 05:37:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 05:37:38 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:37:38 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 05:37:38 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:37:38 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:37:49 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:37:49 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:37:49 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:37:49 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.153 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_sign_seq in 0.154 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_sign_seq in 0.158 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.164 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.166 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.166 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.167 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.167 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.167 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.168 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.168 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.168 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_sign_seq in 0.172 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.172 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.172 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_sign_seq in 0.172 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 1 rows to sequencedetection.log_100_346_sign_idx in 0.047 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 1 rows to sequencedetection.log_100_346_sign_idx in 0.053 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 3 rows to sequencedetection.log_100_346_sign_idx in 0.103 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_sign_idx in 0.137 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_346_sign_idx in 0.146 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_sign_idx in 0.148 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_346_sign_idx in 0.145 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_346_sign_idx in 0.165 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_346_sign_idx in 0.193 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_346_sign_idx in 0.208 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100_346_sign_idx in 0.209 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_idx in 0.213 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 10 rows to sequencedetection.log_100_346_sign_idx in 0.231 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 11 rows to sequencedetection.log_100_346_sign_idx in 0.242 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_sign_idx in 0.232 s.
21/08/29 05:37:50 INFO TableWriter: Wrote 14 rows to sequencedetection.log_100_346_sign_idx in 0.240 s.
21/08/29 05:37:58 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:37:59 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_10000_740.xes signature
21/08/29 05:38:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 05:38:04 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:38:04 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 05:38:04 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:38:04 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:38:13 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:40:27 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingVector.$plus$eq(SizeTrackingVector.scala:31)
	at org.apache.spark.storage.memory.DeserializedValuesHolder.storeValue(MemoryStore.scala:665)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
21/08/29 05:40:27 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 0,5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingVector.$plus$eq(SizeTrackingVector.scala:31)
	at org.apache.spark.storage.memory.DeserializedValuesHolder.storeValue(MemoryStore.scala:665)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
21/08/29 05:40:33 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
21/08/29 05:40:33 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job
Exception in thread "main" org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:932)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:930)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:930)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2128)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2041)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:944)
	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:309)
	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)
	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:151)
	at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:62)
	at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:61)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.OrderedRDDFunctions.sortByKey(OrderedRDDFunctions.scala:61)
	at org.apache.spark.rdd.RDD$$anonfun$sortBy$1.apply(RDD.scala:623)
	at org.apache.spark.rdd.RDD$$anonfun$sortBy$1.apply(RDD.scala:624)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.sortBy(RDD.scala:621)
	at auth.datalab.sequenceDetection.Signatures.Signature$$anonfun$main$1.apply(Signature.scala:50)
	at auth.datalab.sequenceDetection.Signatures.Signature$$anonfun$main$1.apply(Signature.scala:39)
	at org.apache.spark.sql.SparkSession.time(SparkSession.scala:677)
	at auth.datalab.sequenceDetection.Signatures.Signature$.main(Signature.scala:39)
	at auth.datalab.sequenceDetection.Main$.main(Main.scala:9)
	at auth.datalab.sequenceDetection.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
log_10000_113.xes signature
21/08/29 05:40:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 05:40:43 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:40:43 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 05:40:44 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:40:44 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:40:52 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:41:12 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:41:12 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:41:12 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:41:14 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.231 s.
21/08/29 05:41:14 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.234 s.
21/08/29 05:41:14 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.243 s.
21/08/29 05:41:14 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.245 s.
21/08/29 05:41:14 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.250 s.
21/08/29 05:41:14 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.250 s.
21/08/29 05:41:14 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.250 s.
21/08/29 05:41:14 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.251 s.
21/08/29 05:41:14 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.250 s.
21/08/29 05:41:14 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.251 s.
21/08/29 05:41:14 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.256 s.
21/08/29 05:41:14 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.256 s.
21/08/29 05:41:14 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.256 s.
21/08/29 05:41:14 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.253 s.
21/08/29 05:41:14 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.257 s.
21/08/29 05:41:14 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.259 s.
21/08/29 05:41:15 INFO TableWriter: Wrote 7 rows to sequencedetection.log_10000_113_sign_idx in 0.073 s.
21/08/29 05:41:15 INFO TableWriter: Wrote 7 rows to sequencedetection.log_10000_113_sign_idx in 0.061 s.
21/08/29 05:41:15 INFO TableWriter: Wrote 10 rows to sequencedetection.log_10000_113_sign_idx in 0.139 s.
21/08/29 05:41:15 INFO TableWriter: Wrote 16 rows to sequencedetection.log_10000_113_sign_idx in 0.115 s.
21/08/29 05:41:15 INFO TableWriter: Wrote 6 rows to sequencedetection.log_10000_113_sign_idx in 0.153 s.
21/08/29 05:41:15 INFO TableWriter: Wrote 12 rows to sequencedetection.log_10000_113_sign_idx in 0.153 s.
21/08/29 05:41:15 INFO TableWriter: Wrote 12 rows to sequencedetection.log_10000_113_sign_idx in 0.135 s.
21/08/29 05:41:15 INFO TableWriter: Wrote 10 rows to sequencedetection.log_10000_113_sign_idx in 0.148 s.
21/08/29 05:41:15 INFO TableWriter: Wrote 18 rows to sequencedetection.log_10000_113_sign_idx in 0.159 s.
21/08/29 05:41:15 INFO TableWriter: Wrote 14 rows to sequencedetection.log_10000_113_sign_idx in 0.178 s.
21/08/29 05:41:15 INFO TableWriter: Wrote 19 rows to sequencedetection.log_10000_113_sign_idx in 0.189 s.
21/08/29 05:41:15 INFO TableWriter: Wrote 10 rows to sequencedetection.log_10000_113_sign_idx in 0.168 s.
21/08/29 05:41:15 INFO TableWriter: Wrote 22 rows to sequencedetection.log_10000_113_sign_idx in 0.160 s.
21/08/29 05:41:15 INFO TableWriter: Wrote 18 rows to sequencedetection.log_10000_113_sign_idx in 0.174 s.
21/08/29 05:41:15 INFO TableWriter: Wrote 21 rows to sequencedetection.log_10000_113_sign_idx in 0.183 s.
21/08/29 05:41:15 INFO TableWriter: Wrote 21 rows to sequencedetection.log_10000_113_sign_idx in 0.209 s.
21/08/29 05:41:22 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:41:23 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_500_740.xes setcontainment
21/08/29 05:41:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 05:41:29 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:41:29 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 05:41:29 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:41:29 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:41:42 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:45:14 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:45:15 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:45:15 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:45:39 INFO TableWriter: Wrote 24304 rows to sequencedetection.log_500_740_set_idx in 25.134 s.
21/08/29 05:45:40 INFO TableWriter: Wrote 24228 rows to sequencedetection.log_500_740_set_idx in 22.245 s.
21/08/29 05:45:41 INFO TableWriter: Wrote 24267 rows to sequencedetection.log_500_740_set_idx in 22.254 s.
21/08/29 05:45:41 INFO TableWriter: Wrote 24205 rows to sequencedetection.log_500_740_set_idx in 21.993 s.
21/08/29 05:45:41 INFO TableWriter: Wrote 24456 rows to sequencedetection.log_500_740_set_idx in 21.626 s.
21/08/29 05:45:41 INFO TableWriter: Wrote 24320 rows to sequencedetection.log_500_740_set_idx in 21.014 s.
21/08/29 05:45:41 INFO TableWriter: Wrote 24216 rows to sequencedetection.log_500_740_set_idx in 20.831 s.
21/08/29 05:45:41 INFO TableWriter: Wrote 24137 rows to sequencedetection.log_500_740_set_idx in 19.972 s.
21/08/29 05:45:41 INFO TableWriter: Wrote 24620 rows to sequencedetection.log_500_740_set_idx in 21.050 s.
21/08/29 05:45:42 INFO TableWriter: Wrote 24227 rows to sequencedetection.log_500_740_set_idx in 18.524 s.
21/08/29 05:45:42 INFO TableWriter: Wrote 24446 rows to sequencedetection.log_500_740_set_idx in 18.680 s.
21/08/29 05:45:42 INFO TableWriter: Wrote 24350 rows to sequencedetection.log_500_740_set_idx in 18.591 s.
21/08/29 05:45:42 INFO TableWriter: Wrote 24306 rows to sequencedetection.log_500_740_set_idx in 18.742 s.
21/08/29 05:45:42 INFO TableWriter: Wrote 24688 rows to sequencedetection.log_500_740_set_idx in 18.450 s.
21/08/29 05:45:43 INFO TableWriter: Wrote 24372 rows to sequencedetection.log_500_740_set_idx in 14.801 s.
21/08/29 05:45:43 INFO TableWriter: Wrote 24345 rows to sequencedetection.log_500_740_set_idx in 14.774 s.
21/08/29 05:45:43 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_740_set_seq in 0.110 s.
21/08/29 05:45:43 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_740_set_seq in 0.141 s.
21/08/29 05:45:43 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_740_set_seq in 0.192 s.
21/08/29 05:45:43 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_740_set_seq in 0.205 s.
21/08/29 05:45:43 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.091 s.
21/08/29 05:45:43 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.105 s.
21/08/29 05:45:43 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.052 s.
21/08/29 05:45:43 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.111 s.
21/08/29 05:45:43 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.050 s.
21/08/29 05:45:43 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.049 s.
21/08/29 05:45:43 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.041 s.
21/08/29 05:45:43 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.084 s.
21/08/29 05:45:43 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.036 s.
21/08/29 05:45:43 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.040 s.
21/08/29 05:45:43 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.034 s.
21/08/29 05:45:43 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.022 s.
21/08/29 05:45:50 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:45:51 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_10000_346.xes setcontainment
21/08/29 05:45:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 05:45:57 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:45:57 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 05:45:58 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:45:58 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:46:05 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:46:24 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:46:24 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:46:24 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:46:31 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:59:40 ERROR Utils: Uncaught exception in thread driver-heartbeater
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/29 05:59:40 ERROR Executor: Exception in task 14.0 in stage 1.0 (TID 30)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/29 05:59:40 ERROR Executor: Exception in task 11.0 in stage 1.0 (TID 27)
java.lang.OutOfMemoryError: Java heap space
21/08/29 05:59:40 ERROR Executor: Exception in task 5.0 in stage 1.0 (TID 21)
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.lang.StringBuilder.toString(StringBuilder.java:407)
	at java.io.ObjectInputStream$BlockDataInputStream.readUTFBody(ObjectInputStream.java:3557)
	at java.io.ObjectInputStream$BlockDataInputStream.readUTF(ObjectInputStream.java:3344)
	at java.io.ObjectInputStream.readString(ObjectInputStream.java:2023)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1649)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
21/08/29 05:59:43 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 21,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.lang.StringBuilder.toString(StringBuilder.java:407)
	at java.io.ObjectInputStream$BlockDataInputStream.readUTFBody(ObjectInputStream.java:3557)
	at java.io.ObjectInputStream$BlockDataInputStream.readUTF(ObjectInputStream.java:3344)
	at java.io.ObjectInputStream.readString(ObjectInputStream.java:2023)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1649)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
21/08/29 05:59:43 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 27,5,main]
java.lang.OutOfMemoryError: Java heap space
21/08/29 05:59:43 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 30,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/29 05:59:43 ERROR TaskSetManager: Task 11 in stage 1.0 failed 1 times; aborting job
21/08/29 05:59:43 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
Exception in thread "main" java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
auth.datalab.sequenceDetection.CassandraConnectionTrait$class.startSpark(CassandraConnectionTrait.scala:54)
auth.datalab.sequenceDetection.SetContainment.CassandraSetContainment.startSpark(CassandraSetContainment.scala:11)
auth.datalab.sequenceDetection.SetContainment.SetContainment$.main(SetContainment.scala:25)
auth.datalab.sequenceDetection.Main$.main(Main.scala:11)
auth.datalab.sequenceDetection.Main.main(Main.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

The currently active SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
auth.datalab.sequenceDetection.CassandraConnectionTrait$class.startSpark(CassandraConnectionTrait.scala:54)
auth.datalab.sequenceDetection.SetContainment.CassandraSetContainment.startSpark(CassandraSetContainment.scala:11)
auth.datalab.sequenceDetection.SetContainment.SetContainment$.main(SetContainment.scala:25)
auth.datalab.sequenceDetection.Main$.main(Main.scala:11)
auth.datalab.sequenceDetection.Main.main(Main.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
         
	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:100)
	at org.apache.spark.sql.SparkSession.<init>(SparkSession.scala:91)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:957)
	at auth.datalab.sequenceDetection.CassandraConnectionTrait$class.closeSpark(CassandraConnectionTrait.scala:74)
	at auth.datalab.sequenceDetection.SetContainment.CassandraSetContainment.closeSpark(CassandraSetContainment.scala:11)
	at auth.datalab.sequenceDetection.SetContainment.SetContainment$.main(SetContainment.scala:53)
	at auth.datalab.sequenceDetection.Main$.main(Main.scala:11)
	at auth.datalab.sequenceDetection.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
log_1000_740.xes setcontainment
21/08/29 05:59:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 05:59:49 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:59:49 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 05:59:49 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:59:49 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 05:59:57 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 05:59:57 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 05:59:57 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 05:59:57 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 06:00:05 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 06:10:58 ERROR Utils: Uncaught exception in thread driver-heartbeater
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.util.regex.Pattern.matcher(Pattern.java:1093)
	at java.util.regex.Pattern.split(Pattern.java:1206)
	at java.lang.String.split(String.java:2380)
	at java.lang.String.split(String.java:2422)
	at scala.concurrent.duration.Duration$.scala$concurrent$duration$Duration$$words(Duration.scala:73)
	at scala.concurrent.duration.Duration$$anonfun$3.apply(Duration.scala:90)
	at scala.concurrent.duration.Duration$$anonfun$3.apply(Duration.scala:90)
	at scala.collection.MapLike$MappedValues.get(MapLike.scala:249)
	at scala.collection.MapLike$class.apply(MapLike.scala:140)
	at scala.collection.AbstractMap.apply(Map.scala:59)
	at scala.concurrent.duration.FiniteDuration.unitString(Duration.scala:601)
	at scala.concurrent.duration.FiniteDuration.toString(Duration.scala:602)
	at java.lang.String.valueOf(String.java:2994)
	at scala.collection.mutable.StringBuilder.append(StringBuilder.scala:200)
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:223)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:227)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:220)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:841)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:870)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:870)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:870)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:870)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/08/29 06:11:22 ERROR Executor: Exception in task 7.0 in stage 1.0 (TID 23)
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at sun.reflect.GeneratedSerializationConstructorAccessor115.newInstance(Unknown Source)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at java.io.ObjectStreamClass.newInstance(ObjectStreamClass.java:1102)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2171)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:158)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:188)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:185)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:156)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
21/08/29 06:11:35 ERROR Executor: Exception in task 8.0 in stage 1.0 (TID 24)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/29 06:12:24 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 24,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/29 06:12:24 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 23,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at sun.reflect.GeneratedSerializationConstructorAccessor115.newInstance(Unknown Source)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at java.io.ObjectStreamClass.newInstance(ObjectStreamClass.java:1102)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2171)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:158)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:188)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:185)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:156)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
21/08/29 06:12:24 ERROR TaskSetManager: Task 8 in stage 1.0 failed 1 times; aborting job
21/08/29 06:12:24 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
21/08/29 06:12:26 ERROR Executor: Exception in task 9.0 in stage 1.0 (TID 25)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/29 06:12:26 ERROR Executor: Exception in task 5.0 in stage 1.0 (TID 21)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/29 06:12:26 ERROR Executor: Exception in task 12.0 in stage 1.0 (TID 28)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/29 06:12:26 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 28,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/29 06:12:26 ERROR Executor: Exception in task 11.0 in stage 1.0 (TID 27)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/29 06:12:26 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 27,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/29 06:12:26 ERROR Executor: Exception in task 4.0 in stage 1.0 (TID 20)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/29 06:12:26 ERROR Executor: Exception in task 15.0 in stage 1.0 (TID 31)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/29 06:12:26 ERROR Executor: Exception in task 0.0 in stage 1.0 (TID 16)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/29 06:12:26 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 31,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/29 06:12:26 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 20,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/29 06:12:26 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 21,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/29 06:12:26 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 16,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/08/29 06:12:26 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 25,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
Exception in thread "main" java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
auth.datalab.sequenceDetection.CassandraConnectionTrait$class.startSpark(CassandraConnectionTrait.scala:54)
auth.datalab.sequenceDetection.SetContainment.CassandraSetContainment.startSpark(CassandraSetContainment.scala:11)
auth.datalab.sequenceDetection.SetContainment.SetContainment$.main(SetContainment.scala:25)
auth.datalab.sequenceDetection.Main$.main(Main.scala:11)
auth.datalab.sequenceDetection.Main.main(Main.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

The currently active SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
auth.datalab.sequenceDetection.CassandraConnectionTrait$class.startSpark(CassandraConnectionTrait.scala:54)
auth.datalab.sequenceDetection.SetContainment.CassandraSetContainment.startSpark(CassandraSetContainment.scala:11)
auth.datalab.sequenceDetection.SetContainment.SetContainment$.main(SetContainment.scala:25)
auth.datalab.sequenceDetection.Main$.main(Main.scala:11)
auth.datalab.sequenceDetection.Main.main(Main.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
         
	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:100)
	at org.apache.spark.sql.SparkSession.<init>(SparkSession.scala:91)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:957)
	at auth.datalab.sequenceDetection.CassandraConnectionTrait$class.closeSpark(CassandraConnectionTrait.scala:74)
	at auth.datalab.sequenceDetection.SetContainment.CassandraSetContainment.closeSpark(CassandraSetContainment.scala:11)
	at auth.datalab.sequenceDetection.SetContainment.SetContainment$.main(SetContainment.scala:53)
	at auth.datalab.sequenceDetection.Main$.main(Main.scala:11)
	at auth.datalab.sequenceDetection.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
log_100000_346.xes setcontainment
21/08/29 06:12:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 06:12:37 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 06:12:37 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 06:12:38 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 06:12:38 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 06:12:46 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 06:47:03 ERROR TaskSchedulerImpl: Lost an executor driver (already removed): Executor heartbeat timed out after 125180 ms
Exception in thread "main" java.lang.OutOfMemoryError: Java heap space
21/08/29 13:22:08 ERROR Inbox: Ignoring error
java.lang.IllegalStateException: Promise already completed.
	at scala.concurrent.Promise$class.complete(Promise.scala:55)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:157)
	at scala.concurrent.Promise$class.success(Promise.scala:86)
	at scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:157)
	at org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)
	at org.apache.spark.rpc.netty.NettyRpcCallContext.sendFailure(NettyRpcCallContext.scala:36)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:110)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/08/29 13:22:08 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_1000_346.xes setcontainment
21/08/29 13:22:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 13:22:13 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 13:22:13 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 13:22:13 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 13:22:13 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 13:22:26 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 13:23:46 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 13:23:46 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 13:23:46 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 13:23:54 INFO TableWriter: Wrote 4281 rows to sequencedetection.log_1000_346_set_idx in 7.229 s.
21/08/29 13:23:54 INFO TableWriter: Wrote 4248 rows to sequencedetection.log_1000_346_set_idx in 7.502 s.
21/08/29 13:23:54 INFO TableWriter: Wrote 4276 rows to sequencedetection.log_1000_346_set_idx in 7.593 s.
21/08/29 13:23:54 INFO TableWriter: Wrote 4314 rows to sequencedetection.log_1000_346_set_idx in 7.850 s.
21/08/29 13:23:54 INFO TableWriter: Wrote 4350 rows to sequencedetection.log_1000_346_set_idx in 7.520 s.
21/08/29 13:23:54 INFO TableWriter: Wrote 4303 rows to sequencedetection.log_1000_346_set_idx in 7.684 s.
21/08/29 13:23:54 INFO TableWriter: Wrote 4235 rows to sequencedetection.log_1000_346_set_idx in 7.560 s.
21/08/29 13:23:54 INFO TableWriter: Wrote 4326 rows to sequencedetection.log_1000_346_set_idx in 7.389 s.
21/08/29 13:23:54 INFO TableWriter: Wrote 4432 rows to sequencedetection.log_1000_346_set_idx in 7.856 s.
21/08/29 13:23:54 INFO TableWriter: Wrote 4433 rows to sequencedetection.log_1000_346_set_idx in 7.269 s.
21/08/29 13:23:54 INFO TableWriter: Wrote 4395 rows to sequencedetection.log_1000_346_set_idx in 7.334 s.
21/08/29 13:23:54 INFO TableWriter: Wrote 4435 rows to sequencedetection.log_1000_346_set_idx in 7.325 s.
21/08/29 13:23:54 INFO TableWriter: Wrote 4287 rows to sequencedetection.log_1000_346_set_idx in 4.784 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 4410 rows to sequencedetection.log_1000_346_set_idx in 4.246 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 4308 rows to sequencedetection.log_1000_346_set_idx in 4.019 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 4399 rows to sequencedetection.log_1000_346_set_idx in 3.681 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_set_seq in 0.185 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_set_seq in 0.200 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_set_seq in 0.212 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_set_seq in 0.213 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_set_seq in 0.215 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_set_seq in 0.218 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_set_seq in 0.220 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_set_seq in 0.219 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_set_seq in 0.224 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_set_seq in 0.224 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_set_seq in 0.227 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_set_seq in 0.218 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_set_seq in 0.217 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_set_seq in 0.229 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_set_seq in 0.219 s.
21/08/29 13:23:55 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_set_seq in 0.231 s.
21/08/29 13:24:02 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 13:24:03 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100_740.xes setcontainment
21/08/29 13:24:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 13:24:09 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 13:24:09 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 13:24:09 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 13:24:09 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 13:24:20 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 13:24:52 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 13:24:52 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 13:24:52 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 13:25:01 INFO TableWriter: Wrote 21506 rows to sequencedetection.log_100_740_set_idx in 9.555 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 21570 rows to sequencedetection.log_100_740_set_idx in 9.579 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 21464 rows to sequencedetection.log_100_740_set_idx in 9.615 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 21470 rows to sequencedetection.log_100_740_set_idx in 9.602 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 21579 rows to sequencedetection.log_100_740_set_idx in 9.629 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 21474 rows to sequencedetection.log_100_740_set_idx in 9.642 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 21519 rows to sequencedetection.log_100_740_set_idx in 9.656 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 21532 rows to sequencedetection.log_100_740_set_idx in 9.642 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 21490 rows to sequencedetection.log_100_740_set_idx in 9.628 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 21615 rows to sequencedetection.log_100_740_set_idx in 9.648 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 21796 rows to sequencedetection.log_100_740_set_idx in 9.630 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 21679 rows to sequencedetection.log_100_740_set_idx in 9.654 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 21592 rows to sequencedetection.log_100_740_set_idx in 9.652 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 21677 rows to sequencedetection.log_100_740_set_idx in 9.610 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 21775 rows to sequencedetection.log_100_740_set_idx in 9.703 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 21962 rows to sequencedetection.log_100_740_set_idx in 9.721 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.058 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_set_seq in 0.066 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.080 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.084 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.082 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.082 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_set_seq in 0.083 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.076 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.082 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_set_seq in 0.081 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.078 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.085 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_set_seq in 0.084 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.086 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.074 s.
21/08/29 13:25:01 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.079 s.
21/08/29 13:25:09 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 13:25:10 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_500_346.xes setcontainment
21/08/29 13:25:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 13:25:15 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 13:25:15 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 13:25:16 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 13:25:16 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 13:25:27 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 13:25:58 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 13:25:58 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 13:25:58 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 13:26:02 INFO TableWriter: Wrote 4281 rows to sequencedetection.log_500_346_set_idx in 4.376 s.
21/08/29 13:26:02 INFO TableWriter: Wrote 4327 rows to sequencedetection.log_500_346_set_idx in 4.375 s.
21/08/29 13:26:02 INFO TableWriter: Wrote 4249 rows to sequencedetection.log_500_346_set_idx in 4.476 s.
21/08/29 13:26:02 INFO TableWriter: Wrote 4296 rows to sequencedetection.log_500_346_set_idx in 4.344 s.
21/08/29 13:26:02 INFO TableWriter: Wrote 4310 rows to sequencedetection.log_500_346_set_idx in 4.374 s.
21/08/29 13:26:02 INFO TableWriter: Wrote 4342 rows to sequencedetection.log_500_346_set_idx in 4.608 s.
21/08/29 13:26:02 INFO TableWriter: Wrote 4339 rows to sequencedetection.log_500_346_set_idx in 4.548 s.
21/08/29 13:26:02 INFO TableWriter: Wrote 4441 rows to sequencedetection.log_500_346_set_idx in 4.179 s.
21/08/29 13:26:02 INFO TableWriter: Wrote 4314 rows to sequencedetection.log_500_346_set_idx in 4.610 s.
21/08/29 13:26:02 INFO TableWriter: Wrote 4341 rows to sequencedetection.log_500_346_set_idx in 4.119 s.
21/08/29 13:26:02 INFO TableWriter: Wrote 4399 rows to sequencedetection.log_500_346_set_idx in 4.437 s.
21/08/29 13:26:02 INFO TableWriter: Wrote 4378 rows to sequencedetection.log_500_346_set_idx in 3.997 s.
21/08/29 13:26:02 INFO TableWriter: Wrote 4439 rows to sequencedetection.log_500_346_set_idx in 4.547 s.
21/08/29 13:26:02 INFO TableWriter: Wrote 4408 rows to sequencedetection.log_500_346_set_idx in 4.173 s.
21/08/29 13:26:02 INFO TableWriter: Wrote 4426 rows to sequencedetection.log_500_346_set_idx in 4.004 s.
21/08/29 13:26:02 INFO TableWriter: Wrote 4458 rows to sequencedetection.log_500_346_set_idx in 4.233 s.
21/08/29 13:26:02 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.097 s.
21/08/29 13:26:02 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.121 s.
21/08/29 13:26:03 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.134 s.
21/08/29 13:26:03 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.127 s.
21/08/29 13:26:03 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_set_seq in 0.131 s.
21/08/29 13:26:03 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.137 s.
21/08/29 13:26:03 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.137 s.
21/08/29 13:26:03 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.129 s.
21/08/29 13:26:03 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.146 s.
21/08/29 13:26:03 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.149 s.
21/08/29 13:26:03 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.153 s.
21/08/29 13:26:03 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.147 s.
21/08/29 13:26:03 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_set_seq in 0.154 s.
21/08/29 13:26:03 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_set_seq in 0.155 s.
21/08/29 13:26:03 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.150 s.
21/08/29 13:26:03 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_set_seq in 0.155 s.
21/08/29 13:26:10 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 13:26:11 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100000_113.xes setcontainment
21/08/29 13:26:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 13:26:16 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 13:26:16 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 13:26:17 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 13:26:17 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 13:26:25 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 13:27:04 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 13:27:04 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 13:27:04 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 13:27:13 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 13:35:32 ERROR Executor: Exception in task 6.0 in stage 1.0 (TID 22)
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$$anonfun$sampleArray$1.apply$mcVI$sp(SizeEstimator.scala:285)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:261)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:165)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
21/08/29 13:35:44 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 22,5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$$anonfun$sampleArray$1.apply$mcVI$sp(SizeEstimator.scala:285)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:261)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:165)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
21/08/29 13:35:44 ERROR TaskSetManager: Task 6 in stage 1.0 failed 1 times; aborting job
21/08/29 13:35:44 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
21/08/29 13:35:56 ERROR TaskSchedulerImpl: Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$4@2a5d14ae rejected from java.util.concurrent.ThreadPoolExecutor@331a565[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 18]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueFailedTask(TaskResultGetter.scala:131)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:560)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:539)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Exception in thread "main" java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
auth.datalab.sequenceDetection.CassandraConnectionTrait$class.startSpark(CassandraConnectionTrait.scala:54)
auth.datalab.sequenceDetection.SetContainment.CassandraSetContainment.startSpark(CassandraSetContainment.scala:11)
auth.datalab.sequenceDetection.SetContainment.SetContainment$.main(SetContainment.scala:25)
auth.datalab.sequenceDetection.Main$.main(Main.scala:11)
auth.datalab.sequenceDetection.Main.main(Main.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

The currently active SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
auth.datalab.sequenceDetection.CassandraConnectionTrait$class.startSpark(CassandraConnectionTrait.scala:54)
auth.datalab.sequenceDetection.SetContainment.CassandraSetContainment.startSpark(CassandraSetContainment.scala:11)
auth.datalab.sequenceDetection.SetContainment.SetContainment$.main(SetContainment.scala:25)
auth.datalab.sequenceDetection.Main$.main(Main.scala:11)
auth.datalab.sequenceDetection.Main.main(Main.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
         
	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:100)
	at org.apache.spark.sql.SparkSession.<init>(SparkSession.scala:91)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:957)
	at auth.datalab.sequenceDetection.CassandraConnectionTrait$class.closeSpark(CassandraConnectionTrait.scala:74)
	at auth.datalab.sequenceDetection.SetContainment.CassandraSetContainment.closeSpark(CassandraSetContainment.scala:11)
	at auth.datalab.sequenceDetection.SetContainment.SetContainment$.main(SetContainment.scala:53)
	at auth.datalab.sequenceDetection.Main$.main(Main.scala:11)
	at auth.datalab.sequenceDetection.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
log_100_113.xes setcontainment
21/08/29 13:36:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 13:36:08 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 13:36:08 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 13:36:09 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 13:36:09 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 13:36:17 INFO TableWriter: Wrote 254 rows to sequencedetection.log_100_113_set_idx in 0.709 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 260 rows to sequencedetection.log_100_113_set_idx in 0.655 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 262 rows to sequencedetection.log_100_113_set_idx in 0.785 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 256 rows to sequencedetection.log_100_113_set_idx in 0.698 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 277 rows to sequencedetection.log_100_113_set_idx in 0.731 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 280 rows to sequencedetection.log_100_113_set_idx in 0.746 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 279 rows to sequencedetection.log_100_113_set_idx in 0.745 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 289 rows to sequencedetection.log_100_113_set_idx in 0.748 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 293 rows to sequencedetection.log_100_113_set_idx in 0.816 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 280 rows to sequencedetection.log_100_113_set_idx in 0.741 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 304 rows to sequencedetection.log_100_113_set_idx in 0.745 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 290 rows to sequencedetection.log_100_113_set_idx in 0.759 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 311 rows to sequencedetection.log_100_113_set_idx in 0.758 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 303 rows to sequencedetection.log_100_113_set_idx in 0.778 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 318 rows to sequencedetection.log_100_113_set_idx in 0.759 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 295 rows to sequencedetection.log_100_113_set_idx in 0.748 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.037 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_set_seq in 0.037 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_set_seq in 0.029 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_set_seq in 0.029 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.033 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.028 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.030 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.032 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.042 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.037 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.034 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.043 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.052 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_set_seq in 0.047 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.052 s.
21/08/29 13:36:17 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.048 s.
21/08/29 13:36:24 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 13:36:25 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_1000_113.xes setcontainment
21/08/29 13:36:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 13:36:31 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 13:36:31 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 13:36:31 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 13:36:31 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 13:36:40 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 13:36:40 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 13:36:40 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 13:36:41 INFO TableWriter: Wrote 292 rows to sequencedetection.log_1000_113_set_idx in 0.789 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 295 rows to sequencedetection.log_1000_113_set_idx in 0.680 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 299 rows to sequencedetection.log_1000_113_set_idx in 0.909 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 311 rows to sequencedetection.log_1000_113_set_idx in 0.893 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 307 rows to sequencedetection.log_1000_113_set_idx in 0.818 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 320 rows to sequencedetection.log_1000_113_set_idx in 0.814 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 322 rows to sequencedetection.log_1000_113_set_idx in 0.809 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 322 rows to sequencedetection.log_1000_113_set_idx in 1.032 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 315 rows to sequencedetection.log_1000_113_set_idx in 0.693 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 323 rows to sequencedetection.log_1000_113_set_idx in 0.760 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 333 rows to sequencedetection.log_1000_113_set_idx in 0.811 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 333 rows to sequencedetection.log_1000_113_set_idx in 0.915 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 355 rows to sequencedetection.log_1000_113_set_idx in 0.842 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 343 rows to sequencedetection.log_1000_113_set_idx in 0.767 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 349 rows to sequencedetection.log_1000_113_set_idx in 0.662 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 342 rows to sequencedetection.log_1000_113_set_idx in 0.633 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_set_seq in 0.050 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_set_seq in 0.055 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_set_seq in 0.076 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_set_seq in 0.099 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_set_seq in 0.120 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_set_seq in 0.130 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_set_seq in 0.130 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_set_seq in 0.125 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_set_seq in 0.134 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_set_seq in 0.130 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_set_seq in 0.129 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_set_seq in 0.143 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_set_seq in 0.132 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_set_seq in 0.136 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_set_seq in 0.133 s.
21/08/29 13:36:41 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_set_seq in 0.146 s.
21/08/29 13:36:42 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 13:36:48 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 13:36:49 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_200000_113.xes setcontainment
21/08/29 13:36:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 13:36:55 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 13:36:55 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 13:36:55 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 13:36:55 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 13:37:03 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 13:38:22 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 13:38:22 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 13:38:22 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 13:38:31 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 13:49:37 ERROR Executor: Exception in task 4.0 in stage 1.0 (TID 20)
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$$anonfun$sampleArray$1.apply$mcVI$sp(SizeEstimator.scala:285)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:262)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:165)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
21/08/29 13:49:42 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 20,5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$$anonfun$sampleArray$1.apply$mcVI$sp(SizeEstimator.scala:285)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:262)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:165)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
21/08/29 13:49:42 ERROR TaskSetManager: Task 4 in stage 1.0 failed 1 times; aborting job
21/08/29 13:49:50 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
Exception in thread "main" java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
auth.datalab.sequenceDetection.CassandraConnectionTrait$class.startSpark(CassandraConnectionTrait.scala:54)
auth.datalab.sequenceDetection.SetContainment.CassandraSetContainment.startSpark(CassandraSetContainment.scala:11)
auth.datalab.sequenceDetection.SetContainment.SetContainment$.main(SetContainment.scala:25)
auth.datalab.sequenceDetection.Main$.main(Main.scala:11)
auth.datalab.sequenceDetection.Main.main(Main.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

The currently active SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
auth.datalab.sequenceDetection.CassandraConnectionTrait$class.startSpark(CassandraConnectionTrait.scala:54)
auth.datalab.sequenceDetection.SetContainment.CassandraSetContainment.startSpark(CassandraSetContainment.scala:11)
auth.datalab.sequenceDetection.SetContainment.SetContainment$.main(SetContainment.scala:25)
auth.datalab.sequenceDetection.Main$.main(Main.scala:11)
auth.datalab.sequenceDetection.Main.main(Main.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
         
	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:100)
	at org.apache.spark.sql.SparkSession.<init>(SparkSession.scala:91)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:957)
	at auth.datalab.sequenceDetection.CassandraConnectionTrait$class.closeSpark(CassandraConnectionTrait.scala:74)
	at auth.datalab.sequenceDetection.SetContainment.CassandraSetContainment.closeSpark(CassandraSetContainment.scala:11)
	at auth.datalab.sequenceDetection.SetContainment.SetContainment$.main(SetContainment.scala:53)
	at auth.datalab.sequenceDetection.Main$.main(Main.scala:11)
	at auth.datalab.sequenceDetection.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
log_100_346.xes setcontainment
21/08/29 13:50:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 13:50:09 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 13:50:09 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 13:50:09 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 13:50:09 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 13:50:21 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 13:50:25 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 13:50:25 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 13:50:25 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 13:50:28 INFO TableWriter: Wrote 3973 rows to sequencedetection.log_100_346_set_idx in 3.044 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 4025 rows to sequencedetection.log_100_346_set_idx in 2.994 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 3989 rows to sequencedetection.log_100_346_set_idx in 3.095 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 4054 rows to sequencedetection.log_100_346_set_idx in 3.103 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 4033 rows to sequencedetection.log_100_346_set_idx in 3.084 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 4039 rows to sequencedetection.log_100_346_set_idx in 3.167 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 4041 rows to sequencedetection.log_100_346_set_idx in 3.101 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 4058 rows to sequencedetection.log_100_346_set_idx in 3.171 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 4045 rows to sequencedetection.log_100_346_set_idx in 3.113 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 4092 rows to sequencedetection.log_100_346_set_idx in 3.087 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 4120 rows to sequencedetection.log_100_346_set_idx in 3.159 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 4115 rows to sequencedetection.log_100_346_set_idx in 3.011 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 4127 rows to sequencedetection.log_100_346_set_idx in 3.130 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 4178 rows to sequencedetection.log_100_346_set_idx in 3.197 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 4192 rows to sequencedetection.log_100_346_set_idx in 3.161 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 4166 rows to sequencedetection.log_100_346_set_idx in 3.126 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.033 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.036 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.036 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.034 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.040 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.037 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.039 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.046 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.046 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_set_seq in 0.049 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_set_seq in 0.049 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.063 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.064 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.065 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_set_seq in 0.065 s.
21/08/29 13:50:28 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_set_seq in 0.064 s.
21/08/29 13:50:36 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 13:50:37 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_10000_740.xes setcontainment
21/08/29 13:50:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 13:50:42 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 13:50:42 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 13:50:43 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 13:50:43 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 13:50:50 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 13:51:35 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 13:51:35 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 13:51:35 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 13:51:42 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 15:25:06 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 15:25:06 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 15:25:06 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 15:25:53 WARN RequestHandler: Not retrying statement because it is not idempotent (this message will be logged only once). Note that this version of the driver changes the default retry behavior for non-idempotent statements: they won't be automatically retried anymore. The driver marks statements non-idempotent by default, so you should explicitly call setIdempotent(true) if your statements are safe to retry. See http://goo.gl/4HrSby for more details.
21/08/29 15:25:53 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@3eca691d
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 18 more
21/08/29 15:25:53 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2b9c90a6
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:25:53 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@1346613
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:25:53 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@1125bd1a
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:25:53 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2ec01036
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:04 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@3bd8e2c5
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:04 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@5fe4f600
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:04 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@1dbc5f99
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:04 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@40bcd12b
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:04 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@4454daa6
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:04 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@22fbf90d
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:04 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@4c469f07
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:04 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@39464f28
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:04 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2708a1e2
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:04 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@1c3055b6
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:04 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@4fe185f7
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@4bf0ba25
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@700d90a2
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@254187a1
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@e85019d
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2077d97b
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@5dc223c5
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@3a70cc92
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2d265476
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@29e218ef
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@70bd85bc
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@119747da
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@3c210bd
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@56d23f1f
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@40f1528d
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@40d4444b
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@61f47b47
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@47270413
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@65a0e524
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@6a057082
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@709f4e6
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@1597944d
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@52560b8d
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@33e95928
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2bdb8f23
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@5cf14e41
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@11f27ced
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@77f68ce0
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@107313f
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@275037d4
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@584efbc8
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:30 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@79d5017d
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:54 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@4c5900be
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:54 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@7721a8ff
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:54 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2611ff34
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:54 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@20b0845b
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:54 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@364d9028
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:54 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@fa8656e
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:54 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@17df7f2e
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:54 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@317fec5a
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:54 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@23a3bea9
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:54 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@3b5bad06
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:54 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@10f64e8a
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:54 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@3c5f5960
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:54 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@7855152e
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:54 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@6b7a9bc
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:54 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@501d595a
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:35:54 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@17c81bad
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:18 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@23359a28
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:18 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@64658169
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:18 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@a8a8af6
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:18 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@62e3d025
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:18 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@629cd0dc
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:18 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@43cce54a
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@5b290704
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@17f38a95
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@4523b572
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@56d88f5a
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@507fcb12
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2e34df85
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@4509b619
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@50df4cce
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@3276b985
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2dfe2c8b
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@7952cf36
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@3e166af7
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@6522b9b4
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@56c801e6
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@286d571f
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@15fa075d
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@5ccdce03
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@4e3bf5a5
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@1b2420b0
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@6d63d82e
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2c2ee37
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@5bec0f37
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:36:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@17e930b2
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:07 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@78aaba4b
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:07 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2a45cf56
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:07 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@6ebb767a
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:07 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@66fcfd74
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:07 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@55d7ca16
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:07 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@1ccac2b
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:07 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2dbc0678
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:07 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@78da7bc9
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:07 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@41b066ee
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:07 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@3e46ebea
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:07 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@31d25013
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:07 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@18a3612a
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:07 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@ed6734c
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:07 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@54f941ce
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:07 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@bf703c8
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:07 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@6e5d3e03
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 18 more
21/08/29 15:37:32 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@560e96a6
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:32 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@142a2498
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:32 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@4c2ec493
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 18 more
21/08/29 15:37:32 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@5cbbefa9
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:32 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@688e1425
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:32 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@3a4afac7
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:32 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@4df4e38c
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:32 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@215d854c
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:32 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2f7c8032
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:32 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@12f5c1d5
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:32 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@285e220c
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:32 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@38959457
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:32 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@3730c2c8
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:32 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@14667677
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:32 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2dbb4cec
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:37:32 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@13502d7f
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/08/29 15:39:15 ERROR Executor: Exception in task 13.0 in stage 1.0 (TID 29)
java.io.IOException: Failed to write statements to sequencedetection.log_10000_740_set_idx. The
latest exception was
  Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)

Please check the executor logs for more exceptions and information
             
	at com.datastax.spark.connector.writer.TableWriter$$anonfun$writeInternal$1$$anonfun$apply$3.apply(TableWriter.scala:243)
	at com.datastax.spark.connector.writer.TableWriter$$anonfun$writeInternal$1$$anonfun$apply$3.apply(TableWriter.scala:241)
	at scala.Option.map(Option.scala:146)
	at com.datastax.spark.connector.writer.TableWriter$$anonfun$writeInternal$1.apply(TableWriter.scala:241)
	at com.datastax.spark.connector.writer.TableWriter$$anonfun$writeInternal$1.apply(TableWriter.scala:210)
	at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$withSessionDo$1.apply(CassandraConnector.scala:112)
	at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$withSessionDo$1.apply(CassandraConnector.scala:111)
	at com.datastax.spark.connector.cql.CassandraConnector.closeResourceAfterUse(CassandraConnector.scala:145)
	at com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:111)
	at com.datastax.spark.connector.writer.TableWriter.writeInternal(TableWriter.scala:210)
	at com.datastax.spark.connector.writer.TableWriter.update(TableWriter.scala:191)
	at com.datastax.spark.connector.writer.TableWriter.write(TableWriter.scala:180)
	at com.datastax.spark.connector.RDDFunctions$$anonfun$saveToCassandra$1.apply(RDDFunctions.scala:36)
	at com.datastax.spark.connector.RDDFunctions$$anonfun$saveToCassandra$1.apply(RDDFunctions.scala:36)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/08/29 15:39:16 ERROR TaskSetManager: Task 13 in stage 1.0 failed 1 times; aborting job
21/08/29 15:39:16 ERROR TaskSchedulerImpl: Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$4@43bbd2 rejected from java.util.concurrent.ThreadPoolExecutor@43edcfa7[Shutting down, pool size = 3, active threads = 2, queued tasks = 0, completed tasks = 22]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueFailedTask(TaskResultGetter.scala:131)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:560)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:539)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/08/29 15:39:16 ERROR TaskSchedulerImpl: Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$4@3ade5f53 rejected from java.util.concurrent.ThreadPoolExecutor@43edcfa7[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 24]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueFailedTask(TaskResultGetter.scala:131)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:560)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:539)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/08/29 15:39:16 ERROR TaskSchedulerImpl: Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$4@94ebeb6 rejected from java.util.concurrent.ThreadPoolExecutor@43edcfa7[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 24]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueFailedTask(TaskResultGetter.scala:131)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:560)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:539)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/08/29 15:39:16 ERROR TaskSchedulerImpl: Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$4@4f982a48 rejected from java.util.concurrent.ThreadPoolExecutor@43edcfa7[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 24]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueFailedTask(TaskResultGetter.scala:131)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:560)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:539)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/08/29 15:39:23 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 15:39:24 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_10000_113.xes setcontainment
21/08/29 15:39:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/08/29 15:39:30 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 15:39:30 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/08/29 15:39:30 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 15:39:30 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 15:39:38 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 15:39:38 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 15:39:38 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 15:39:38 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 15:39:45 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 15:40:13 INFO ClockFactory: Using native clock to generate timestamps.
21/08/29 15:40:13 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/08/29 15:40:13 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/08/29 15:40:16 INFO TableWriter: Wrote 325 rows to sequencedetection.log_10000_113_set_idx in 2.398 s.
21/08/29 15:40:16 INFO TableWriter: Wrote 296 rows to sequencedetection.log_10000_113_set_idx in 1.211 s.
21/08/29 15:40:17 INFO TableWriter: Wrote 314 rows to sequencedetection.log_10000_113_set_idx in 1.040 s.
21/08/29 15:40:17 INFO TableWriter: Wrote 334 rows to sequencedetection.log_10000_113_set_idx in 1.133 s.
21/08/29 15:40:17 INFO TableWriter: Wrote 327 rows to sequencedetection.log_10000_113_set_idx in 1.026 s.
21/08/29 15:40:17 INFO TableWriter: Wrote 311 rows to sequencedetection.log_10000_113_set_idx in 0.796 s.
21/08/29 15:40:17 INFO TableWriter: Wrote 360 rows to sequencedetection.log_10000_113_set_idx in 0.695 s.
21/08/29 15:40:19 INFO TableWriter: Wrote 297 rows to sequencedetection.log_10000_113_set_idx in 0.974 s.
21/08/29 15:40:19 INFO TableWriter: Wrote 302 rows to sequencedetection.log_10000_113_set_idx in 1.000 s.
21/08/29 15:40:19 INFO TableWriter: Wrote 328 rows to sequencedetection.log_10000_113_set_idx in 1.075 s.
21/08/29 15:40:19 INFO TableWriter: Wrote 321 rows to sequencedetection.log_10000_113_set_idx in 0.946 s.
21/08/29 15:40:19 INFO TableWriter: Wrote 349 rows to sequencedetection.log_10000_113_set_idx in 0.647 s.
21/08/29 15:40:19 INFO TableWriter: Wrote 353 rows to sequencedetection.log_10000_113_set_idx in 0.292 s.
21/08/29 15:40:20 INFO TableWriter: Wrote 337 rows to sequencedetection.log_10000_113_set_idx in 0.577 s.
21/08/29 15:40:20 INFO TableWriter: Wrote 321 rows to sequencedetection.log_10000_113_set_idx in 0.582 s.
21/08/29 15:40:20 INFO TableWriter: Wrote 344 rows to sequencedetection.log_10000_113_set_idx in 0.489 s.
21/08/29 15:40:21 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.792 s.
21/08/29 15:40:21 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.783 s.
21/08/29 15:40:21 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.795 s.
21/08/29 15:40:21 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.796 s.
21/08/29 15:40:21 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.818 s.
21/08/29 15:40:21 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.805 s.
21/08/29 15:40:21 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.827 s.
21/08/29 15:40:21 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.818 s.
21/08/29 15:40:21 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.832 s.
21/08/29 15:40:21 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.849 s.
21/08/29 15:40:21 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.835 s.
21/08/29 15:40:21 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.836 s.
21/08/29 15:40:21 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.844 s.
21/08/29 15:40:21 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.848 s.
21/08/29 15:40:21 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.853 s.
21/08/29 15:40:21 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.849 s.
21/08/29 15:40:28 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/08/29 15:40:29 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
