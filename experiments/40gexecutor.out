log_500_740.xes normal
21/09/01 08:06:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 08:06:56 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 08:06:56 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 08:06:57 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 08:06:57 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 08:07:18 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 08:09:43 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 08:09:43 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 08:09:43 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 08:10:43 INFO TableWriter: Wrote 24137 rows to sequencedetection.log_500_740_idx in 59.491 s.
21/09/01 08:10:43 INFO TableWriter: Wrote 24306 rows to sequencedetection.log_500_740_idx in 59.556 s.
21/09/01 08:10:43 INFO TableWriter: Wrote 24216 rows to sequencedetection.log_500_740_idx in 59.585 s.
21/09/01 08:10:43 INFO TableWriter: Wrote 24227 rows to sequencedetection.log_500_740_idx in 59.599 s.
21/09/01 08:10:43 INFO TableWriter: Wrote 24205 rows to sequencedetection.log_500_740_idx in 59.621 s.
21/09/01 08:10:43 INFO TableWriter: Wrote 24372 rows to sequencedetection.log_500_740_idx in 59.743 s.
21/09/01 08:10:43 INFO TableWriter: Wrote 24345 rows to sequencedetection.log_500_740_idx in 59.756 s.
21/09/01 08:10:43 INFO TableWriter: Wrote 24228 rows to sequencedetection.log_500_740_idx in 59.759 s.
21/09/01 08:10:43 INFO TableWriter: Wrote 24446 rows to sequencedetection.log_500_740_idx in 59.765 s.
21/09/01 08:10:43 INFO TableWriter: Wrote 24267 rows to sequencedetection.log_500_740_idx in 59.800 s.
21/09/01 08:10:43 INFO TableWriter: Wrote 24320 rows to sequencedetection.log_500_740_idx in 59.801 s.
21/09/01 08:10:43 INFO TableWriter: Wrote 24304 rows to sequencedetection.log_500_740_idx in 59.816 s.
21/09/01 08:10:43 INFO TableWriter: Wrote 24620 rows to sequencedetection.log_500_740_idx in 59.818 s.
21/09/01 08:10:43 INFO TableWriter: Wrote 24350 rows to sequencedetection.log_500_740_idx in 59.832 s.
21/09/01 08:10:43 INFO TableWriter: Wrote 24456 rows to sequencedetection.log_500_740_idx in 59.842 s.
21/09/01 08:10:43 INFO TableWriter: Wrote 24688 rows to sequencedetection.log_500_740_idx in 59.865 s.
21/09/01 08:10:48 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 08:10:48 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 08:10:48 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 08:10:50 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 08:10:59 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 08:11:18 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 08:11:18 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 08:11:18 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 08:11:19 INFO TableWriter: Wrote 44 rows to sequencedetection.log_500_740_count in 1.028 s.
21/09/01 08:11:19 INFO TableWriter: Wrote 43 rows to sequencedetection.log_500_740_count in 1.035 s.
21/09/01 08:11:19 INFO TableWriter: Wrote 43 rows to sequencedetection.log_500_740_count in 1.071 s.
21/09/01 08:11:19 INFO TableWriter: Wrote 42 rows to sequencedetection.log_500_740_count in 1.069 s.
21/09/01 08:11:19 INFO TableWriter: Wrote 45 rows to sequencedetection.log_500_740_count in 1.192 s.
21/09/01 08:11:19 INFO TableWriter: Wrote 45 rows to sequencedetection.log_500_740_count in 1.217 s.
21/09/01 08:11:19 INFO TableWriter: Wrote 45 rows to sequencedetection.log_500_740_count in 1.228 s.
21/09/01 08:11:19 INFO TableWriter: Wrote 47 rows to sequencedetection.log_500_740_count in 1.243 s.
21/09/01 08:11:19 INFO TableWriter: Wrote 47 rows to sequencedetection.log_500_740_count in 1.292 s.
21/09/01 08:11:19 INFO TableWriter: Wrote 45 rows to sequencedetection.log_500_740_count in 1.299 s.
21/09/01 08:11:19 INFO TableWriter: Wrote 49 rows to sequencedetection.log_500_740_count in 1.307 s.
21/09/01 08:11:19 INFO TableWriter: Wrote 46 rows to sequencedetection.log_500_740_count in 1.308 s.
21/09/01 08:11:19 INFO TableWriter: Wrote 50 rows to sequencedetection.log_500_740_count in 1.318 s.
21/09/01 08:11:19 INFO TableWriter: Wrote 48 rows to sequencedetection.log_500_740_count in 1.319 s.
21/09/01 08:11:19 INFO TableWriter: Wrote 50 rows to sequencedetection.log_500_740_count in 1.370 s.
21/09/01 08:11:19 INFO TableWriter: Wrote 50 rows to sequencedetection.log_500_740_count in 1.380 s.
21/09/01 08:11:20 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_740_seq in 0.211 s.
21/09/01 08:11:20 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_740_seq in 0.220 s.
21/09/01 08:11:20 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_740_seq in 0.223 s.
21/09/01 08:11:20 INFO TableWriter: Wrote 28 rows to sequencedetection.log_500_740_seq in 0.226 s.
21/09/01 08:11:20 INFO TableWriter: Wrote 30 rows to sequencedetection.log_500_740_seq in 0.240 s.
21/09/01 08:11:20 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_740_seq in 0.239 s.
21/09/01 08:11:20 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_740_seq in 0.241 s.
21/09/01 08:11:20 INFO TableWriter: Wrote 30 rows to sequencedetection.log_500_740_seq in 0.253 s.
21/09/01 08:11:20 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_740_seq in 0.262 s.
21/09/01 08:11:20 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_740_seq in 0.270 s.
21/09/01 08:11:20 INFO TableWriter: Wrote 30 rows to sequencedetection.log_500_740_seq in 0.280 s.
21/09/01 08:11:20 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_740_seq in 0.281 s.
21/09/01 08:11:20 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_740_seq in 0.283 s.
21/09/01 08:11:20 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_740_seq in 0.285 s.
21/09/01 08:11:20 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_740_seq in 0.312 s.
21/09/01 08:11:20 INFO TableWriter: Wrote 40 rows to sequencedetection.log_500_740_seq in 0.324 s.
21/09/01 08:11:27 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 08:11:28 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_10000_346.xes normal
21/09/01 08:11:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 08:11:34 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 08:11:35 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 08:11:35 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 08:11:35 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 08:11:46 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 08:12:06 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 08:12:06 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 08:12:06 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 08:12:18 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 08:12:20 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 08:12:20 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 08:12:20 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 08:12:28 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 08:26:52 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 08:26:52 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 08:26:52 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 09:51:36 INFO TableWriter: Wrote 4305 rows to sequencedetection.log_10000_346_idx in 5083.783 s.
21/09/01 09:52:01 INFO TableWriter: Wrote 4372 rows to sequencedetection.log_10000_346_idx in 5109.048 s.
21/09/01 09:52:03 INFO TableWriter: Wrote 4326 rows to sequencedetection.log_10000_346_idx in 5110.345 s.
21/09/01 09:52:03 INFO TableWriter: Wrote 4500 rows to sequencedetection.log_10000_346_idx in 5111.001 s.
21/09/01 09:52:04 INFO TableWriter: Wrote 4508 rows to sequencedetection.log_10000_346_idx in 5111.670 s.
21/09/01 09:52:04 INFO TableWriter: Wrote 4394 rows to sequencedetection.log_10000_346_idx in 5111.734 s.
21/09/01 09:52:04 INFO TableWriter: Wrote 4474 rows to sequencedetection.log_10000_346_idx in 5112.007 s.
21/09/01 09:52:04 INFO TableWriter: Wrote 4390 rows to sequencedetection.log_10000_346_idx in 5112.031 s.
21/09/01 09:52:04 INFO TableWriter: Wrote 4408 rows to sequencedetection.log_10000_346_idx in 5112.169 s.
21/09/01 09:52:06 INFO TableWriter: Wrote 4428 rows to sequencedetection.log_10000_346_idx in 5113.655 s.
21/09/01 09:52:07 INFO TableWriter: Wrote 4360 rows to sequencedetection.log_10000_346_idx in 5114.426 s.
21/09/01 09:52:07 INFO TableWriter: Wrote 4521 rows to sequencedetection.log_10000_346_idx in 5114.526 s.
21/09/01 09:52:21 INFO TableWriter: Wrote 4355 rows to sequencedetection.log_10000_346_idx in 5128.363 s.
21/09/01 09:52:23 INFO TableWriter: Wrote 4392 rows to sequencedetection.log_10000_346_idx in 5131.114 s.
21/09/01 09:52:27 INFO TableWriter: Wrote 4496 rows to sequencedetection.log_10000_346_idx in 5134.374 s.
21/09/01 09:52:29 INFO TableWriter: Wrote 4464 rows to sequencedetection.log_10000_346_idx in 5136.415 s.
21/09/01 09:52:34 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 09:52:34 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 09:52:34 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 09:52:36 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 09:52:41 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 10:38:11 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 10:38:11 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 10:38:11 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 10:38:12 INFO TableWriter: Wrote 20 rows to sequencedetection.log_10000_346_count in 0.219 s.
21/09/01 10:38:12 INFO TableWriter: Wrote 21 rows to sequencedetection.log_10000_346_count in 0.245 s.
21/09/01 10:38:12 INFO TableWriter: Wrote 20 rows to sequencedetection.log_10000_346_count in 0.247 s.
21/09/01 10:38:12 INFO TableWriter: Wrote 21 rows to sequencedetection.log_10000_346_count in 0.250 s.
21/09/01 10:38:12 INFO TableWriter: Wrote 21 rows to sequencedetection.log_10000_346_count in 0.250 s.
21/09/01 10:38:12 INFO TableWriter: Wrote 21 rows to sequencedetection.log_10000_346_count in 0.258 s.
21/09/01 10:38:12 INFO TableWriter: Wrote 22 rows to sequencedetection.log_10000_346_count in 0.258 s.
21/09/01 10:38:12 INFO TableWriter: Wrote 22 rows to sequencedetection.log_10000_346_count in 0.262 s.
21/09/01 10:38:12 INFO TableWriter: Wrote 21 rows to sequencedetection.log_10000_346_count in 0.263 s.
21/09/01 10:38:12 INFO TableWriter: Wrote 21 rows to sequencedetection.log_10000_346_count in 0.267 s.
21/09/01 10:38:12 INFO TableWriter: Wrote 21 rows to sequencedetection.log_10000_346_count in 0.271 s.
21/09/01 10:38:12 INFO TableWriter: Wrote 23 rows to sequencedetection.log_10000_346_count in 0.271 s.
21/09/01 10:38:12 INFO TableWriter: Wrote 23 rows to sequencedetection.log_10000_346_count in 0.274 s.
21/09/01 10:38:12 INFO TableWriter: Wrote 21 rows to sequencedetection.log_10000_346_count in 0.278 s.
21/09/01 10:38:12 INFO TableWriter: Wrote 24 rows to sequencedetection.log_10000_346_count in 0.282 s.
21/09/01 10:38:12 INFO TableWriter: Wrote 23 rows to sequencedetection.log_10000_346_count in 0.297 s.
21/09/01 10:38:27 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_346_seq in 9.736 s.
21/09/01 10:38:27 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_346_seq in 9.743 s.
21/09/01 10:38:27 INFO TableWriter: Wrote 558 rows to sequencedetection.log_10000_346_seq in 10.005 s.
21/09/01 10:38:27 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_346_seq in 10.089 s.
21/09/01 10:38:27 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_346_seq in 10.147 s.
21/09/01 10:38:27 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_346_seq in 10.232 s.
21/09/01 10:38:27 INFO TableWriter: Wrote 558 rows to sequencedetection.log_10000_346_seq in 10.472 s.
21/09/01 10:38:27 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_346_seq in 10.472 s.
21/09/01 10:38:27 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_346_seq in 10.488 s.
21/09/01 10:38:27 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_346_seq in 10.500 s.
21/09/01 10:38:30 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_346_seq in 13.366 s.
21/09/01 10:38:30 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_346_seq in 13.683 s.
21/09/01 10:38:30 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_346_seq in 13.697 s.
21/09/01 10:38:31 INFO TableWriter: Wrote 744 rows to sequencedetection.log_10000_346_seq in 13.755 s.
21/09/01 10:38:31 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_346_seq in 14.164 s.
21/09/01 10:38:31 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_346_seq in 14.309 s.
21/09/01 10:38:38 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 10:38:39 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_1000_740.xes normal
21/09/01 10:38:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 10:38:47 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 10:38:48 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 10:38:48 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 10:38:48 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 10:38:59 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 10:38:59 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 10:38:59 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 10:38:59 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 10:39:14 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 10:45:03 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 10:45:03 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 10:45:03 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 10:47:18 INFO TableWriter: Wrote 24503 rows to sequencedetection.log_1000_740_idx in 135.286 s.
21/09/01 10:47:18 INFO TableWriter: Wrote 24552 rows to sequencedetection.log_1000_740_idx in 135.287 s.
21/09/01 10:47:18 INFO TableWriter: Wrote 24597 rows to sequencedetection.log_1000_740_idx in 135.552 s.
21/09/01 10:47:18 INFO TableWriter: Wrote 24585 rows to sequencedetection.log_1000_740_idx in 135.579 s.
21/09/01 10:47:18 INFO TableWriter: Wrote 24573 rows to sequencedetection.log_1000_740_idx in 135.681 s.
21/09/01 10:47:18 INFO TableWriter: Wrote 24702 rows to sequencedetection.log_1000_740_idx in 135.686 s.
21/09/01 10:47:19 INFO TableWriter: Wrote 24586 rows to sequencedetection.log_1000_740_idx in 135.719 s.
21/09/01 10:47:19 INFO TableWriter: Wrote 24713 rows to sequencedetection.log_1000_740_idx in 135.803 s.
21/09/01 10:47:19 INFO TableWriter: Wrote 24805 rows to sequencedetection.log_1000_740_idx in 135.807 s.
21/09/01 10:47:19 INFO TableWriter: Wrote 24666 rows to sequencedetection.log_1000_740_idx in 135.854 s.
21/09/01 10:47:19 INFO TableWriter: Wrote 24670 rows to sequencedetection.log_1000_740_idx in 135.958 s.
21/09/01 10:47:19 INFO TableWriter: Wrote 24856 rows to sequencedetection.log_1000_740_idx in 135.972 s.
21/09/01 10:47:19 INFO TableWriter: Wrote 24703 rows to sequencedetection.log_1000_740_idx in 135.988 s.
21/09/01 10:47:19 INFO TableWriter: Wrote 24952 rows to sequencedetection.log_1000_740_idx in 136.012 s.
21/09/01 10:47:24 INFO TableWriter: Wrote 25062 rows to sequencedetection.log_1000_740_idx in 141.255 s.
21/09/01 10:47:24 INFO TableWriter: Wrote 24696 rows to sequencedetection.log_1000_740_idx in 141.387 s.
21/09/01 10:47:38 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 10:49:14 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 10:49:14 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 10:49:14 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 10:49:15 INFO TableWriter: Wrote 43 rows to sequencedetection.log_1000_740_count in 1.047 s.
21/09/01 10:49:15 INFO TableWriter: Wrote 42 rows to sequencedetection.log_1000_740_count in 1.071 s.
21/09/01 10:49:15 INFO TableWriter: Wrote 44 rows to sequencedetection.log_1000_740_count in 1.103 s.
21/09/01 10:49:15 INFO TableWriter: Wrote 43 rows to sequencedetection.log_1000_740_count in 1.107 s.
21/09/01 10:49:15 INFO TableWriter: Wrote 45 rows to sequencedetection.log_1000_740_count in 1.233 s.
21/09/01 10:49:15 INFO TableWriter: Wrote 45 rows to sequencedetection.log_1000_740_count in 1.237 s.
21/09/01 10:49:15 INFO TableWriter: Wrote 46 rows to sequencedetection.log_1000_740_count in 1.259 s.
21/09/01 10:49:15 INFO TableWriter: Wrote 47 rows to sequencedetection.log_1000_740_count in 1.335 s.
21/09/01 10:49:15 INFO TableWriter: Wrote 47 rows to sequencedetection.log_1000_740_count in 1.354 s.
21/09/01 10:49:15 INFO TableWriter: Wrote 50 rows to sequencedetection.log_1000_740_count in 1.369 s.
21/09/01 10:49:15 INFO TableWriter: Wrote 45 rows to sequencedetection.log_1000_740_count in 1.375 s.
21/09/01 10:49:15 INFO TableWriter: Wrote 45 rows to sequencedetection.log_1000_740_count in 1.384 s.
21/09/01 10:49:15 INFO TableWriter: Wrote 49 rows to sequencedetection.log_1000_740_count in 1.386 s.
21/09/01 10:49:15 INFO TableWriter: Wrote 48 rows to sequencedetection.log_1000_740_count in 1.387 s.
21/09/01 10:49:15 INFO TableWriter: Wrote 50 rows to sequencedetection.log_1000_740_count in 1.392 s.
21/09/01 10:49:15 INFO TableWriter: Wrote 50 rows to sequencedetection.log_1000_740_count in 1.426 s.
21/09/01 10:49:21 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_740_seq in 0.586 s.
21/09/01 10:49:21 INFO TableWriter: Wrote 55 rows to sequencedetection.log_1000_740_seq in 0.617 s.
21/09/01 10:49:21 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_740_seq in 0.676 s.
21/09/01 10:49:21 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_740_seq in 0.705 s.
21/09/01 10:49:21 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_740_seq in 0.728 s.
21/09/01 10:49:21 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_740_seq in 0.741 s.
21/09/01 10:49:21 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_740_seq in 0.744 s.
21/09/01 10:49:21 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_740_seq in 0.747 s.
21/09/01 10:49:21 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_740_seq in 0.749 s.
21/09/01 10:49:21 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_740_seq in 0.746 s.
21/09/01 10:49:21 INFO TableWriter: Wrote 76 rows to sequencedetection.log_1000_740_seq in 0.956 s.
21/09/01 10:49:21 INFO TableWriter: Wrote 76 rows to sequencedetection.log_1000_740_seq in 1.108 s.
21/09/01 10:49:21 INFO TableWriter: Wrote 72 rows to sequencedetection.log_1000_740_seq in 1.131 s.
21/09/01 10:49:21 INFO TableWriter: Wrote 76 rows to sequencedetection.log_1000_740_seq in 1.168 s.
21/09/01 10:49:21 INFO TableWriter: Wrote 72 rows to sequencedetection.log_1000_740_seq in 1.171 s.
21/09/01 10:49:21 INFO TableWriter: Wrote 72 rows to sequencedetection.log_1000_740_seq in 1.226 s.
21/09/01 10:49:29 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 10:49:30 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100000_346.xes normal
21/09/01 10:49:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 10:49:37 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 10:49:37 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 10:49:38 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 10:49:38 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 10:49:49 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 10:53:49 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 10:53:49 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 10:53:49 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 10:54:05 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 10:54:47 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 10:54:47 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 10:54:47 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 10:54:54 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 13:04:42 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 13:04:42 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 13:04:42 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:18:49 ERROR TaskSchedulerImpl: Lost executor driver on localhost: Executor heartbeat timed out after 149152 ms
21/09/01 14:18:49 ERROR Executor: Exception in task 6.0 in stage 5.0 (TID 130)
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$$anonfun$sampleArray$1.apply$mcVI$sp(SizeEstimator.scala:285)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:262)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:165)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
21/09/01 14:18:49 ERROR TaskSetManager: Task 13 in stage 5.0 failed 1 times; aborting job
21/09/01 14:18:49 ERROR TaskSchedulerImpl: Ignoring update with state FAILED for TID 130 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
21/09/01 14:18:49 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 130,5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$$anonfun$sampleArray$1.apply$mcVI$sp(SizeEstimator.scala:285)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:262)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:165)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
21/09/01 14:18:49 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_1000_346.xes normal
21/09/01 14:19:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 14:19:16 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:19:17 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 14:19:17 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:19:17 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:19:38 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 14:20:35 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:20:35 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:20:35 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:20:51 INFO TableWriter: Wrote 4248 rows to sequencedetection.log_1000_346_idx in 15.546 s.
21/09/01 14:20:51 INFO TableWriter: Wrote 4235 rows to sequencedetection.log_1000_346_idx in 15.570 s.
21/09/01 14:20:51 INFO TableWriter: Wrote 4314 rows to sequencedetection.log_1000_346_idx in 15.615 s.
21/09/01 14:20:51 INFO TableWriter: Wrote 4276 rows to sequencedetection.log_1000_346_idx in 15.679 s.
21/09/01 14:20:51 INFO TableWriter: Wrote 4281 rows to sequencedetection.log_1000_346_idx in 15.691 s.
21/09/01 14:20:51 INFO TableWriter: Wrote 4303 rows to sequencedetection.log_1000_346_idx in 15.691 s.
21/09/01 14:20:51 INFO TableWriter: Wrote 4308 rows to sequencedetection.log_1000_346_idx in 15.696 s.
21/09/01 14:20:51 INFO TableWriter: Wrote 4287 rows to sequencedetection.log_1000_346_idx in 15.714 s.
21/09/01 14:20:51 INFO TableWriter: Wrote 4433 rows to sequencedetection.log_1000_346_idx in 15.730 s.
21/09/01 14:20:51 INFO TableWriter: Wrote 4326 rows to sequencedetection.log_1000_346_idx in 15.746 s.
21/09/01 14:20:51 INFO TableWriter: Wrote 4432 rows to sequencedetection.log_1000_346_idx in 15.757 s.
21/09/01 14:20:51 INFO TableWriter: Wrote 4395 rows to sequencedetection.log_1000_346_idx in 15.758 s.
21/09/01 14:20:51 INFO TableWriter: Wrote 4410 rows to sequencedetection.log_1000_346_idx in 15.769 s.
21/09/01 14:20:51 INFO TableWriter: Wrote 4399 rows to sequencedetection.log_1000_346_idx in 15.780 s.
21/09/01 14:20:51 INFO TableWriter: Wrote 4350 rows to sequencedetection.log_1000_346_idx in 15.781 s.
21/09/01 14:20:51 INFO TableWriter: Wrote 4435 rows to sequencedetection.log_1000_346_idx in 15.794 s.
21/09/01 14:20:56 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:20:56 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:20:56 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:20:58 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 14:21:05 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:21:05 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:21:05 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:21:05 INFO TableWriter: Wrote 20 rows to sequencedetection.log_1000_346_count in 0.230 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 22 rows to sequencedetection.log_1000_346_count in 0.246 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 21 rows to sequencedetection.log_1000_346_count in 0.250 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 23 rows to sequencedetection.log_1000_346_count in 0.277 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 21 rows to sequencedetection.log_1000_346_count in 0.293 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 21 rows to sequencedetection.log_1000_346_count in 0.293 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 23 rows to sequencedetection.log_1000_346_count in 0.298 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 21 rows to sequencedetection.log_1000_346_count in 0.301 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 20 rows to sequencedetection.log_1000_346_count in 0.306 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 21 rows to sequencedetection.log_1000_346_count in 0.303 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 22 rows to sequencedetection.log_1000_346_count in 0.309 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 23 rows to sequencedetection.log_1000_346_count in 0.309 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 21 rows to sequencedetection.log_1000_346_count in 0.309 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 21 rows to sequencedetection.log_1000_346_count in 0.310 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 21 rows to sequencedetection.log_1000_346_count in 0.312 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 24 rows to sequencedetection.log_1000_346_count in 0.314 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_346_seq in 0.455 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_346_seq in 0.463 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_346_seq in 0.481 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_346_seq in 0.505 s.
21/09/01 14:21:06 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 14:21:06 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_346_seq in 0.517 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_346_seq in 0.517 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 55 rows to sequencedetection.log_1000_346_seq in 0.527 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_346_seq in 0.525 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_346_seq in 0.527 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_346_seq in 0.531 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 72 rows to sequencedetection.log_1000_346_seq in 0.540 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 72 rows to sequencedetection.log_1000_346_seq in 0.541 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 72 rows to sequencedetection.log_1000_346_seq in 0.544 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 76 rows to sequencedetection.log_1000_346_seq in 0.544 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 76 rows to sequencedetection.log_1000_346_seq in 0.544 s.
21/09/01 14:21:06 INFO TableWriter: Wrote 76 rows to sequencedetection.log_1000_346_seq in 0.545 s.
21/09/01 14:21:13 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 14:21:14 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100_740.xes normal
21/09/01 14:21:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 14:21:21 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:21:21 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 14:21:21 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:21:21 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:21:41 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 14:22:16 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:22:16 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:22:16 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:22:32 INFO TableWriter: Wrote 21470 rows to sequencedetection.log_100_740_idx in 15.797 s.
21/09/01 14:22:32 INFO TableWriter: Wrote 21474 rows to sequencedetection.log_100_740_idx in 15.819 s.
21/09/01 14:22:32 INFO TableWriter: Wrote 21464 rows to sequencedetection.log_100_740_idx in 15.827 s.
21/09/01 14:22:32 INFO TableWriter: Wrote 21490 rows to sequencedetection.log_100_740_idx in 15.826 s.
21/09/01 14:22:32 INFO TableWriter: Wrote 21579 rows to sequencedetection.log_100_740_idx in 15.844 s.
21/09/01 14:22:32 INFO TableWriter: Wrote 21592 rows to sequencedetection.log_100_740_idx in 15.859 s.
21/09/01 14:22:32 INFO TableWriter: Wrote 21519 rows to sequencedetection.log_100_740_idx in 15.861 s.
21/09/01 14:22:32 INFO TableWriter: Wrote 21506 rows to sequencedetection.log_100_740_idx in 15.864 s.
21/09/01 14:22:32 INFO TableWriter: Wrote 21532 rows to sequencedetection.log_100_740_idx in 15.868 s.
21/09/01 14:22:32 INFO TableWriter: Wrote 21615 rows to sequencedetection.log_100_740_idx in 15.881 s.
21/09/01 14:22:32 INFO TableWriter: Wrote 21570 rows to sequencedetection.log_100_740_idx in 15.887 s.
21/09/01 14:22:32 INFO TableWriter: Wrote 21796 rows to sequencedetection.log_100_740_idx in 15.896 s.
21/09/01 14:22:32 INFO TableWriter: Wrote 21677 rows to sequencedetection.log_100_740_idx in 15.903 s.
21/09/01 14:22:32 INFO TableWriter: Wrote 21775 rows to sequencedetection.log_100_740_idx in 15.908 s.
21/09/01 14:22:32 INFO TableWriter: Wrote 21679 rows to sequencedetection.log_100_740_idx in 15.938 s.
21/09/01 14:22:32 INFO TableWriter: Wrote 21962 rows to sequencedetection.log_100_740_idx in 15.947 s.
21/09/01 14:22:44 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:22:44 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:22:44 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:22:45 INFO TableWriter: Wrote 40 rows to sequencedetection.log_100_740_count in 0.876 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 44 rows to sequencedetection.log_100_740_count in 0.905 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 43 rows to sequencedetection.log_100_740_count in 0.922 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 43 rows to sequencedetection.log_100_740_count in 0.937 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 46 rows to sequencedetection.log_100_740_count in 1.063 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 47 rows to sequencedetection.log_100_740_count in 1.127 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 47 rows to sequencedetection.log_100_740_count in 1.173 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 50 rows to sequencedetection.log_100_740_count in 1.173 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 49 rows to sequencedetection.log_100_740_count in 1.180 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 45 rows to sequencedetection.log_100_740_count in 1.181 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 45 rows to sequencedetection.log_100_740_count in 1.204 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 49 rows to sequencedetection.log_100_740_count in 1.330 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 45 rows to sequencedetection.log_100_740_count in 1.334 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 48 rows to sequencedetection.log_100_740_count in 1.347 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 45 rows to sequencedetection.log_100_740_count in 1.348 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 50 rows to sequencedetection.log_100_740_count in 1.349 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_740_seq in 0.038 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_seq in 0.041 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_seq in 0.047 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_seq in 0.050 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_seq in 0.049 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_seq in 0.052 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_740_seq in 0.053 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_seq in 0.057 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_740_seq in 0.059 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_seq in 0.062 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_740_seq in 0.064 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 3 rows to sequencedetection.log_100_740_seq in 0.064 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_seq in 0.067 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_seq in 0.067 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_seq in 0.067 s.
21/09/01 14:22:45 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_740_seq in 0.079 s.
21/09/01 14:22:45 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 14:22:52 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 14:22:53 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_500_346.xes normal
21/09/01 14:22:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 14:23:00 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:23:00 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 14:23:00 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:23:00 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:23:21 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 14:23:52 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:23:52 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:23:52 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:24:01 INFO TableWriter: Wrote 4314 rows to sequencedetection.log_500_346_idx in 9.122 s.
21/09/01 14:24:01 INFO TableWriter: Wrote 4281 rows to sequencedetection.log_500_346_idx in 9.125 s.
21/09/01 14:24:01 INFO TableWriter: Wrote 4342 rows to sequencedetection.log_500_346_idx in 9.128 s.
21/09/01 14:24:01 INFO TableWriter: Wrote 4249 rows to sequencedetection.log_500_346_idx in 9.137 s.
21/09/01 14:24:01 INFO TableWriter: Wrote 4310 rows to sequencedetection.log_500_346_idx in 9.170 s.
21/09/01 14:24:01 INFO TableWriter: Wrote 4296 rows to sequencedetection.log_500_346_idx in 9.187 s.
21/09/01 14:24:01 INFO TableWriter: Wrote 4339 rows to sequencedetection.log_500_346_idx in 9.190 s.
21/09/01 14:24:01 INFO TableWriter: Wrote 4327 rows to sequencedetection.log_500_346_idx in 9.194 s.
21/09/01 14:24:01 INFO TableWriter: Wrote 4426 rows to sequencedetection.log_500_346_idx in 9.195 s.
21/09/01 14:24:01 INFO TableWriter: Wrote 4341 rows to sequencedetection.log_500_346_idx in 9.207 s.
21/09/01 14:24:01 INFO TableWriter: Wrote 4439 rows to sequencedetection.log_500_346_idx in 9.208 s.
21/09/01 14:24:01 INFO TableWriter: Wrote 4441 rows to sequencedetection.log_500_346_idx in 9.215 s.
21/09/01 14:24:01 INFO TableWriter: Wrote 4408 rows to sequencedetection.log_500_346_idx in 9.220 s.
21/09/01 14:24:01 INFO TableWriter: Wrote 4399 rows to sequencedetection.log_500_346_idx in 9.226 s.
21/09/01 14:24:01 INFO TableWriter: Wrote 4378 rows to sequencedetection.log_500_346_idx in 9.227 s.
21/09/01 14:24:01 INFO TableWriter: Wrote 4458 rows to sequencedetection.log_500_346_idx in 9.237 s.
21/09/01 14:24:07 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:24:07 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:24:07 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:24:07 INFO TableWriter: Wrote 23 rows to sequencedetection.log_500_346_count in 0.282 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 20 rows to sequencedetection.log_500_346_count in 0.289 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 22 rows to sequencedetection.log_500_346_count in 0.303 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 21 rows to sequencedetection.log_500_346_count in 0.310 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 23 rows to sequencedetection.log_500_346_count in 0.314 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 21 rows to sequencedetection.log_500_346_count in 0.315 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 21 rows to sequencedetection.log_500_346_count in 0.313 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 21 rows to sequencedetection.log_500_346_count in 0.316 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 23 rows to sequencedetection.log_500_346_count in 0.317 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 21 rows to sequencedetection.log_500_346_count in 0.318 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 24 rows to sequencedetection.log_500_346_count in 0.333 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 22 rows to sequencedetection.log_500_346_count in 0.332 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 20 rows to sequencedetection.log_500_346_count in 0.334 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 21 rows to sequencedetection.log_500_346_count in 0.340 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 21 rows to sequencedetection.log_500_346_count in 0.341 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 21 rows to sequencedetection.log_500_346_count in 0.346 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_346_seq in 0.122 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_346_seq in 0.154 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_346_seq in 0.198 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_346_seq in 0.198 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 30 rows to sequencedetection.log_500_346_seq in 0.200 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 30 rows to sequencedetection.log_500_346_seq in 0.202 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 28 rows to sequencedetection.log_500_346_seq in 0.205 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 30 rows to sequencedetection.log_500_346_seq in 0.204 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_346_seq in 0.200 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 40 rows to sequencedetection.log_500_346_seq in 0.207 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_346_seq in 0.210 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_346_seq in 0.211 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_346_seq in 0.212 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_346_seq in 0.215 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_346_seq in 0.216 s.
21/09/01 14:24:07 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_346_seq in 0.239 s.
21/09/01 14:24:09 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 14:24:15 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 14:24:16 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100000_113.xes normal
21/09/01 14:24:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 14:24:22 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:24:22 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 14:24:23 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:24:23 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:24:34 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 14:25:12 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:25:12 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:25:12 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:25:25 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 14:25:26 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:25:26 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:25:26 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:25:34 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 14:35:02 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:35:02 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:35:02 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:36:06 INFO TableWriter: Wrote 360 rows to sequencedetection.log_100000_113_idx in 64.525 s.
21/09/01 14:36:20 INFO TableWriter: Wrote 296 rows to sequencedetection.log_100000_113_idx in 78.549 s.
21/09/01 14:36:35 INFO TableWriter: Wrote 314 rows to sequencedetection.log_100000_113_idx in 93.423 s.
21/09/01 14:36:49 INFO TableWriter: Wrote 326 rows to sequencedetection.log_100000_113_idx in 107.940 s.
21/09/01 14:36:55 INFO TableWriter: Wrote 311 rows to sequencedetection.log_100000_113_idx in 113.067 s.
21/09/01 14:36:58 INFO TableWriter: Wrote 337 rows to sequencedetection.log_100000_113_idx in 116.797 s.
21/09/01 14:37:01 INFO TableWriter: Wrote 353 rows to sequencedetection.log_100000_113_idx in 119.681 s.
21/09/01 14:37:03 INFO TableWriter: Wrote 327 rows to sequencedetection.log_100000_113_idx in 121.851 s.
21/09/01 14:37:08 INFO TableWriter: Wrote 329 rows to sequencedetection.log_100000_113_idx in 126.033 s.
21/09/01 14:37:15 WARN RequestHandler: Not retrying statement because it is not idempotent (this message will be logged only once). Note that this version of the driver changes the default retry behavior for non-idempotent statements: they won't be automatically retried anymore. The driver marks statements non-idempotent by default, so you should explicitly call setIdempotent(true) if your statements are safe to retry. See http://goo.gl/4HrSby for more details.
21/09/01 14:37:15 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@29b79264
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 14:37:15 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2856637a
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 14:37:15 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@1ec49ec7
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 14:37:15 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@70c1d10e
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 14:37:15 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@5be68fea
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 14:37:15 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@613d62c1
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 14:37:15 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@1de383ab
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 14:37:15 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@4d2c4aa6
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 14:37:15 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@4af337a6
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 14:37:15 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@17a19e9a
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 14:37:15 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2f71302c
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 14:37:15 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@5ceae16c
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 14:37:17 ERROR Executor: Exception in task 14.0 in stage 5.0 (TID 138)
java.io.IOException: Failed to write statements to sequencedetection.log_100000_113_idx. The
latest exception was
  Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)

Please check the executor logs for more exceptions and information
             
	at com.datastax.spark.connector.writer.TableWriter$$anonfun$writeInternal$1$$anonfun$apply$3.apply(TableWriter.scala:243)
	at com.datastax.spark.connector.writer.TableWriter$$anonfun$writeInternal$1$$anonfun$apply$3.apply(TableWriter.scala:241)
	at scala.Option.map(Option.scala:146)
	at com.datastax.spark.connector.writer.TableWriter$$anonfun$writeInternal$1.apply(TableWriter.scala:241)
	at com.datastax.spark.connector.writer.TableWriter$$anonfun$writeInternal$1.apply(TableWriter.scala:210)
	at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$withSessionDo$1.apply(CassandraConnector.scala:112)
	at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$withSessionDo$1.apply(CassandraConnector.scala:111)
	at com.datastax.spark.connector.cql.CassandraConnector.closeResourceAfterUse(CassandraConnector.scala:145)
	at com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:111)
	at com.datastax.spark.connector.writer.TableWriter.writeInternal(TableWriter.scala:210)
	at com.datastax.spark.connector.writer.TableWriter.update(TableWriter.scala:191)
	at com.datastax.spark.connector.writer.TableWriter.write(TableWriter.scala:180)
	at com.datastax.spark.connector.RDDFunctions$$anonfun$saveToCassandra$1.apply(RDDFunctions.scala:36)
	at com.datastax.spark.connector.RDDFunctions$$anonfun$saveToCassandra$1.apply(RDDFunctions.scala:36)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/09/01 14:37:17 ERROR TaskSetManager: Task 14 in stage 5.0 failed 1 times; aborting job
21/09/01 14:37:17 ERROR TaskSchedulerImpl: Exception in statusUpdate
java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$4@5244c2f3 rejected from java.util.concurrent.ThreadPoolExecutor@2ab390f3[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 138]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at org.apache.spark.scheduler.TaskResultGetter.enqueueFailedTask(TaskResultGetter.scala:131)
	at org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:560)
	at org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:539)
	at org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:67)
	at org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)
	at org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)
	at org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)
	at org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:221)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/09/01 14:37:24 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 14:37:25 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100_113.xes normal
21/09/01 14:37:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 14:37:36 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:37:37 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 14:37:37 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:37:37 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:37:49 INFO TableWriter: Wrote 262 rows to sequencedetection.log_100_113_idx in 0.850 s.
21/09/01 14:37:49 INFO TableWriter: Wrote 256 rows to sequencedetection.log_100_113_idx in 0.854 s.
21/09/01 14:37:49 INFO TableWriter: Wrote 254 rows to sequencedetection.log_100_113_idx in 0.858 s.
21/09/01 14:37:49 INFO TableWriter: Wrote 260 rows to sequencedetection.log_100_113_idx in 0.867 s.
21/09/01 14:37:49 INFO TableWriter: Wrote 277 rows to sequencedetection.log_100_113_idx in 0.871 s.
21/09/01 14:37:49 INFO TableWriter: Wrote 280 rows to sequencedetection.log_100_113_idx in 0.875 s.
21/09/01 14:37:49 INFO TableWriter: Wrote 290 rows to sequencedetection.log_100_113_idx in 0.878 s.
21/09/01 14:37:49 INFO TableWriter: Wrote 279 rows to sequencedetection.log_100_113_idx in 0.879 s.
21/09/01 14:37:49 INFO TableWriter: Wrote 280 rows to sequencedetection.log_100_113_idx in 0.878 s.
21/09/01 14:37:49 INFO TableWriter: Wrote 289 rows to sequencedetection.log_100_113_idx in 0.885 s.
21/09/01 14:37:49 INFO TableWriter: Wrote 293 rows to sequencedetection.log_100_113_idx in 0.885 s.
21/09/01 14:37:49 INFO TableWriter: Wrote 295 rows to sequencedetection.log_100_113_idx in 0.887 s.
21/09/01 14:37:49 INFO TableWriter: Wrote 303 rows to sequencedetection.log_100_113_idx in 0.891 s.
21/09/01 14:37:49 INFO TableWriter: Wrote 304 rows to sequencedetection.log_100_113_idx in 0.893 s.
21/09/01 14:37:49 INFO TableWriter: Wrote 311 rows to sequencedetection.log_100_113_idx in 0.894 s.
21/09/01 14:37:49 INFO TableWriter: Wrote 318 rows to sequencedetection.log_100_113_idx in 0.897 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_113_count in 0.034 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_count in 0.045 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100_113_count in 0.043 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100_113_count in 0.047 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_113_count in 0.049 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_113_count in 0.050 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100_113_count in 0.052 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_count in 0.049 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_113_count in 0.052 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_113_count in 0.054 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_113_count in 0.063 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100_113_count in 0.056 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_113_count in 0.062 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100_113_count in 0.062 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_113_count in 0.067 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_113_count in 0.065 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 3 rows to sequencedetection.log_100_113_seq in 0.025 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_seq in 0.025 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_seq in 0.026 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_seq in 0.027 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_seq in 0.034 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_seq in 0.032 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_seq in 0.033 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_seq in 0.033 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_113_seq in 0.033 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_113_seq in 0.034 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_113_seq in 0.035 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_seq in 0.035 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_seq in 0.036 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_seq in 0.038 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_113_seq in 0.039 s.
21/09/01 14:37:50 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_113_seq in 0.040 s.
21/09/01 14:37:57 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 14:37:58 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_1000_113.xes normal
21/09/01 14:38:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 14:38:03 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:38:03 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 14:38:04 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:38:04 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:38:19 INFO TableWriter: Wrote 292 rows to sequencedetection.log_1000_113_idx in 1.421 s.
21/09/01 14:38:19 INFO TableWriter: Wrote 311 rows to sequencedetection.log_1000_113_idx in 1.437 s.
21/09/01 14:38:19 INFO TableWriter: Wrote 295 rows to sequencedetection.log_1000_113_idx in 1.449 s.
21/09/01 14:38:19 INFO TableWriter: Wrote 299 rows to sequencedetection.log_1000_113_idx in 1.455 s.
21/09/01 14:38:19 INFO TableWriter: Wrote 307 rows to sequencedetection.log_1000_113_idx in 1.455 s.
21/09/01 14:38:19 INFO TableWriter: Wrote 322 rows to sequencedetection.log_1000_113_idx in 1.456 s.
21/09/01 14:38:19 INFO TableWriter: Wrote 333 rows to sequencedetection.log_1000_113_idx in 1.472 s.
21/09/01 14:38:19 INFO TableWriter: Wrote 322 rows to sequencedetection.log_1000_113_idx in 1.481 s.
21/09/01 14:38:19 INFO TableWriter: Wrote 320 rows to sequencedetection.log_1000_113_idx in 1.482 s.
21/09/01 14:38:19 INFO TableWriter: Wrote 333 rows to sequencedetection.log_1000_113_idx in 1.489 s.
21/09/01 14:38:19 INFO TableWriter: Wrote 323 rows to sequencedetection.log_1000_113_idx in 1.491 s.
21/09/01 14:38:19 INFO TableWriter: Wrote 315 rows to sequencedetection.log_1000_113_idx in 1.493 s.
21/09/01 14:38:19 INFO TableWriter: Wrote 355 rows to sequencedetection.log_1000_113_idx in 1.494 s.
21/09/01 14:38:19 INFO TableWriter: Wrote 349 rows to sequencedetection.log_1000_113_idx in 1.501 s.
21/09/01 14:38:19 INFO TableWriter: Wrote 343 rows to sequencedetection.log_1000_113_idx in 1.503 s.
21/09/01 14:38:19 INFO TableWriter: Wrote 342 rows to sequencedetection.log_1000_113_idx in 1.510 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 4 rows to sequencedetection.log_1000_113_count in 0.038 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 8 rows to sequencedetection.log_1000_113_count in 0.039 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 4 rows to sequencedetection.log_1000_113_count in 0.043 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 9 rows to sequencedetection.log_1000_113_count in 0.041 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 8 rows to sequencedetection.log_1000_113_count in 0.041 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 8 rows to sequencedetection.log_1000_113_count in 0.051 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 9 rows to sequencedetection.log_1000_113_count in 0.053 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 9 rows to sequencedetection.log_1000_113_count in 0.053 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 8 rows to sequencedetection.log_1000_113_count in 0.053 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 4 rows to sequencedetection.log_1000_113_count in 0.051 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 9 rows to sequencedetection.log_1000_113_count in 0.054 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 6 rows to sequencedetection.log_1000_113_count in 0.057 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 5 rows to sequencedetection.log_1000_113_count in 0.056 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 7 rows to sequencedetection.log_1000_113_count in 0.060 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 5 rows to sequencedetection.log_1000_113_count in 0.062 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 9 rows to sequencedetection.log_1000_113_count in 0.061 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_113_seq in 0.101 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_113_seq in 0.133 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_113_seq in 0.135 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_113_seq in 0.141 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_113_seq in 0.141 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_113_seq in 0.141 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 72 rows to sequencedetection.log_1000_113_seq in 0.146 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 55 rows to sequencedetection.log_1000_113_seq in 0.155 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 76 rows to sequencedetection.log_1000_113_seq in 0.156 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 54 rows to sequencedetection.log_1000_113_seq in 0.157 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_113_seq in 0.157 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 72 rows to sequencedetection.log_1000_113_seq in 0.162 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 76 rows to sequencedetection.log_1000_113_seq in 0.159 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 57 rows to sequencedetection.log_1000_113_seq in 0.163 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 72 rows to sequencedetection.log_1000_113_seq in 0.168 s.
21/09/01 14:38:20 INFO TableWriter: Wrote 76 rows to sequencedetection.log_1000_113_seq in 0.167 s.
21/09/01 14:38:28 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 14:38:29 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_200000_113.xes normal
21/09/01 14:38:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 14:38:34 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:38:34 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 14:38:35 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:38:35 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:38:45 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 14:40:12 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:40:12 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:40:12 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:40:25 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 14:40:33 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 14:40:33 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 14:40:33 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 14:40:40 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 15:14:03 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 15:14:03 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 15:14:03 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 15:16:25 INFO TableWriter: Wrote 360 rows to sequencedetection.log_200000_113_idx in 141.827 s.
21/09/01 15:16:50 INFO TableWriter: Wrote 296 rows to sequencedetection.log_200000_113_idx in 167.028 s.
21/09/01 15:17:20 INFO TableWriter: Wrote 314 rows to sequencedetection.log_200000_113_idx in 197.223 s.
21/09/01 15:17:42 INFO TableWriter: Wrote 326 rows to sequencedetection.log_200000_113_idx in 219.139 s.
21/09/01 15:18:13 INFO TableWriter: Wrote 311 rows to sequencedetection.log_200000_113_idx in 250.539 s.
21/09/01 15:18:17 INFO TableWriter: Wrote 337 rows to sequencedetection.log_200000_113_idx in 253.979 s.
21/09/01 15:18:20 INFO TableWriter: Wrote 353 rows to sequencedetection.log_200000_113_idx in 257.218 s.
21/09/01 15:18:43 WARN RequestHandler: Not retrying statement because it is not idempotent (this message will be logged only once). Note that this version of the driver changes the default retry behavior for non-idempotent statements: they won't be automatically retried anymore. The driver marks statements non-idempotent by default, so you should explicitly call setIdempotent(true) if your statements are safe to retry. See http://goo.gl/4HrSby for more details.
21/09/01 15:18:43 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@7a17cbc2
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 15:18:43 INFO TableWriter: Wrote 327 rows to sequencedetection.log_200000_113_idx in 280.077 s.
21/09/01 15:18:50 INFO TableWriter: Wrote 329 rows to sequencedetection.log_200000_113_idx in 287.577 s.
21/09/01 15:18:54 INFO TableWriter: Wrote 298 rows to sequencedetection.log_200000_113_idx in 290.878 s.
21/09/01 15:18:58 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@6ea51a80
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 15:18:58 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@66a9218a
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 15:18:58 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@3f2f1300
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 15:18:58 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@5e041386
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 15:18:58 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@192bc895
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 15:18:58 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@1805a16
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 15:18:58 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2a9bd53d
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 15:18:58 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@29618e57
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 15:18:58 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@4b428c74
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 15:18:58 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@37b53910
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/01 15:19:00 ERROR Executor: Exception in task 14.0 in stage 5.0 (TID 138)
java.io.IOException: Failed to write statements to sequencedetection.log_200000_113_idx. The
latest exception was
  Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)

Please check the executor logs for more exceptions and information
             
	at com.datastax.spark.connector.writer.TableWriter$$anonfun$writeInternal$1$$anonfun$apply$3.apply(TableWriter.scala:243)
	at com.datastax.spark.connector.writer.TableWriter$$anonfun$writeInternal$1$$anonfun$apply$3.apply(TableWriter.scala:241)
	at scala.Option.map(Option.scala:146)
	at com.datastax.spark.connector.writer.TableWriter$$anonfun$writeInternal$1.apply(TableWriter.scala:241)
	at com.datastax.spark.connector.writer.TableWriter$$anonfun$writeInternal$1.apply(TableWriter.scala:210)
	at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$withSessionDo$1.apply(CassandraConnector.scala:112)
	at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$withSessionDo$1.apply(CassandraConnector.scala:111)
	at com.datastax.spark.connector.cql.CassandraConnector.closeResourceAfterUse(CassandraConnector.scala:145)
	at com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:111)
	at com.datastax.spark.connector.writer.TableWriter.writeInternal(TableWriter.scala:210)
	at com.datastax.spark.connector.writer.TableWriter.update(TableWriter.scala:191)
	at com.datastax.spark.connector.writer.TableWriter.write(TableWriter.scala:180)
	at com.datastax.spark.connector.RDDFunctions$$anonfun$saveToCassandra$1.apply(RDDFunctions.scala:36)
	at com.datastax.spark.connector.RDDFunctions$$anonfun$saveToCassandra$1.apply(RDDFunctions.scala:36)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/09/01 15:19:00 ERROR TaskSetManager: Task 14 in stage 5.0 failed 1 times; aborting job
21/09/01 15:19:07 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 15:19:08 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100_346.xes normal
21/09/01 15:19:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 15:19:20 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 15:19:20 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 15:19:21 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 15:19:21 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 15:19:39 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 15:19:41 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 15:19:41 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 15:19:41 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 15:19:45 INFO TableWriter: Wrote 3973 rows to sequencedetection.log_100_346_idx in 4.325 s.
21/09/01 15:19:45 INFO TableWriter: Wrote 4025 rows to sequencedetection.log_100_346_idx in 4.336 s.
21/09/01 15:19:45 INFO TableWriter: Wrote 4039 rows to sequencedetection.log_100_346_idx in 4.346 s.
21/09/01 15:19:46 INFO TableWriter: Wrote 4033 rows to sequencedetection.log_100_346_idx in 4.360 s.
21/09/01 15:19:46 INFO TableWriter: Wrote 3989 rows to sequencedetection.log_100_346_idx in 4.362 s.
21/09/01 15:19:46 INFO TableWriter: Wrote 4045 rows to sequencedetection.log_100_346_idx in 4.364 s.
21/09/01 15:19:46 INFO TableWriter: Wrote 4054 rows to sequencedetection.log_100_346_idx in 4.368 s.
21/09/01 15:19:46 INFO TableWriter: Wrote 4041 rows to sequencedetection.log_100_346_idx in 4.372 s.
21/09/01 15:19:46 INFO TableWriter: Wrote 4058 rows to sequencedetection.log_100_346_idx in 4.389 s.
21/09/01 15:19:46 INFO TableWriter: Wrote 4166 rows to sequencedetection.log_100_346_idx in 4.389 s.
21/09/01 15:19:46 INFO TableWriter: Wrote 4115 rows to sequencedetection.log_100_346_idx in 4.396 s.
21/09/01 15:19:46 INFO TableWriter: Wrote 4092 rows to sequencedetection.log_100_346_idx in 4.402 s.
21/09/01 15:19:46 INFO TableWriter: Wrote 4120 rows to sequencedetection.log_100_346_idx in 4.420 s.
21/09/01 15:19:46 INFO TableWriter: Wrote 4192 rows to sequencedetection.log_100_346_idx in 4.421 s.
21/09/01 15:19:46 INFO TableWriter: Wrote 4127 rows to sequencedetection.log_100_346_idx in 4.425 s.
21/09/01 15:19:46 INFO TableWriter: Wrote 4178 rows to sequencedetection.log_100_346_idx in 4.425 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 20 rows to sequencedetection.log_100_346_count in 0.180 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 20 rows to sequencedetection.log_100_346_count in 0.187 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 23 rows to sequencedetection.log_100_346_count in 0.190 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 21 rows to sequencedetection.log_100_346_count in 0.192 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 21 rows to sequencedetection.log_100_346_count in 0.192 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 21 rows to sequencedetection.log_100_346_count in 0.195 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 23 rows to sequencedetection.log_100_346_count in 0.222 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 23 rows to sequencedetection.log_100_346_count in 0.226 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 24 rows to sequencedetection.log_100_346_count in 0.254 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 22 rows to sequencedetection.log_100_346_count in 0.259 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 21 rows to sequencedetection.log_100_346_count in 0.260 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 21 rows to sequencedetection.log_100_346_count in 0.263 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 22 rows to sequencedetection.log_100_346_count in 0.263 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 21 rows to sequencedetection.log_100_346_count in 0.264 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 21 rows to sequencedetection.log_100_346_count in 0.282 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 21 rows to sequencedetection.log_100_346_count in 0.281 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 3 rows to sequencedetection.log_100_346_seq in 0.030 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_346_seq in 0.043 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_seq in 0.043 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_seq in 0.044 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_seq in 0.044 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_seq in 0.042 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_seq in 0.044 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_seq in 0.045 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_seq in 0.047 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_seq in 0.048 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_seq in 0.064 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_seq in 0.068 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_346_seq in 0.069 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_346_seq in 0.069 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_346_seq in 0.074 s.
21/09/01 15:19:47 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_346_seq in 0.073 s.
21/09/01 15:19:55 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 15:19:56 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_10000_740.xes normal
21/09/01 15:19:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 15:20:01 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 15:20:01 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 15:20:02 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 15:20:02 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 15:20:13 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 15:21:04 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 15:21:04 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 15:21:04 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 15:21:17 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 15:21:34 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 15:21:34 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 15:21:34 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 15:21:41 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 16:21:17 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 16:21:17 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 16:21:17 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
Exception in thread "Spark Context Cleaner" java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/01 16:48:13 ERROR Utils: uncaught error in thread Spark Context Cleaner, stopping SparkContext
21/09/01 17:02:57 ERROR TaskSchedulerImpl: Lost executor driver on localhost: Executor heartbeat timed out after 158973 ms
21/09/01 17:05:39 ERROR Executor: Exception in task 15.0 in stage 5.0 (TID 139)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/01 17:05:39 ERROR Executor: Exception in task 1.0 in stage 5.0 (TID 125)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/01 17:05:39 ERROR Executor: Exception in task 11.0 in stage 5.0 (TID 135)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/01 17:05:39 ERROR Executor: Exception in task 3.0 in stage 5.0 (TID 127)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/01 17:05:39 ERROR Executor: Exception in task 5.0 in stage 5.0 (TID 129)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/01 17:05:39 ERROR Executor: Exception in task 0.0 in stage 5.0 (TID 124)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/01 17:05:39 ERROR Executor: Exception in task 8.0 in stage 5.0 (TID 132)
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.util.Arrays.copyOfRange(Arrays.java:3664)
	at java.lang.String.<init>(String.java:207)
	at java.lang.StringBuilder.toString(StringBuilder.java:407)
	at java.io.ObjectInputStream$BlockDataInputStream.readUTFBody(ObjectInputStream.java:3557)
	at java.io.ObjectInputStream$BlockDataInputStream.readUTF(ObjectInputStream.java:3344)
	at java.io.ObjectInputStream.readString(ObjectInputStream.java:2023)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1649)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)
	at sun.reflect.GeneratedMethodAccessor51.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)
	at sun.reflect.GeneratedMethodAccessor51.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
21/09/01 17:06:59 ERROR Executor: Exception in task 10.0 in stage 5.0 (TID 134)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/01 17:08:13 ERROR TaskSetManager: Task 13 in stage 5.0 failed 1 times; aborting job
21/09/01 17:08:13 ERROR Executor: Exception in task 9.0 in stage 5.0 (TID 133)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/01 17:08:25 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 139,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/01 17:08:25 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 125,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/01 17:08:25 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 127,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/01 17:08:25 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 124,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/01 17:08:25 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 132,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.util.Arrays.copyOfRange(Arrays.java:3664)
	at java.lang.String.<init>(String.java:207)
	at java.lang.StringBuilder.toString(StringBuilder.java:407)
	at java.io.ObjectInputStream$BlockDataInputStream.readUTFBody(ObjectInputStream.java:3557)
	at java.io.ObjectInputStream$BlockDataInputStream.readUTF(ObjectInputStream.java:3344)
	at java.io.ObjectInputStream.readString(ObjectInputStream.java:2023)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1649)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)
	at sun.reflect.GeneratedMethodAccessor51.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)
	at sun.reflect.GeneratedMethodAccessor51.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
21/09/01 17:08:25 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 133,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/01 17:08:25 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 135,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/01 17:08:25 ERROR TaskSchedulerImpl: Ignoring update with state FAILED for TID 125 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
21/09/01 17:08:25 ERROR TaskSchedulerImpl: Ignoring update with state FAILED for TID 132 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
21/09/01 17:08:25 ERROR TaskSchedulerImpl: Ignoring update with state FAILED for TID 127 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
21/09/01 17:08:25 ERROR TaskSchedulerImpl: Ignoring update with state FAILED for TID 124 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
21/09/01 17:08:25 ERROR TaskSchedulerImpl: Ignoring update with state FAILED for TID 134 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
21/09/01 17:08:25 ERROR TaskSchedulerImpl: Ignoring update with state FAILED for TID 129 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
21/09/01 17:08:25 ERROR TaskSchedulerImpl: Ignoring update with state FAILED for TID 139 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
21/09/01 17:08:25 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 134,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/01 17:08:25 ERROR TaskSchedulerImpl: Ignoring update with state FAILED for TID 135 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
21/09/01 17:08:25 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 129,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/01 17:08:25 ERROR TaskSchedulerImpl: Ignoring update with state FAILED for TID 133 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
21/09/01 17:08:25 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
21/09/01 17:08:25 ERROR ShuffleBlockFetcherIterator: Failed to create input stream from local block
java.io.IOException: Error in reading FileSegmentManagedBuffer{file=/tmp/blockmgr-1ddcb284-e57d-4820-852a-0d387b74325a/06/shuffle_1_5_0.data, offset=360041933, length=61301725}
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:111)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:442)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:64)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:156)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at com.datastax.spark.connector.util.CountingIterator.hasNext(CountingIterator.scala:12)
	at com.datastax.spark.connector.writer.GroupingBatchBuilder.hasNext(GroupingBatchBuilder.scala:101)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at com.datastax.spark.connector.writer.GroupingBatchBuilder.foreach(GroupingBatchBuilder.scala:31)
	at com.datastax.spark.connector.writer.TableWriter$$anonfun$writeInternal$1.apply(TableWriter.scala:233)
	at com.datastax.spark.connector.writer.TableWriter$$anonfun$writeInternal$1.apply(TableWriter.scala:210)
	at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$withSessionDo$1.apply(CassandraConnector.scala:112)
	at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$withSessionDo$1.apply(CassandraConnector.scala:111)
	at com.datastax.spark.connector.cql.CassandraConnector.closeResourceAfterUse(CassandraConnector.scala:145)
	at com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:111)
	at com.datastax.spark.connector.writer.TableWriter.writeInternal(TableWriter.scala:210)
	at com.datastax.spark.connector.writer.TableWriter.update(TableWriter.scala:191)
	at com.datastax.spark.connector.writer.TableWriter.write(TableWriter.scala:180)
	at com.datastax.spark.connector.RDDFunctions$$anonfun$saveToCassandra$1.apply(RDDFunctions.scala:36)
	at com.datastax.spark.connector.RDDFunctions$$anonfun$saveToCassandra$1.apply(RDDFunctions.scala:36)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: /tmp/blockmgr-1ddcb284-e57d-4820-852a-0d387b74325a/06/shuffle_1_5_0.data (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.network.buffer.FileSegmentManagedBuffer.createInputStream(FileSegmentManagedBuffer.java:100)
	... 44 more
21/09/01 17:08:25 ERROR TaskSchedulerImpl: Ignoring update with state FAILED for TID 130 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
log_10000_113.xes normal
21/09/01 17:08:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 17:08:39 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 17:08:39 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 17:08:40 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 17:08:40 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 17:08:49 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 17:08:49 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 17:08:49 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 17:08:51 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 17:09:04 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 17:09:20 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 17:09:20 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 17:09:20 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 17:09:26 INFO TableWriter: Wrote 296 rows to sequencedetection.log_10000_113_idx in 6.203 s.
21/09/01 17:09:26 INFO TableWriter: Wrote 325 rows to sequencedetection.log_10000_113_idx in 6.692 s.
21/09/01 17:09:26 INFO TableWriter: Wrote 314 rows to sequencedetection.log_10000_113_idx in 6.738 s.
21/09/01 17:09:27 INFO TableWriter: Wrote 311 rows to sequencedetection.log_10000_113_idx in 7.363 s.
21/09/01 17:09:27 INFO TableWriter: Wrote 337 rows to sequencedetection.log_10000_113_idx in 7.382 s.
21/09/01 17:09:27 INFO TableWriter: Wrote 360 rows to sequencedetection.log_10000_113_idx in 7.444 s.
21/09/01 17:09:27 INFO TableWriter: Wrote 353 rows to sequencedetection.log_10000_113_idx in 7.462 s.
21/09/01 17:09:28 INFO TableWriter: Wrote 327 rows to sequencedetection.log_10000_113_idx in 8.044 s.
21/09/01 17:09:28 INFO TableWriter: Wrote 297 rows to sequencedetection.log_10000_113_idx in 8.117 s.
21/09/01 17:09:28 INFO TableWriter: Wrote 328 rows to sequencedetection.log_10000_113_idx in 8.246 s.
21/09/01 17:09:28 INFO TableWriter: Wrote 321 rows to sequencedetection.log_10000_113_idx in 8.307 s.
21/09/01 17:09:28 INFO TableWriter: Wrote 302 rows to sequencedetection.log_10000_113_idx in 8.338 s.
21/09/01 17:09:28 INFO TableWriter: Wrote 334 rows to sequencedetection.log_10000_113_idx in 8.348 s.
21/09/01 17:09:28 INFO TableWriter: Wrote 349 rows to sequencedetection.log_10000_113_idx in 8.399 s.
21/09/01 17:09:28 INFO TableWriter: Wrote 321 rows to sequencedetection.log_10000_113_idx in 8.433 s.
21/09/01 17:09:28 INFO TableWriter: Wrote 344 rows to sequencedetection.log_10000_113_idx in 8.778 s.
21/09/01 17:09:36 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 17:09:36 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 17:09:36 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 17:09:36 INFO TableWriter: Wrote 4 rows to sequencedetection.log_10000_113_count in 0.093 s.
21/09/01 17:09:36 INFO TableWriter: Wrote 4 rows to sequencedetection.log_10000_113_count in 0.094 s.
21/09/01 17:09:36 INFO TableWriter: Wrote 8 rows to sequencedetection.log_10000_113_count in 0.096 s.
21/09/01 17:09:36 INFO TableWriter: Wrote 5 rows to sequencedetection.log_10000_113_count in 0.096 s.
21/09/01 17:09:36 INFO TableWriter: Wrote 7 rows to sequencedetection.log_10000_113_count in 0.096 s.
21/09/01 17:09:36 INFO TableWriter: Wrote 8 rows to sequencedetection.log_10000_113_count in 0.100 s.
21/09/01 17:09:36 INFO TableWriter: Wrote 9 rows to sequencedetection.log_10000_113_count in 0.100 s.
21/09/01 17:09:36 INFO TableWriter: Wrote 8 rows to sequencedetection.log_10000_113_count in 0.100 s.
21/09/01 17:09:36 INFO TableWriter: Wrote 6 rows to sequencedetection.log_10000_113_count in 0.100 s.
21/09/01 17:09:36 INFO TableWriter: Wrote 9 rows to sequencedetection.log_10000_113_count in 0.103 s.
21/09/01 17:09:36 INFO TableWriter: Wrote 5 rows to sequencedetection.log_10000_113_count in 0.111 s.
21/09/01 17:09:36 INFO TableWriter: Wrote 4 rows to sequencedetection.log_10000_113_count in 0.113 s.
21/09/01 17:09:36 INFO TableWriter: Wrote 9 rows to sequencedetection.log_10000_113_count in 0.112 s.
21/09/01 17:09:36 INFO TableWriter: Wrote 9 rows to sequencedetection.log_10000_113_count in 0.113 s.
21/09/01 17:09:36 INFO TableWriter: Wrote 9 rows to sequencedetection.log_10000_113_count in 0.128 s.
21/09/01 17:09:36 INFO TableWriter: Wrote 8 rows to sequencedetection.log_10000_113_count in 0.129 s.
21/09/01 17:09:36 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 17:09:37 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_113_seq in 1.239 s.
21/09/01 17:09:37 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_113_seq in 1.261 s.
21/09/01 17:09:37 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_113_seq in 1.275 s.
21/09/01 17:09:37 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_113_seq in 1.283 s.
21/09/01 17:09:37 INFO TableWriter: Wrote 558 rows to sequencedetection.log_10000_113_seq in 1.298 s.
21/09/01 17:09:37 INFO TableWriter: Wrote 558 rows to sequencedetection.log_10000_113_seq in 1.299 s.
21/09/01 17:09:37 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_113_seq in 1.345 s.
21/09/01 17:09:37 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_113_seq in 1.365 s.
21/09/01 17:09:37 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_113_seq in 1.403 s.
21/09/01 17:09:37 INFO TableWriter: Wrote 555 rows to sequencedetection.log_10000_113_seq in 1.415 s.
21/09/01 17:09:37 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_113_seq in 1.418 s.
21/09/01 17:09:37 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_113_seq in 1.438 s.
21/09/01 17:09:37 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_113_seq in 1.452 s.
21/09/01 17:09:37 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_113_seq in 1.463 s.
21/09/01 17:09:37 INFO TableWriter: Wrote 744 rows to sequencedetection.log_10000_113_seq in 1.472 s.
21/09/01 17:09:37 INFO TableWriter: Wrote 740 rows to sequencedetection.log_10000_113_seq in 1.477 s.
21/09/01 17:09:45 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 17:09:46 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_500_740.xes signature
21/09/01 17:09:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 17:09:52 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 17:09:52 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 17:09:52 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 17:09:52 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 17:10:04 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 17:11:14 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 17:11:14 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 17:11:14 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 17:11:15 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.408 s.
21/09/01 17:11:15 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.408 s.
21/09/01 17:11:15 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.409 s.
21/09/01 17:11:15 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.410 s.
21/09/01 17:11:15 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.410 s.
21/09/01 17:11:15 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_740_sign_seq in 0.410 s.
21/09/01 17:11:15 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_740_sign_seq in 0.411 s.
21/09/01 17:11:15 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.412 s.
21/09/01 17:11:15 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.411 s.
21/09/01 17:11:15 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.412 s.
21/09/01 17:11:15 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.407 s.
21/09/01 17:11:15 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_740_sign_seq in 0.412 s.
21/09/01 17:11:15 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_740_sign_seq in 0.412 s.
21/09/01 17:11:15 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.413 s.
21/09/01 17:11:15 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.416 s.
21/09/01 17:11:15 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_seq in 0.416 s.
21/09/01 17:11:20 INFO TableWriter: Wrote 25 rows to sequencedetection.log_500_740_sign_idx in 2.042 s.
21/09/01 17:11:20 INFO TableWriter: Wrote 28 rows to sequencedetection.log_500_740_sign_idx in 2.215 s.
21/09/01 17:11:21 INFO TableWriter: Wrote 27 rows to sequencedetection.log_500_740_sign_idx in 2.455 s.
21/09/01 17:11:21 INFO TableWriter: Wrote 28 rows to sequencedetection.log_500_740_sign_idx in 2.555 s.
21/09/01 17:11:21 INFO TableWriter: Wrote 29 rows to sequencedetection.log_500_740_sign_idx in 2.631 s.
21/09/01 17:11:21 INFO TableWriter: Wrote 28 rows to sequencedetection.log_500_740_sign_idx in 2.627 s.
21/09/01 17:11:21 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_sign_idx in 2.768 s.
21/09/01 17:11:21 INFO TableWriter: Wrote 28 rows to sequencedetection.log_500_740_sign_idx in 2.808 s.
21/09/01 17:11:21 INFO TableWriter: Wrote 34 rows to sequencedetection.log_500_740_sign_idx in 2.828 s.
21/09/01 17:11:21 INFO TableWriter: Wrote 30 rows to sequencedetection.log_500_740_sign_idx in 2.819 s.
21/09/01 17:11:21 INFO TableWriter: Wrote 33 rows to sequencedetection.log_500_740_sign_idx in 2.840 s.
21/09/01 17:11:21 INFO TableWriter: Wrote 33 rows to sequencedetection.log_500_740_sign_idx in 2.871 s.
21/09/01 17:11:21 INFO TableWriter: Wrote 33 rows to sequencedetection.log_500_740_sign_idx in 2.891 s.
21/09/01 17:11:21 INFO TableWriter: Wrote 35 rows to sequencedetection.log_500_740_sign_idx in 2.909 s.
21/09/01 17:11:21 INFO TableWriter: Wrote 36 rows to sequencedetection.log_500_740_sign_idx in 2.957 s.
21/09/01 17:11:21 INFO TableWriter: Wrote 42 rows to sequencedetection.log_500_740_sign_idx in 2.981 s.
21/09/01 17:11:29 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 17:11:30 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_10000_346.xes signature
21/09/01 17:11:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 17:11:36 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 17:11:36 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 17:11:36 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 17:11:36 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 17:11:52 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 17:25:02 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 17:25:02 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 17:25:02 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 17:25:12 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_346_sign_seq in 7.466 s.
21/09/01 17:25:12 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_346_sign_seq in 7.532 s.
21/09/01 17:25:12 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_346_sign_seq in 7.549 s.
21/09/01 17:25:12 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_346_sign_seq in 7.599 s.
21/09/01 17:25:12 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_346_sign_seq in 7.604 s.
21/09/01 17:25:12 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_346_sign_seq in 7.607 s.
21/09/01 17:25:12 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_346_sign_seq in 7.613 s.
21/09/01 17:25:12 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_346_sign_seq in 7.620 s.
21/09/01 17:25:12 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_346_sign_seq in 7.646 s.
21/09/01 17:25:12 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_346_sign_seq in 7.676 s.
21/09/01 17:25:12 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_346_sign_seq in 7.787 s.
21/09/01 17:25:12 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_346_sign_seq in 7.862 s.
21/09/01 17:25:12 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_346_sign_seq in 7.869 s.
21/09/01 17:25:12 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_346_sign_seq in 7.970 s.
21/09/01 17:25:13 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_346_sign_seq in 8.085 s.
21/09/01 17:25:13 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_346_sign_seq in 8.187 s.
21/09/01 17:25:21 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 17:25:29 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 17:25:30 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 17:25:30 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 17:25:43 INFO TableWriter: Wrote 414 rows to sequencedetection.log_10000_346_sign_idx in 13.612 s.
21/09/01 17:25:43 INFO TableWriter: Wrote 411 rows to sequencedetection.log_10000_346_sign_idx in 13.764 s.
21/09/01 17:25:44 INFO TableWriter: Wrote 423 rows to sequencedetection.log_10000_346_sign_idx in 14.162 s.
21/09/01 17:25:44 INFO TableWriter: Wrote 436 rows to sequencedetection.log_10000_346_sign_idx in 14.652 s.
21/09/01 17:25:45 INFO TableWriter: Wrote 455 rows to sequencedetection.log_10000_346_sign_idx in 15.591 s.
21/09/01 17:25:46 INFO TableWriter: Wrote 483 rows to sequencedetection.log_10000_346_sign_idx in 16.338 s.
21/09/01 17:25:47 INFO TableWriter: Wrote 521 rows to sequencedetection.log_10000_346_sign_idx in 17.007 s.
21/09/01 17:25:47 INFO TableWriter: Wrote 503 rows to sequencedetection.log_10000_346_sign_idx in 17.048 s.
21/09/01 17:25:47 INFO TableWriter: Wrote 528 rows to sequencedetection.log_10000_346_sign_idx in 17.309 s.
21/09/01 17:25:47 INFO TableWriter: Wrote 571 rows to sequencedetection.log_10000_346_sign_idx in 17.815 s.
21/09/01 17:25:48 INFO TableWriter: Wrote 607 rows to sequencedetection.log_10000_346_sign_idx in 18.398 s.
21/09/01 17:25:48 INFO TableWriter: Wrote 616 rows to sequencedetection.log_10000_346_sign_idx in 18.653 s.
21/09/01 17:25:48 INFO TableWriter: Wrote 660 rows to sequencedetection.log_10000_346_sign_idx in 18.996 s.
21/09/01 17:25:54 INFO TableWriter: Wrote 684 rows to sequencedetection.log_10000_346_sign_idx in 24.384 s.
21/09/01 17:25:54 INFO TableWriter: Wrote 706 rows to sequencedetection.log_10000_346_sign_idx in 24.428 s.
21/09/01 17:25:54 INFO TableWriter: Wrote 701 rows to sequencedetection.log_10000_346_sign_idx in 24.431 s.
21/09/01 17:26:01 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 17:26:02 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_1000_740.xes signature
21/09/01 17:26:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 17:26:10 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 17:26:10 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 17:26:10 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 17:26:10 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 17:26:22 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 17:30:37 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 17:30:37 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 17:30:37 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 17:30:38 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_740_sign_seq in 0.582 s.
21/09/01 17:30:38 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_sign_seq in 0.584 s.
21/09/01 17:30:38 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_sign_seq in 0.585 s.
21/09/01 17:30:38 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_740_sign_seq in 0.585 s.
21/09/01 17:30:38 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_740_sign_seq in 0.585 s.
21/09/01 17:30:38 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_740_sign_seq in 0.585 s.
21/09/01 17:30:38 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_sign_seq in 0.586 s.
21/09/01 17:30:38 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_sign_seq in 0.586 s.
21/09/01 17:30:38 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_sign_seq in 0.590 s.
21/09/01 17:30:38 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_740_sign_seq in 0.594 s.
21/09/01 17:30:38 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_sign_seq in 0.595 s.
21/09/01 17:30:38 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_740_sign_seq in 0.595 s.
21/09/01 17:30:38 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_sign_seq in 0.596 s.
21/09/01 17:30:38 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_740_sign_seq in 0.596 s.
21/09/01 17:30:38 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_740_sign_seq in 0.592 s.
21/09/01 17:30:38 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_sign_seq in 0.609 s.
21/09/01 17:30:46 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 17:30:47 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 17:30:47 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 17:30:47 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 17:30:52 INFO TableWriter: Wrote 50 rows to sequencedetection.log_1000_740_sign_idx in 4.968 s.
21/09/01 17:30:52 INFO TableWriter: Wrote 59 rows to sequencedetection.log_1000_740_sign_idx in 5.045 s.
21/09/01 17:30:52 INFO TableWriter: Wrote 56 rows to sequencedetection.log_1000_740_sign_idx in 5.322 s.
21/09/01 17:30:52 INFO TableWriter: Wrote 59 rows to sequencedetection.log_1000_740_sign_idx in 5.517 s.
21/09/01 17:30:52 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_740_sign_idx in 5.570 s.
21/09/01 17:30:53 INFO TableWriter: Wrote 59 rows to sequencedetection.log_1000_740_sign_idx in 5.655 s.
21/09/01 17:30:53 INFO TableWriter: Wrote 66 rows to sequencedetection.log_1000_740_sign_idx in 5.673 s.
21/09/01 17:30:53 INFO TableWriter: Wrote 61 rows to sequencedetection.log_1000_740_sign_idx in 5.694 s.
21/09/01 17:30:53 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_sign_idx in 5.714 s.
21/09/01 17:30:53 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_sign_idx in 5.754 s.
21/09/01 17:30:53 INFO TableWriter: Wrote 61 rows to sequencedetection.log_1000_740_sign_idx in 5.791 s.
21/09/01 17:30:53 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_sign_idx in 5.832 s.
21/09/01 17:30:53 INFO TableWriter: Wrote 66 rows to sequencedetection.log_1000_740_sign_idx in 5.862 s.
21/09/01 17:30:53 INFO TableWriter: Wrote 67 rows to sequencedetection.log_1000_740_sign_idx in 5.873 s.
21/09/01 17:30:53 INFO TableWriter: Wrote 70 rows to sequencedetection.log_1000_740_sign_idx in 5.895 s.
21/09/01 17:30:53 INFO TableWriter: Wrote 77 rows to sequencedetection.log_1000_740_sign_idx in 5.989 s.
21/09/01 17:31:00 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 17:31:01 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100000_346.xes signature
21/09/01 17:31:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 17:31:08 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 17:31:08 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 17:31:09 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 17:31:09 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 17:31:22 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 18:55:03 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 18:55:03 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 18:55:03 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 18:55:11 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 18:55:28 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 18:55:28 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 18:55:28 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 18:57:06 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_346_sign_seq in 97.385 s.
21/09/01 18:57:06 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_346_sign_seq in 97.492 s.
21/09/01 18:57:06 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_346_sign_seq in 97.959 s.
21/09/01 18:57:06 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_346_sign_seq in 98.104 s.
21/09/01 18:57:06 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_346_sign_seq in 98.128 s.
21/09/01 18:57:06 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_346_sign_seq in 98.189 s.
21/09/01 18:57:06 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_346_sign_seq in 98.185 s.
21/09/01 18:57:07 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_346_sign_seq in 98.268 s.
21/09/01 18:57:07 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_346_sign_seq in 98.351 s.
21/09/01 18:57:07 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_346_sign_seq in 98.432 s.
21/09/01 18:57:07 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_346_sign_seq in 98.528 s.
21/09/01 18:57:07 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_346_sign_seq in 98.550 s.
21/09/01 18:57:07 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_346_sign_seq in 98.712 s.
21/09/01 18:57:07 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_346_sign_seq in 98.797 s.
21/09/01 18:57:07 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_346_sign_seq in 98.977 s.
21/09/01 18:57:08 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_346_sign_seq in 99.417 s.
21/09/01 18:57:13 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 18:57:13 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 18:57:13 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 18:57:15 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 18:57:20 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:33:00 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:33:00 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:33:00 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:35:45 INFO TableWriter: Wrote 3376 rows to sequencedetection.log_100000_346_sign_idx in 165.182 s.
21/09/01 20:35:53 INFO TableWriter: Wrote 3532 rows to sequencedetection.log_100000_346_sign_idx in 173.440 s.
21/09/01 20:35:58 INFO TableWriter: Wrote 3694 rows to sequencedetection.log_100000_346_sign_idx in 178.426 s.
21/09/01 20:35:59 INFO TableWriter: Wrote 3709 rows to sequencedetection.log_100000_346_sign_idx in 178.642 s.
21/09/01 20:36:07 INFO TableWriter: Wrote 3907 rows to sequencedetection.log_100000_346_sign_idx in 187.194 s.
21/09/01 20:36:08 INFO TableWriter: Wrote 3955 rows to sequencedetection.log_100000_346_sign_idx in 188.071 s.
21/09/01 20:36:17 INFO TableWriter: Wrote 4235 rows to sequencedetection.log_100000_346_sign_idx in 197.309 s.
21/09/01 20:36:25 INFO TableWriter: Wrote 4507 rows to sequencedetection.log_100000_346_sign_idx in 204.761 s.
21/09/01 20:36:25 INFO TableWriter: Wrote 4511 rows to sequencedetection.log_100000_346_sign_idx in 205.218 s.
21/09/01 20:36:36 INFO TableWriter: Wrote 4970 rows to sequencedetection.log_100000_346_sign_idx in 215.652 s.
21/09/01 20:36:38 INFO TableWriter: Wrote 5137 rows to sequencedetection.log_100000_346_sign_idx in 217.593 s.
21/09/01 20:36:39 INFO TableWriter: Wrote 5327 rows to sequencedetection.log_100000_346_sign_idx in 219.232 s.
21/09/01 20:36:40 INFO TableWriter: Wrote 5432 rows to sequencedetection.log_100000_346_sign_idx in 220.136 s.
21/09/01 20:36:45 INFO TableWriter: Wrote 5703 rows to sequencedetection.log_100000_346_sign_idx in 224.817 s.
21/09/01 20:36:45 INFO TableWriter: Wrote 5800 rows to sequencedetection.log_100000_346_sign_idx in 225.300 s.
21/09/01 20:36:45 INFO TableWriter: Wrote 5774 rows to sequencedetection.log_100000_346_sign_idx in 225.309 s.
21/09/01 20:36:58 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:36:59 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_1000_346.xes signature
21/09/01 20:37:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 20:37:08 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:37:08 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 20:37:09 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:37:09 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:37:25 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:37:58 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:37:58 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:37:58 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:37:59 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_sign_seq in 0.470 s.
21/09/01 20:37:59 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_sign_seq in 0.477 s.
21/09/01 20:37:59 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_sign_seq in 0.480 s.
21/09/01 20:37:59 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_sign_seq in 0.483 s.
21/09/01 20:37:59 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_sign_seq in 0.484 s.
21/09/01 20:37:59 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_sign_seq in 0.485 s.
21/09/01 20:37:59 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_sign_seq in 0.485 s.
21/09/01 20:37:59 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_sign_seq in 0.485 s.
21/09/01 20:37:59 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_sign_seq in 0.484 s.
21/09/01 20:37:59 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_sign_seq in 0.485 s.
21/09/01 20:37:59 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_sign_seq in 0.485 s.
21/09/01 20:37:59 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_sign_seq in 0.484 s.
21/09/01 20:37:59 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_sign_seq in 0.484 s.
21/09/01 20:37:59 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_sign_seq in 0.485 s.
21/09/01 20:37:59 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_sign_seq in 0.486 s.
21/09/01 20:37:59 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_sign_seq in 0.487 s.
21/09/01 20:38:02 INFO TableWriter: Wrote 30 rows to sequencedetection.log_1000_346_sign_idx in 0.878 s.
21/09/01 20:38:02 INFO TableWriter: Wrote 33 rows to sequencedetection.log_1000_346_sign_idx in 1.069 s.
21/09/01 20:38:02 INFO TableWriter: Wrote 45 rows to sequencedetection.log_1000_346_sign_idx in 1.121 s.
21/09/01 20:38:02 INFO TableWriter: Wrote 49 rows to sequencedetection.log_1000_346_sign_idx in 1.487 s.
21/09/01 20:38:02 INFO TableWriter: Wrote 50 rows to sequencedetection.log_1000_346_sign_idx in 1.550 s.
21/09/01 20:38:02 INFO TableWriter: Wrote 51 rows to sequencedetection.log_1000_346_sign_idx in 1.574 s.
21/09/01 20:38:02 INFO TableWriter: Wrote 58 rows to sequencedetection.log_1000_346_sign_idx in 1.697 s.
21/09/01 20:38:02 INFO TableWriter: Wrote 59 rows to sequencedetection.log_1000_346_sign_idx in 1.726 s.
21/09/01 20:38:03 INFO TableWriter: Wrote 61 rows to sequencedetection.log_1000_346_sign_idx in 1.875 s.
21/09/01 20:38:03 INFO TableWriter: Wrote 66 rows to sequencedetection.log_1000_346_sign_idx in 1.874 s.
21/09/01 20:38:03 INFO TableWriter: Wrote 66 rows to sequencedetection.log_1000_346_sign_idx in 1.916 s.
21/09/01 20:38:03 INFO TableWriter: Wrote 70 rows to sequencedetection.log_1000_346_sign_idx in 1.948 s.
21/09/01 20:38:03 INFO TableWriter: Wrote 86 rows to sequencedetection.log_1000_346_sign_idx in 1.977 s.
21/09/01 20:38:03 INFO TableWriter: Wrote 81 rows to sequencedetection.log_1000_346_sign_idx in 1.994 s.
21/09/01 20:38:03 INFO TableWriter: Wrote 78 rows to sequencedetection.log_1000_346_sign_idx in 1.973 s.
21/09/01 20:38:03 INFO TableWriter: Wrote 100 rows to sequencedetection.log_1000_346_sign_idx in 2.044 s.
21/09/01 20:38:10 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:38:11 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100_740.xes signature
21/09/01 20:38:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 20:38:16 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:38:16 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 20:38:17 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:38:17 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:38:31 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:38:44 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:38:44 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:38:44 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:38:45 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_sign_seq in 0.233 s.
21/09/01 20:38:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.237 s.
21/09/01 20:38:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.233 s.
21/09/01 20:38:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.233 s.
21/09/01 20:38:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.237 s.
21/09/01 20:38:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.235 s.
21/09/01 20:38:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.237 s.
21/09/01 20:38:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.237 s.
21/09/01 20:38:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.237 s.
21/09/01 20:38:45 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_sign_seq in 0.237 s.
21/09/01 20:38:45 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_sign_seq in 0.237 s.
21/09/01 20:38:45 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_sign_seq in 0.239 s.
21/09/01 20:38:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.237 s.
21/09/01 20:38:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.231 s.
21/09/01 20:38:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.240 s.
21/09/01 20:38:45 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_seq in 0.242 s.
21/09/01 20:38:46 INFO TableWriter: Wrote 0 rows to sequencedetection.log_100_740_sign_idx in 0.051 s.
21/09/01 20:38:46 INFO TableWriter: Wrote 3 rows to sequencedetection.log_100_740_sign_idx in 0.326 s.
21/09/01 20:38:46 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_740_sign_idx in 0.405 s.
21/09/01 20:38:46 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_740_sign_idx in 0.447 s.
21/09/01 20:38:46 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_idx in 0.447 s.
21/09/01 20:38:46 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_740_sign_idx in 0.449 s.
21/09/01 20:38:46 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_sign_idx in 0.455 s.
21/09/01 20:38:46 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_740_sign_idx in 0.472 s.
21/09/01 20:38:46 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_idx in 0.483 s.
21/09/01 20:38:46 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_sign_idx in 0.505 s.
21/09/01 20:38:46 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_sign_idx in 0.525 s.
21/09/01 20:38:46 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_sign_idx in 0.518 s.
21/09/01 20:38:46 INFO TableWriter: Wrote 10 rows to sequencedetection.log_100_740_sign_idx in 0.533 s.
21/09/01 20:38:46 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100_740_sign_idx in 0.546 s.
21/09/01 20:38:46 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_740_sign_idx in 0.577 s.
21/09/01 20:38:46 INFO TableWriter: Wrote 12 rows to sequencedetection.log_100_740_sign_idx in 0.584 s.
21/09/01 20:38:54 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:38:55 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_500_346.xes signature
21/09/01 20:38:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 20:39:00 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:39:00 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 20:39:00 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:39:00 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:39:13 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:39:29 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:39:29 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:39:29 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:39:30 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_sign_seq in 0.340 s.
21/09/01 20:39:30 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.341 s.
21/09/01 20:39:30 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.341 s.
21/09/01 20:39:30 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.326 s.
21/09/01 20:39:30 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.345 s.
21/09/01 20:39:30 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.331 s.
21/09/01 20:39:30 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.346 s.
21/09/01 20:39:30 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.346 s.
21/09/01 20:39:30 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.321 s.
21/09/01 20:39:30 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.346 s.
21/09/01 20:39:30 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_sign_seq in 0.347 s.
21/09/01 20:39:30 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.329 s.
21/09/01 20:39:30 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_sign_seq in 0.347 s.
21/09/01 20:39:30 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_sign_seq in 0.347 s.
21/09/01 20:39:30 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.331 s.
21/09/01 20:39:30 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_seq in 0.329 s.
21/09/01 20:39:32 INFO TableWriter: Wrote 14 rows to sequencedetection.log_500_346_sign_idx in 0.459 s.
21/09/01 20:39:32 INFO TableWriter: Wrote 25 rows to sequencedetection.log_500_346_sign_idx in 0.543 s.
21/09/01 20:39:32 INFO TableWriter: Wrote 19 rows to sequencedetection.log_500_346_sign_idx in 0.685 s.
21/09/01 20:39:32 INFO TableWriter: Wrote 28 rows to sequencedetection.log_500_346_sign_idx in 0.748 s.
21/09/01 20:39:32 INFO TableWriter: Wrote 28 rows to sequencedetection.log_500_346_sign_idx in 0.786 s.
21/09/01 20:39:32 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_sign_idx in 0.812 s.
21/09/01 20:39:32 INFO TableWriter: Wrote 30 rows to sequencedetection.log_500_346_sign_idx in 0.837 s.
21/09/01 20:39:32 INFO TableWriter: Wrote 24 rows to sequencedetection.log_500_346_sign_idx in 0.838 s.
21/09/01 20:39:32 INFO TableWriter: Wrote 34 rows to sequencedetection.log_500_346_sign_idx in 0.913 s.
21/09/01 20:39:32 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_sign_idx in 0.916 s.
21/09/01 20:39:32 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_sign_idx in 0.910 s.
21/09/01 20:39:32 INFO TableWriter: Wrote 35 rows to sequencedetection.log_500_346_sign_idx in 0.926 s.
21/09/01 20:39:32 INFO TableWriter: Wrote 34 rows to sequencedetection.log_500_346_sign_idx in 0.929 s.
21/09/01 20:39:32 INFO TableWriter: Wrote 39 rows to sequencedetection.log_500_346_sign_idx in 0.951 s.
21/09/01 20:39:32 INFO TableWriter: Wrote 43 rows to sequencedetection.log_500_346_sign_idx in 0.968 s.
21/09/01 20:39:32 INFO TableWriter: Wrote 46 rows to sequencedetection.log_500_346_sign_idx in 0.981 s.
21/09/01 20:39:39 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:39:40 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100000_113.xes signature
21/09/01 20:39:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 20:39:45 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:39:46 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 20:39:46 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:39:46 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:39:58 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:41:50 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:41:50 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:41:50 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:42:15 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 14.108 s.
21/09/01 20:42:15 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 14.106 s.
21/09/01 20:42:15 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 14.131 s.
21/09/01 20:42:15 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 14.089 s.
21/09/01 20:42:15 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 14.121 s.
21/09/01 20:42:15 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 14.200 s.
21/09/01 20:42:15 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 14.214 s.
21/09/01 20:42:15 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 14.332 s.
21/09/01 20:42:15 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 14.286 s.
21/09/01 20:42:15 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 14.349 s.
21/09/01 20:42:15 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 14.266 s.
21/09/01 20:42:15 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 14.347 s.
21/09/01 20:42:15 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 14.350 s.
21/09/01 20:42:15 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 14.359 s.
21/09/01 20:42:15 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 22.052 s.
21/09/01 20:42:15 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_sign_seq in 14.452 s.
21/09/01 20:42:26 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:42:26 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:42:27 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:42:27 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:42:27 INFO TableWriter: Wrote 10 rows to sequencedetection.log_100000_113_sign_idx in 0.218 s.
21/09/01 20:42:27 INFO TableWriter: Wrote 10 rows to sequencedetection.log_100000_113_sign_idx in 0.183 s.
21/09/01 20:42:27 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100000_113_sign_idx in 0.283 s.
21/09/01 20:42:27 INFO TableWriter: Wrote 10 rows to sequencedetection.log_100000_113_sign_idx in 0.263 s.
21/09/01 20:42:27 INFO TableWriter: Wrote 16 rows to sequencedetection.log_100000_113_sign_idx in 0.249 s.
21/09/01 20:42:27 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100000_113_sign_idx in 0.243 s.
21/09/01 20:42:27 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100000_113_sign_idx in 0.232 s.
21/09/01 20:42:27 INFO TableWriter: Wrote 14 rows to sequencedetection.log_100000_113_sign_idx in 0.208 s.
21/09/01 20:42:27 INFO TableWriter: Wrote 12 rows to sequencedetection.log_100000_113_sign_idx in 0.264 s.
21/09/01 20:42:27 INFO TableWriter: Wrote 18 rows to sequencedetection.log_100000_113_sign_idx in 0.133 s.
21/09/01 20:42:27 INFO TableWriter: Wrote 19 rows to sequencedetection.log_100000_113_sign_idx in 0.247 s.
21/09/01 20:42:27 INFO TableWriter: Wrote 18 rows to sequencedetection.log_100000_113_sign_idx in 0.199 s.
21/09/01 20:42:27 INFO TableWriter: Wrote 12 rows to sequencedetection.log_100000_113_sign_idx in 0.318 s.
21/09/01 20:42:27 INFO TableWriter: Wrote 22 rows to sequencedetection.log_100000_113_sign_idx in 0.097 s.
21/09/01 20:42:27 INFO TableWriter: Wrote 21 rows to sequencedetection.log_100000_113_sign_idx in 0.257 s.
21/09/01 20:42:27 INFO TableWriter: Wrote 22 rows to sequencedetection.log_100000_113_sign_idx in 0.074 s.
21/09/01 20:42:34 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:42:35 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100_113.xes signature
21/09/01 20:42:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 20:42:41 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:42:41 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 20:42:41 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:42:41 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:42:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.161 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.161 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.162 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.162 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_sign_seq in 0.168 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.163 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.163 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.161 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.164 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.165 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.161 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.162 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_seq in 0.161 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_sign_seq in 0.165 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_sign_seq in 0.168 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_sign_seq in 0.167 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 2 rows to sequencedetection.log_100_113_sign_idx in 0.027 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 2 rows to sequencedetection.log_100_113_sign_idx in 0.026 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 3 rows to sequencedetection.log_100_113_sign_idx in 0.037 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_sign_idx in 0.040 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 2 rows to sequencedetection.log_100_113_sign_idx in 0.053 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_113_sign_idx in 0.053 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 0 rows to sequencedetection.log_100_113_sign_idx in 0.053 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 1 rows to sequencedetection.log_100_113_sign_idx in 0.054 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_113_sign_idx in 0.072 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_113_sign_idx in 0.052 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 1 rows to sequencedetection.log_100_113_sign_idx in 0.069 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_idx in 0.102 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_113_sign_idx in 0.120 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 8 rows to sequencedetection.log_100_113_sign_idx in 0.117 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_sign_idx in 0.124 s.
21/09/01 20:42:50 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_sign_idx in 0.119 s.
21/09/01 20:42:57 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:42:58 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_1000_113.xes signature
21/09/01 20:43:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 20:43:03 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:43:03 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 20:43:04 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:43:04 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:43:13 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:43:13 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:43:13 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:43:14 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_sign_seq in 0.372 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_sign_seq in 0.371 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_sign_seq in 0.373 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_sign_seq in 0.371 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_sign_seq in 0.371 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_sign_seq in 0.374 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_sign_seq in 0.374 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_sign_seq in 0.375 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_sign_seq in 0.375 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_sign_seq in 0.375 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_sign_seq in 0.375 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_sign_seq in 0.375 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_sign_seq in 0.375 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_sign_seq in 0.375 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_sign_seq in 0.376 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_sign_seq in 0.376 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 10 rows to sequencedetection.log_1000_113_sign_idx in 0.099 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 12 rows to sequencedetection.log_1000_113_sign_idx in 0.104 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 12 rows to sequencedetection.log_1000_113_sign_idx in 0.107 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 9 rows to sequencedetection.log_1000_113_sign_idx in 0.111 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 6 rows to sequencedetection.log_1000_113_sign_idx in 0.112 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 15 rows to sequencedetection.log_1000_113_sign_idx in 0.130 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 11 rows to sequencedetection.log_1000_113_sign_idx in 0.119 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 7 rows to sequencedetection.log_1000_113_sign_idx in 0.148 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 6 rows to sequencedetection.log_1000_113_sign_idx in 0.157 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 4 rows to sequencedetection.log_1000_113_sign_idx in 0.147 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 6 rows to sequencedetection.log_1000_113_sign_idx in 0.160 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 15 rows to sequencedetection.log_1000_113_sign_idx in 0.150 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 15 rows to sequencedetection.log_1000_113_sign_idx in 0.144 s.
21/09/01 20:43:14 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:43:14 INFO TableWriter: Wrote 13 rows to sequencedetection.log_1000_113_sign_idx in 0.155 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 10 rows to sequencedetection.log_1000_113_sign_idx in 0.162 s.
21/09/01 20:43:14 INFO TableWriter: Wrote 20 rows to sequencedetection.log_1000_113_sign_idx in 0.165 s.
21/09/01 20:43:21 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:43:22 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_200000_113.xes signature
21/09/01 20:43:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 20:43:27 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:43:27 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 20:43:28 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:43:28 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:43:38 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:46:57 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:46:58 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:46:58 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:47:10 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:47:14 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:47:15 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:47:15 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:47:44 INFO TableWriter: Wrote 12500 rows to sequencedetection.log_200000_113_sign_seq in 29.819 s.
21/09/01 20:47:44 INFO TableWriter: Wrote 12500 rows to sequencedetection.log_200000_113_sign_seq in 29.811 s.
21/09/01 20:47:44 INFO TableWriter: Wrote 12500 rows to sequencedetection.log_200000_113_sign_seq in 29.696 s.
21/09/01 20:47:44 INFO TableWriter: Wrote 12500 rows to sequencedetection.log_200000_113_sign_seq in 30.612 s.
21/09/01 20:47:45 INFO TableWriter: Wrote 12500 rows to sequencedetection.log_200000_113_sign_seq in 29.833 s.
21/09/01 20:47:45 INFO TableWriter: Wrote 12500 rows to sequencedetection.log_200000_113_sign_seq in 30.631 s.
21/09/01 20:47:45 INFO TableWriter: Wrote 12500 rows to sequencedetection.log_200000_113_sign_seq in 29.960 s.
21/09/01 20:47:45 INFO TableWriter: Wrote 12500 rows to sequencedetection.log_200000_113_sign_seq in 30.715 s.
21/09/01 20:47:45 INFO TableWriter: Wrote 12500 rows to sequencedetection.log_200000_113_sign_seq in 30.720 s.
21/09/01 20:47:45 INFO TableWriter: Wrote 12500 rows to sequencedetection.log_200000_113_sign_seq in 29.996 s.
21/09/01 20:47:45 INFO TableWriter: Wrote 12500 rows to sequencedetection.log_200000_113_sign_seq in 30.790 s.
21/09/01 20:47:45 INFO TableWriter: Wrote 12500 rows to sequencedetection.log_200000_113_sign_seq in 30.838 s.
21/09/01 20:47:45 INFO TableWriter: Wrote 12500 rows to sequencedetection.log_200000_113_sign_seq in 30.053 s.
21/09/01 20:47:45 INFO TableWriter: Wrote 12500 rows to sequencedetection.log_200000_113_sign_seq in 30.145 s.
21/09/01 20:47:45 INFO TableWriter: Wrote 12500 rows to sequencedetection.log_200000_113_sign_seq in 30.172 s.
21/09/01 20:47:45 INFO TableWriter: Wrote 12500 rows to sequencedetection.log_200000_113_sign_seq in 31.004 s.
21/09/01 20:47:52 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:48:04 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:48:04 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:48:04 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:48:04 INFO TableWriter: Wrote 7 rows to sequencedetection.log_200000_113_sign_idx in 0.150 s.
21/09/01 20:48:04 INFO TableWriter: Wrote 10 rows to sequencedetection.log_200000_113_sign_idx in 0.114 s.
21/09/01 20:48:04 INFO TableWriter: Wrote 10 rows to sequencedetection.log_200000_113_sign_idx in 0.240 s.
21/09/01 20:48:04 INFO TableWriter: Wrote 6 rows to sequencedetection.log_200000_113_sign_idx in 0.212 s.
21/09/01 20:48:04 INFO TableWriter: Wrote 10 rows to sequencedetection.log_200000_113_sign_idx in 0.227 s.
21/09/01 20:48:04 INFO TableWriter: Wrote 7 rows to sequencedetection.log_200000_113_sign_idx in 0.102 s.
21/09/01 20:48:04 INFO TableWriter: Wrote 12 rows to sequencedetection.log_200000_113_sign_idx in 0.294 s.
21/09/01 20:48:04 INFO TableWriter: Wrote 12 rows to sequencedetection.log_200000_113_sign_idx in 0.248 s.
21/09/01 20:48:04 INFO TableWriter: Wrote 16 rows to sequencedetection.log_200000_113_sign_idx in 0.160 s.
21/09/01 20:48:04 INFO TableWriter: Wrote 14 rows to sequencedetection.log_200000_113_sign_idx in 0.076 s.
21/09/01 20:48:04 INFO TableWriter: Wrote 19 rows to sequencedetection.log_200000_113_sign_idx in 0.219 s.
21/09/01 20:48:04 INFO TableWriter: Wrote 18 rows to sequencedetection.log_200000_113_sign_idx in 0.112 s.
21/09/01 20:48:04 INFO TableWriter: Wrote 21 rows to sequencedetection.log_200000_113_sign_idx in 0.202 s.
21/09/01 20:48:05 INFO TableWriter: Wrote 22 rows to sequencedetection.log_200000_113_sign_idx in 0.140 s.
21/09/01 20:48:05 INFO TableWriter: Wrote 18 rows to sequencedetection.log_200000_113_sign_idx in 0.130 s.
21/09/01 20:48:05 INFO TableWriter: Wrote 22 rows to sequencedetection.log_200000_113_sign_idx in 0.062 s.
21/09/01 20:48:12 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:48:13 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100_346.xes signature
21/09/01 20:48:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 20:48:19 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:48:19 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 20:48:19 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:48:19 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:48:30 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:48:31 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:48:31 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:48:31 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:48:31 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.178 s.
21/09/01 20:48:31 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.178 s.
21/09/01 20:48:31 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.181 s.
21/09/01 20:48:31 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.182 s.
21/09/01 20:48:31 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.182 s.
21/09/01 20:48:31 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_sign_seq in 0.183 s.
21/09/01 20:48:31 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.186 s.
21/09/01 20:48:31 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.187 s.
21/09/01 20:48:31 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_sign_seq in 0.188 s.
21/09/01 20:48:31 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.188 s.
21/09/01 20:48:31 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.188 s.
21/09/01 20:48:31 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.189 s.
21/09/01 20:48:31 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_sign_seq in 0.189 s.
21/09/01 20:48:31 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_sign_seq in 0.191 s.
21/09/01 20:48:31 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.191 s.
21/09/01 20:48:31 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_seq in 0.193 s.
21/09/01 20:48:32 INFO TableWriter: Wrote 1 rows to sequencedetection.log_100_346_sign_idx in 0.062 s.
21/09/01 20:48:32 INFO TableWriter: Wrote 1 rows to sequencedetection.log_100_346_sign_idx in 0.116 s.
21/09/01 20:48:32 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_346_sign_idx in 0.120 s.
21/09/01 20:48:32 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_346_sign_idx in 0.163 s.
21/09/01 20:48:32 INFO TableWriter: Wrote 3 rows to sequencedetection.log_100_346_sign_idx in 0.191 s.
21/09/01 20:48:32 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_346_sign_idx in 0.200 s.
21/09/01 20:48:32 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_sign_idx in 0.208 s.
21/09/01 20:48:32 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_sign_idx in 0.236 s.
21/09/01 20:48:32 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_sign_idx in 0.245 s.
21/09/01 20:48:32 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_sign_idx in 0.243 s.
21/09/01 20:48:32 INFO TableWriter: Wrote 5 rows to sequencedetection.log_100_346_sign_idx in 0.246 s.
21/09/01 20:48:32 INFO TableWriter: Wrote 9 rows to sequencedetection.log_100_346_sign_idx in 0.246 s.
21/09/01 20:48:32 INFO TableWriter: Wrote 4 rows to sequencedetection.log_100_346_sign_idx in 0.251 s.
21/09/01 20:48:32 INFO TableWriter: Wrote 11 rows to sequencedetection.log_100_346_sign_idx in 0.258 s.
21/09/01 20:48:32 INFO TableWriter: Wrote 14 rows to sequencedetection.log_100_346_sign_idx in 0.256 s.
21/09/01 20:48:32 INFO TableWriter: Wrote 10 rows to sequencedetection.log_100_346_sign_idx in 0.264 s.
21/09/01 20:48:39 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 20:48:40 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_10000_740.xes signature
21/09/01 20:48:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 20:48:45 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 20:48:45 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 20:48:46 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 20:48:46 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 20:48:56 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 21:45:17 ERROR Executor: Exception in task 3.0 in stage 0.0 (TID 3)
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingVector.$plus$eq(SizeTrackingVector.scala:31)
	at org.apache.spark.storage.memory.DeserializedValuesHolder.storeValue(MemoryStore.scala:665)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
21/09/01 21:45:17 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 3,5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingVector.$plus$eq(SizeTrackingVector.scala:31)
	at org.apache.spark.storage.memory.DeserializedValuesHolder.storeValue(MemoryStore.scala:665)
	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:222)
	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:286)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
21/09/01 21:45:17 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
Exception in thread "main" org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:932)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:930)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:930)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2128)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2041)
	at org.apache.spark.SparkContext$$anonfun$stop$6.apply$mcV$sp(SparkContext.scala:1949)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1948)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:575)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:944)
	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:309)
	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)
	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:151)
	at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:62)
	at org.apache.spark.rdd.OrderedRDDFunctions$$anonfun$sortByKey$1.apply(OrderedRDDFunctions.scala:61)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.OrderedRDDFunctions.sortByKey(OrderedRDDFunctions.scala:61)
	at org.apache.spark.rdd.RDD$$anonfun$sortBy$1.apply(RDD.scala:623)
	at org.apache.spark.rdd.RDD$$anonfun$sortBy$1.apply(RDD.scala:624)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.sortBy(RDD.scala:621)
	at auth.datalab.sequenceDetection.Signatures.Signature$$anonfun$main$1.apply(Signature.scala:50)
	at auth.datalab.sequenceDetection.Signatures.Signature$$anonfun$main$1.apply(Signature.scala:39)
	at org.apache.spark.sql.SparkSession.time(SparkSession.scala:677)
	at auth.datalab.sequenceDetection.Signatures.Signature$.main(Signature.scala:39)
	at auth.datalab.sequenceDetection.Main$.main(Main.scala:9)
	at auth.datalab.sequenceDetection.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
21/09/01 21:45:17 ERROR TaskSetManager: Task 3 in stage 0.0 failed 1 times; aborting job
log_10000_113.xes signature
21/09/01 21:45:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 21:45:48 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 21:45:48 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 21:45:48 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 21:45:48 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 21:45:59 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 21:46:20 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 21:46:20 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 21:46:20 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 21:46:22 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.208 s.
21/09/01 21:46:22 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.208 s.
21/09/01 21:46:22 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.209 s.
21/09/01 21:46:22 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.213 s.
21/09/01 21:46:22 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.214 s.
21/09/01 21:46:22 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.216 s.
21/09/01 21:46:22 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.219 s.
21/09/01 21:46:22 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.223 s.
21/09/01 21:46:22 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.224 s.
21/09/01 21:46:22 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.224 s.
21/09/01 21:46:22 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.224 s.
21/09/01 21:46:22 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.224 s.
21/09/01 21:46:22 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.225 s.
21/09/01 21:46:22 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.225 s.
21/09/01 21:46:22 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.226 s.
21/09/01 21:46:22 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_sign_seq in 1.231 s.
21/09/01 21:46:23 INFO TableWriter: Wrote 6 rows to sequencedetection.log_10000_113_sign_idx in 0.063 s.
21/09/01 21:46:23 INFO TableWriter: Wrote 7 rows to sequencedetection.log_10000_113_sign_idx in 0.065 s.
21/09/01 21:46:23 INFO TableWriter: Wrote 14 rows to sequencedetection.log_10000_113_sign_idx in 0.069 s.
21/09/01 21:46:23 INFO TableWriter: Wrote 7 rows to sequencedetection.log_10000_113_sign_idx in 0.084 s.
21/09/01 21:46:23 INFO TableWriter: Wrote 10 rows to sequencedetection.log_10000_113_sign_idx in 0.086 s.
21/09/01 21:46:23 INFO TableWriter: Wrote 19 rows to sequencedetection.log_10000_113_sign_idx in 0.154 s.
21/09/01 21:46:23 INFO TableWriter: Wrote 18 rows to sequencedetection.log_10000_113_sign_idx in 0.147 s.
21/09/01 21:46:23 INFO TableWriter: Wrote 12 rows to sequencedetection.log_10000_113_sign_idx in 0.166 s.
21/09/01 21:46:23 INFO TableWriter: Wrote 12 rows to sequencedetection.log_10000_113_sign_idx in 0.180 s.
21/09/01 21:46:23 INFO TableWriter: Wrote 10 rows to sequencedetection.log_10000_113_sign_idx in 0.160 s.
21/09/01 21:46:23 INFO TableWriter: Wrote 10 rows to sequencedetection.log_10000_113_sign_idx in 0.177 s.
21/09/01 21:46:23 INFO TableWriter: Wrote 16 rows to sequencedetection.log_10000_113_sign_idx in 0.182 s.
21/09/01 21:46:23 INFO TableWriter: Wrote 21 rows to sequencedetection.log_10000_113_sign_idx in 0.151 s.
21/09/01 21:46:23 INFO TableWriter: Wrote 22 rows to sequencedetection.log_10000_113_sign_idx in 0.165 s.
21/09/01 21:46:23 INFO TableWriter: Wrote 18 rows to sequencedetection.log_10000_113_sign_idx in 0.195 s.
21/09/01 21:46:23 INFO TableWriter: Wrote 21 rows to sequencedetection.log_10000_113_sign_idx in 0.194 s.
21/09/01 21:46:30 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 21:46:31 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_500_740.xes setcontainment
21/09/01 21:46:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 21:46:37 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 21:46:37 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 21:46:38 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 21:46:38 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 21:46:52 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 21:49:18 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 21:49:18 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 21:49:18 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 21:49:39 INFO TableWriter: Wrote 24205 rows to sequencedetection.log_500_740_set_idx in 20.687 s.
21/09/01 21:49:39 INFO TableWriter: Wrote 24137 rows to sequencedetection.log_500_740_set_idx in 19.509 s.
21/09/01 21:49:39 INFO TableWriter: Wrote 24267 rows to sequencedetection.log_500_740_set_idx in 20.976 s.
21/09/01 21:49:39 INFO TableWriter: Wrote 24227 rows to sequencedetection.log_500_740_set_idx in 20.871 s.
21/09/01 21:49:39 INFO TableWriter: Wrote 24216 rows to sequencedetection.log_500_740_set_idx in 19.857 s.
21/09/01 21:49:39 INFO TableWriter: Wrote 24228 rows to sequencedetection.log_500_740_set_idx in 20.818 s.
21/09/01 21:49:39 INFO TableWriter: Wrote 24372 rows to sequencedetection.log_500_740_set_idx in 20.827 s.
21/09/01 21:49:39 INFO TableWriter: Wrote 24306 rows to sequencedetection.log_500_740_set_idx in 20.829 s.
21/09/01 21:49:39 INFO TableWriter: Wrote 24446 rows to sequencedetection.log_500_740_set_idx in 20.733 s.
21/09/01 21:49:39 INFO TableWriter: Wrote 24345 rows to sequencedetection.log_500_740_set_idx in 19.678 s.
21/09/01 21:49:39 INFO TableWriter: Wrote 24304 rows to sequencedetection.log_500_740_set_idx in 19.822 s.
21/09/01 21:49:39 INFO TableWriter: Wrote 24320 rows to sequencedetection.log_500_740_set_idx in 20.767 s.
21/09/01 21:49:39 INFO TableWriter: Wrote 24350 rows to sequencedetection.log_500_740_set_idx in 19.714 s.
21/09/01 21:49:39 INFO TableWriter: Wrote 24456 rows to sequencedetection.log_500_740_set_idx in 19.993 s.
21/09/01 21:49:39 INFO TableWriter: Wrote 24688 rows to sequencedetection.log_500_740_set_idx in 20.006 s.
21/09/01 21:49:39 INFO TableWriter: Wrote 24620 rows to sequencedetection.log_500_740_set_idx in 20.029 s.
21/09/01 21:49:45 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 21:49:45 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 21:49:45 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 21:49:45 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.164 s.
21/09/01 21:49:45 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_740_set_seq in 0.172 s.
21/09/01 21:49:45 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_740_set_seq in 0.211 s.
21/09/01 21:49:45 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.223 s.
21/09/01 21:49:45 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.227 s.
21/09/01 21:49:45 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.223 s.
21/09/01 21:49:45 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.237 s.
21/09/01 21:49:45 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.229 s.
21/09/01 21:49:45 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.223 s.
21/09/01 21:49:45 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.230 s.
21/09/01 21:49:45 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.239 s.
21/09/01 21:49:45 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_740_set_seq in 0.235 s.
21/09/01 21:49:45 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.221 s.
21/09/01 21:49:45 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_740_set_seq in 0.239 s.
21/09/01 21:49:45 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.236 s.
21/09/01 21:49:45 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_740_set_seq in 0.236 s.
21/09/01 21:49:46 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 21:49:52 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 21:49:53 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_10000_346.xes setcontainment
21/09/01 21:49:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 21:50:00 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 21:50:00 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 21:50:00 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 21:50:00 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 21:50:10 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 21:50:30 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 21:50:30 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 21:50:30 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 21:50:38 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 22:33:22 ERROR Executor: Exception in task 4.0 in stage 1.0 (TID 20)
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at scala.collection.immutable.List.writeReplace(List.scala:418)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeWriteReplace(ObjectStreamClass.java:1244)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1136)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at scala.collection.immutable.List$SerializationProxy.writeObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:1154)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:241)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.org$apache$spark$util$collection$ExternalAppendOnlyMap$$spillMemoryIteratorToDisk(ExternalAppendOnlyMap.scala:236)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.spill(ExternalAppendOnlyMap.scala:188)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.spill(ExternalAppendOnlyMap.scala:55)
	at org.apache.spark.util.collection.Spillable.maybeSpill(Spillable.scala:98)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:162)
21/09/01 22:33:40 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 20,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at scala.collection.immutable.List.writeReplace(List.scala:418)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeWriteReplace(ObjectStreamClass.java:1244)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1136)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at scala.collection.immutable.List$SerializationProxy.writeObject(List.scala:479)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:1154)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1496)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)
	at org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:43)
	at org.apache.spark.serializer.SerializationStream.writeValue(Serializer.scala:134)
	at org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:241)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.org$apache$spark$util$collection$ExternalAppendOnlyMap$$spillMemoryIteratorToDisk(ExternalAppendOnlyMap.scala:236)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.spill(ExternalAppendOnlyMap.scala:188)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.spill(ExternalAppendOnlyMap.scala:55)
	at org.apache.spark.util.collection.Spillable.maybeSpill(Spillable.scala:98)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:162)
21/09/01 22:33:40 ERROR TaskSetManager: Task 4 in stage 1.0 failed 1 times; aborting job
21/09/01 22:33:40 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
Exception in thread "main" java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
auth.datalab.sequenceDetection.CassandraConnectionTrait$class.startSpark(CassandraConnectionTrait.scala:58)
auth.datalab.sequenceDetection.SetContainment.CassandraSetContainment.startSpark(CassandraSetContainment.scala:11)
auth.datalab.sequenceDetection.SetContainment.SetContainment$.main(SetContainment.scala:25)
auth.datalab.sequenceDetection.Main$.main(Main.scala:11)
auth.datalab.sequenceDetection.Main.main(Main.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

The currently active SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
auth.datalab.sequenceDetection.CassandraConnectionTrait$class.startSpark(CassandraConnectionTrait.scala:58)
auth.datalab.sequenceDetection.SetContainment.CassandraSetContainment.startSpark(CassandraSetContainment.scala:11)
auth.datalab.sequenceDetection.SetContainment.SetContainment$.main(SetContainment.scala:25)
auth.datalab.sequenceDetection.Main$.main(Main.scala:11)
auth.datalab.sequenceDetection.Main.main(Main.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
         
	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:100)
	at org.apache.spark.sql.SparkSession.<init>(SparkSession.scala:91)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:957)
	at auth.datalab.sequenceDetection.CassandraConnectionTrait$class.closeSpark(CassandraConnectionTrait.scala:79)
	at auth.datalab.sequenceDetection.SetContainment.CassandraSetContainment.closeSpark(CassandraSetContainment.scala:11)
	at auth.datalab.sequenceDetection.SetContainment.SetContainment$.main(SetContainment.scala:53)
	at auth.datalab.sequenceDetection.Main$.main(Main.scala:11)
	at auth.datalab.sequenceDetection.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
log_1000_740.xes setcontainment
21/09/01 22:33:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 22:33:53 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 22:33:53 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 22:33:54 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 22:33:54 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 22:34:03 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 22:34:03 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 22:34:03 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 22:34:03 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 22:34:10 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 22:41:28 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 22:41:28 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 22:41:28 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 22:42:05 INFO TableWriter: Wrote 24573 rows to sequencedetection.log_1000_740_set_idx in 37.416 s.
21/09/01 22:42:05 INFO TableWriter: Wrote 24666 rows to sequencedetection.log_1000_740_set_idx in 36.980 s.
21/09/01 22:42:05 INFO TableWriter: Wrote 24702 rows to sequencedetection.log_1000_740_set_idx in 37.196 s.
21/09/01 22:42:05 INFO TableWriter: Wrote 24552 rows to sequencedetection.log_1000_740_set_idx in 36.842 s.
21/09/01 22:42:05 INFO TableWriter: Wrote 24856 rows to sequencedetection.log_1000_740_set_idx in 37.012 s.
21/09/01 22:42:05 INFO TableWriter: Wrote 24597 rows to sequencedetection.log_1000_740_set_idx in 37.165 s.
21/09/01 22:42:05 INFO TableWriter: Wrote 24586 rows to sequencedetection.log_1000_740_set_idx in 36.497 s.
21/09/01 22:42:05 INFO TableWriter: Wrote 24703 rows to sequencedetection.log_1000_740_set_idx in 36.460 s.
21/09/01 22:42:05 INFO TableWriter: Wrote 24805 rows to sequencedetection.log_1000_740_set_idx in 36.902 s.
21/09/01 22:42:05 INFO TableWriter: Wrote 24585 rows to sequencedetection.log_1000_740_set_idx in 35.793 s.
21/09/01 22:42:05 INFO TableWriter: Wrote 24503 rows to sequencedetection.log_1000_740_set_idx in 35.567 s.
21/09/01 22:42:05 INFO TableWriter: Wrote 24713 rows to sequencedetection.log_1000_740_set_idx in 35.835 s.
21/09/01 22:42:05 INFO TableWriter: Wrote 24696 rows to sequencedetection.log_1000_740_set_idx in 35.521 s.
21/09/01 22:42:05 INFO TableWriter: Wrote 24952 rows to sequencedetection.log_1000_740_set_idx in 36.581 s.
21/09/01 22:42:05 INFO TableWriter: Wrote 24670 rows to sequencedetection.log_1000_740_set_idx in 35.482 s.
21/09/01 22:42:08 INFO TableWriter: Wrote 25062 rows to sequencedetection.log_1000_740_set_idx in 17.298 s.
21/09/01 22:42:14 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_740_set_seq in 0.346 s.
21/09/01 22:42:14 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_740_set_seq in 0.368 s.
21/09/01 22:42:14 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_set_seq in 0.373 s.
21/09/01 22:42:14 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_set_seq in 0.369 s.
21/09/01 22:42:14 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_set_seq in 0.360 s.
21/09/01 22:42:14 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_740_set_seq in 0.386 s.
21/09/01 22:42:14 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_740_set_seq in 0.376 s.
21/09/01 22:42:14 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_740_set_seq in 0.390 s.
21/09/01 22:42:14 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_740_set_seq in 0.384 s.
21/09/01 22:42:14 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_740_set_seq in 0.390 s.
21/09/01 22:42:14 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_740_set_seq in 0.393 s.
21/09/01 22:42:14 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_set_seq in 0.395 s.
21/09/01 22:42:14 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_set_seq in 0.396 s.
21/09/01 22:42:14 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_set_seq in 0.392 s.
21/09/01 22:42:14 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_set_seq in 0.393 s.
21/09/01 22:42:14 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_740_set_seq in 0.555 s.
21/09/01 22:42:21 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 22:42:22 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100000_346.xes setcontainment
21/09/01 22:42:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/01 22:42:28 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 22:42:28 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/01 22:42:29 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 22:42:29 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 22:42:38 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/01 22:46:41 INFO ClockFactory: Using native clock to generate timestamps.
21/09/01 22:46:41 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/01 22:46:41 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/01 22:46:49 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 00:59:14 ERROR TaskSchedulerImpl: Lost executor driver on localhost: Executor heartbeat timed out after 228500 ms
21/09/02 06:16:58 ERROR TaskSetManager: Task 7 in stage 1.0 failed 1 times; aborting job
21/09/02 08:17:20 ERROR Executor: Exception in task 15.0 in stage 1.0 (TID 31)
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$$anonfun$sampleArray$1.apply$mcVI$sp(SizeEstimator.scala:285)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:261)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:165)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
21/09/02 08:17:20 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 31,5,main]
java.lang.OutOfMemoryError: Java heap space
	at java.util.IdentityHashMap.resize(IdentityHashMap.java:472)
	at java.util.IdentityHashMap.put(IdentityHashMap.java:441)
	at org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:225)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitSingleObject$1.apply(SizeEstimator.scala:224)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$$anonfun$sampleArray$1.apply$mcVI$sp(SizeEstimator.scala:285)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)
	at org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:261)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:165)
	at org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:84)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)
	at org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)
	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
21/09/02 08:17:20 ERROR TaskSchedulerImpl: Ignoring update with state FAILED for TID 31 because its task set is gone (this is likely the result of receiving duplicate task finished status updates) or its executor has been marked as failed.
21/09/02 08:17:20 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
21/09/02 08:17:20 ERROR BlockManager: Failed to report rdd_0_5 to master; giving up.
log_1000_346.xes setcontainment
21/09/02 08:17:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/02 08:17:41 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 08:17:41 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/02 08:17:42 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 08:17:42 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 08:17:56 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 08:18:56 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 08:18:56 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 08:18:56 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 08:19:03 INFO TableWriter: Wrote 4314 rows to sequencedetection.log_1000_346_set_idx in 7.032 s.
21/09/02 08:19:03 INFO TableWriter: Wrote 4235 rows to sequencedetection.log_1000_346_set_idx in 6.632 s.
21/09/02 08:19:03 INFO TableWriter: Wrote 4281 rows to sequencedetection.log_1000_346_set_idx in 6.572 s.
21/09/02 08:19:03 INFO TableWriter: Wrote 4248 rows to sequencedetection.log_1000_346_set_idx in 6.785 s.
21/09/02 08:19:03 INFO TableWriter: Wrote 4287 rows to sequencedetection.log_1000_346_set_idx in 6.421 s.
21/09/02 08:19:03 INFO TableWriter: Wrote 4276 rows to sequencedetection.log_1000_346_set_idx in 6.944 s.
21/09/02 08:19:03 INFO TableWriter: Wrote 4326 rows to sequencedetection.log_1000_346_set_idx in 6.410 s.
21/09/02 08:19:03 INFO TableWriter: Wrote 4432 rows to sequencedetection.log_1000_346_set_idx in 6.874 s.
21/09/02 08:19:03 INFO TableWriter: Wrote 4303 rows to sequencedetection.log_1000_346_set_idx in 6.961 s.
21/09/02 08:19:03 INFO TableWriter: Wrote 4395 rows to sequencedetection.log_1000_346_set_idx in 6.522 s.
21/09/02 08:19:03 INFO TableWriter: Wrote 4350 rows to sequencedetection.log_1000_346_set_idx in 6.755 s.
21/09/02 08:19:03 INFO TableWriter: Wrote 4308 rows to sequencedetection.log_1000_346_set_idx in 6.232 s.
21/09/02 08:19:03 INFO TableWriter: Wrote 4399 rows to sequencedetection.log_1000_346_set_idx in 6.589 s.
21/09/02 08:19:03 INFO TableWriter: Wrote 4435 rows to sequencedetection.log_1000_346_set_idx in 6.366 s.
21/09/02 08:19:03 INFO TableWriter: Wrote 4433 rows to sequencedetection.log_1000_346_set_idx in 6.550 s.
21/09/02 08:19:03 INFO TableWriter: Wrote 4410 rows to sequencedetection.log_1000_346_set_idx in 6.078 s.
21/09/02 08:19:04 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_set_seq in 0.182 s.
21/09/02 08:19:04 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_set_seq in 0.169 s.
21/09/02 08:19:04 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_set_seq in 0.190 s.
21/09/02 08:19:04 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_set_seq in 0.218 s.
21/09/02 08:19:04 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_set_seq in 0.218 s.
21/09/02 08:19:04 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_set_seq in 0.200 s.
21/09/02 08:19:04 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_set_seq in 0.213 s.
21/09/02 08:19:04 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_set_seq in 0.218 s.
21/09/02 08:19:04 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_set_seq in 0.219 s.
21/09/02 08:19:04 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_set_seq in 0.222 s.
21/09/02 08:19:04 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_set_seq in 0.222 s.
21/09/02 08:19:04 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_set_seq in 0.211 s.
21/09/02 08:19:04 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_346_set_seq in 0.214 s.
21/09/02 08:19:04 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_set_seq in 0.200 s.
21/09/02 08:19:04 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_set_seq in 0.218 s.
21/09/02 08:19:04 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_346_set_seq in 0.219 s.
21/09/02 08:19:11 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 08:19:12 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100_740.xes setcontainment
21/09/02 08:19:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/02 08:19:18 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 08:19:18 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/02 08:19:19 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 08:19:19 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 08:19:31 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 08:20:02 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 08:20:02 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 08:20:02 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 08:20:12 INFO TableWriter: Wrote 21470 rows to sequencedetection.log_100_740_set_idx in 10.197 s.
21/09/02 08:20:12 INFO TableWriter: Wrote 21490 rows to sequencedetection.log_100_740_set_idx in 10.246 s.
21/09/02 08:20:12 INFO TableWriter: Wrote 21474 rows to sequencedetection.log_100_740_set_idx in 10.292 s.
21/09/02 08:20:12 INFO TableWriter: Wrote 21519 rows to sequencedetection.log_100_740_set_idx in 10.247 s.
21/09/02 08:20:12 INFO TableWriter: Wrote 21464 rows to sequencedetection.log_100_740_set_idx in 10.290 s.
21/09/02 08:20:12 INFO TableWriter: Wrote 21615 rows to sequencedetection.log_100_740_set_idx in 10.261 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 21506 rows to sequencedetection.log_100_740_set_idx in 10.276 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 21579 rows to sequencedetection.log_100_740_set_idx in 10.216 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 21679 rows to sequencedetection.log_100_740_set_idx in 10.330 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 21677 rows to sequencedetection.log_100_740_set_idx in 10.305 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 21570 rows to sequencedetection.log_100_740_set_idx in 10.322 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 21532 rows to sequencedetection.log_100_740_set_idx in 10.227 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 21775 rows to sequencedetection.log_100_740_set_idx in 10.355 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 21592 rows to sequencedetection.log_100_740_set_idx in 10.245 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 21796 rows to sequencedetection.log_100_740_set_idx in 10.290 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 21962 rows to sequencedetection.log_100_740_set_idx in 10.348 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.043 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.042 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_set_seq in 0.077 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.084 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_set_seq in 0.084 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.088 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.089 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.088 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.088 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.089 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.089 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_set_seq in 0.089 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.093 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.092 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_740_set_seq in 0.091 s.
21/09/02 08:20:13 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_740_set_seq in 0.095 s.
21/09/02 08:20:20 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 08:20:21 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_500_346.xes setcontainment
21/09/02 08:20:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/02 08:20:27 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 08:20:27 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/02 08:20:28 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 08:20:28 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 08:20:41 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 08:21:14 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 08:21:14 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 08:21:14 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 08:21:18 INFO TableWriter: Wrote 4281 rows to sequencedetection.log_500_346_set_idx in 4.526 s.
21/09/02 08:21:18 INFO TableWriter: Wrote 4249 rows to sequencedetection.log_500_346_set_idx in 4.612 s.
21/09/02 08:21:18 INFO TableWriter: Wrote 4314 rows to sequencedetection.log_500_346_set_idx in 4.632 s.
21/09/02 08:21:18 INFO TableWriter: Wrote 4310 rows to sequencedetection.log_500_346_set_idx in 4.464 s.
21/09/02 08:21:18 INFO TableWriter: Wrote 4296 rows to sequencedetection.log_500_346_set_idx in 4.355 s.
21/09/02 08:21:18 INFO TableWriter: Wrote 4408 rows to sequencedetection.log_500_346_set_idx in 4.282 s.
21/09/02 08:21:18 INFO TableWriter: Wrote 4341 rows to sequencedetection.log_500_346_set_idx in 4.454 s.
21/09/02 08:21:18 INFO TableWriter: Wrote 4339 rows to sequencedetection.log_500_346_set_idx in 4.665 s.
21/09/02 08:21:18 INFO TableWriter: Wrote 4327 rows to sequencedetection.log_500_346_set_idx in 4.420 s.
21/09/02 08:21:18 INFO TableWriter: Wrote 4441 rows to sequencedetection.log_500_346_set_idx in 4.311 s.
21/09/02 08:21:18 INFO TableWriter: Wrote 4399 rows to sequencedetection.log_500_346_set_idx in 4.250 s.
21/09/02 08:21:18 INFO TableWriter: Wrote 4426 rows to sequencedetection.log_500_346_set_idx in 4.279 s.
21/09/02 08:21:18 INFO TableWriter: Wrote 4378 rows to sequencedetection.log_500_346_set_idx in 4.204 s.
21/09/02 08:21:18 INFO TableWriter: Wrote 4439 rows to sequencedetection.log_500_346_set_idx in 4.492 s.
21/09/02 08:21:18 INFO TableWriter: Wrote 4342 rows to sequencedetection.log_500_346_set_idx in 4.633 s.
21/09/02 08:21:18 INFO TableWriter: Wrote 4458 rows to sequencedetection.log_500_346_set_idx in 4.345 s.
21/09/02 08:21:19 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.096 s.
21/09/02 08:21:19 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.125 s.
21/09/02 08:21:19 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.120 s.
21/09/02 08:21:19 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.138 s.
21/09/02 08:21:19 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.134 s.
21/09/02 08:21:19 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.133 s.
21/09/02 08:21:19 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_set_seq in 0.142 s.
21/09/02 08:21:19 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_set_seq in 0.142 s.
21/09/02 08:21:19 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_set_seq in 0.125 s.
21/09/02 08:21:19 INFO TableWriter: Wrote 32 rows to sequencedetection.log_500_346_set_seq in 0.124 s.
21/09/02 08:21:19 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.124 s.
21/09/02 08:21:19 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.142 s.
21/09/02 08:21:19 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.135 s.
21/09/02 08:21:19 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.146 s.
21/09/02 08:21:19 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.128 s.
21/09/02 08:21:19 INFO TableWriter: Wrote 31 rows to sequencedetection.log_500_346_set_seq in 0.126 s.
21/09/02 08:21:26 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 08:21:27 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100000_113.xes setcontainment
21/09/02 08:21:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/02 08:21:33 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 08:21:33 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/02 08:21:34 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 08:21:34 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 08:21:43 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 08:22:23 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 08:22:23 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 08:22:23 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 08:22:32 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 08:33:39 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 08:33:39 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 08:33:39 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 08:33:44 INFO TableWriter: Wrote 326 rows to sequencedetection.log_100000_113_set_idx in 4.940 s.
21/09/02 08:33:51 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 08:34:00 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 08:34:00 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 08:34:00 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 08:34:04 INFO TableWriter: Wrote 360 rows to sequencedetection.log_100000_113_set_idx in 4.396 s.
21/09/02 08:34:07 INFO TableWriter: Wrote 314 rows to sequencedetection.log_100000_113_set_idx in 4.497 s.
21/09/02 08:34:12 INFO TableWriter: Wrote 296 rows to sequencedetection.log_100000_113_set_idx in 3.819 s.
21/09/02 08:34:15 INFO TableWriter: Wrote 311 rows to sequencedetection.log_100000_113_set_idx in 4.069 s.
21/09/02 08:34:18 INFO TableWriter: Wrote 334 rows to sequencedetection.log_100000_113_set_idx in 4.624 s.
21/09/02 08:34:20 INFO TableWriter: Wrote 327 rows to sequencedetection.log_100000_113_set_idx in 4.347 s.
21/09/02 08:34:27 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 08:34:29 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 08:34:30 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 08:34:30 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 08:34:33 INFO TableWriter: Wrote 298 rows to sequencedetection.log_100000_113_set_idx in 3.375 s.
21/09/02 08:34:35 INFO TableWriter: Wrote 302 rows to sequencedetection.log_100000_113_set_idx in 2.953 s.
21/09/02 08:34:39 INFO TableWriter: Wrote 329 rows to sequencedetection.log_100000_113_set_idx in 3.292 s.
21/09/02 08:34:41 INFO TableWriter: Wrote 337 rows to sequencedetection.log_100000_113_set_idx in 3.632 s.
21/09/02 08:34:47 INFO TableWriter: Wrote 345 rows to sequencedetection.log_100000_113_set_idx in 3.485 s.
21/09/02 08:34:48 INFO TableWriter: Wrote 321 rows to sequencedetection.log_100000_113_set_idx in 3.634 s.
21/09/02 08:34:50 INFO TableWriter: Wrote 349 rows to sequencedetection.log_100000_113_set_idx in 3.857 s.
21/09/02 08:34:50 INFO TableWriter: Wrote 353 rows to sequencedetection.log_100000_113_set_idx in 3.836 s.
21/09/02 08:34:53 INFO TableWriter: Wrote 321 rows to sequencedetection.log_100000_113_set_idx in 2.424 s.
21/09/02 08:35:11 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_set_seq in 14.097 s.
21/09/02 08:35:11 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_set_seq in 14.044 s.
21/09/02 08:35:11 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_set_seq in 14.012 s.
21/09/02 08:35:11 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_set_seq in 14.093 s.
21/09/02 08:35:11 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_set_seq in 14.139 s.
21/09/02 08:35:11 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_set_seq in 14.165 s.
21/09/02 08:35:11 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_set_seq in 14.169 s.
21/09/02 08:35:11 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_set_seq in 14.140 s.
21/09/02 08:35:11 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_set_seq in 14.207 s.
21/09/02 08:35:11 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_set_seq in 14.250 s.
21/09/02 08:35:11 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_set_seq in 14.244 s.
21/09/02 08:35:11 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_set_seq in 14.225 s.
21/09/02 08:35:11 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_set_seq in 14.271 s.
21/09/02 08:35:11 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_set_seq in 14.327 s.
21/09/02 08:35:11 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_set_seq in 14.268 s.
21/09/02 08:35:11 INFO TableWriter: Wrote 6250 rows to sequencedetection.log_100000_113_set_seq in 14.368 s.
21/09/02 08:35:18 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 08:35:19 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100_113.xes setcontainment
21/09/02 08:35:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/02 08:35:26 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 08:35:26 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/02 08:35:27 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 08:35:27 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 08:35:34 INFO TableWriter: Wrote 256 rows to sequencedetection.log_100_113_set_idx in 0.680 s.
21/09/02 08:35:34 INFO TableWriter: Wrote 260 rows to sequencedetection.log_100_113_set_idx in 0.699 s.
21/09/02 08:35:34 INFO TableWriter: Wrote 254 rows to sequencedetection.log_100_113_set_idx in 0.672 s.
21/09/02 08:35:34 INFO TableWriter: Wrote 262 rows to sequencedetection.log_100_113_set_idx in 0.703 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 277 rows to sequencedetection.log_100_113_set_idx in 0.696 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 280 rows to sequencedetection.log_100_113_set_idx in 0.683 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 279 rows to sequencedetection.log_100_113_set_idx in 0.658 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 280 rows to sequencedetection.log_100_113_set_idx in 0.694 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 295 rows to sequencedetection.log_100_113_set_idx in 0.687 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 293 rows to sequencedetection.log_100_113_set_idx in 0.704 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 290 rows to sequencedetection.log_100_113_set_idx in 0.720 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 303 rows to sequencedetection.log_100_113_set_idx in 0.728 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 304 rows to sequencedetection.log_100_113_set_idx in 0.730 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 289 rows to sequencedetection.log_100_113_set_idx in 0.735 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 311 rows to sequencedetection.log_100_113_set_idx in 0.735 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 318 rows to sequencedetection.log_100_113_set_idx in 0.733 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.014 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_set_seq in 0.020 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.025 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.018 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.030 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.018 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.020 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_set_seq in 0.028 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.039 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.044 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.036 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_set_seq in 0.046 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.036 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.048 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_113_set_seq in 0.052 s.
21/09/02 08:35:35 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_113_set_seq in 0.037 s.
21/09/02 08:35:42 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 08:35:43 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_1000_113.xes setcontainment
21/09/02 08:35:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/02 08:35:48 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 08:35:48 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/02 08:35:49 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 08:35:49 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 08:35:59 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 08:35:59 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 08:35:59 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 08:36:00 INFO TableWriter: Wrote 292 rows to sequencedetection.log_1000_113_set_idx in 0.912 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 295 rows to sequencedetection.log_1000_113_set_idx in 0.733 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 299 rows to sequencedetection.log_1000_113_set_idx in 0.753 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 311 rows to sequencedetection.log_1000_113_set_idx in 1.020 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 322 rows to sequencedetection.log_1000_113_set_idx in 1.028 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 315 rows to sequencedetection.log_1000_113_set_idx in 0.648 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 322 rows to sequencedetection.log_1000_113_set_idx in 0.693 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 307 rows to sequencedetection.log_1000_113_set_idx in 0.871 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 333 rows to sequencedetection.log_1000_113_set_idx in 0.654 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 323 rows to sequencedetection.log_1000_113_set_idx in 0.729 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 333 rows to sequencedetection.log_1000_113_set_idx in 0.852 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 320 rows to sequencedetection.log_1000_113_set_idx in 0.640 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 349 rows to sequencedetection.log_1000_113_set_idx in 0.751 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 343 rows to sequencedetection.log_1000_113_set_idx in 0.697 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 355 rows to sequencedetection.log_1000_113_set_idx in 0.730 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 342 rows to sequencedetection.log_1000_113_set_idx in 0.581 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_set_seq in 0.108 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_set_seq in 0.119 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_set_seq in 0.120 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_set_seq in 0.129 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_set_seq in 0.130 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_set_seq in 0.121 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_set_seq in 0.108 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_set_seq in 0.106 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_set_seq in 0.122 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_set_seq in 0.136 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_set_seq in 0.138 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_set_seq in 0.127 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_set_seq in 0.131 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_set_seq in 0.133 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 62 rows to sequencedetection.log_1000_113_set_seq in 0.143 s.
21/09/02 08:36:00 INFO TableWriter: Wrote 63 rows to sequencedetection.log_1000_113_set_seq in 0.142 s.
21/09/02 08:36:01 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 08:36:07 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 08:36:08 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_200000_113.xes setcontainment
21/09/02 08:36:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/02 08:36:14 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 08:36:14 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/02 08:36:15 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 08:36:15 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 08:36:24 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 08:37:50 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 08:37:50 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 08:37:50 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 08:37:57 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 09:15:30 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 09:15:30 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 09:15:30 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 09:15:41 INFO TableWriter: Wrote 326 rows to sequencedetection.log_200000_113_set_idx in 11.859 s.
21/09/02 09:15:49 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 09:16:14 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 09:16:14 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 09:16:14 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 09:16:24 INFO TableWriter: Wrote 360 rows to sequencedetection.log_200000_113_set_idx in 9.454 s.
21/09/02 09:16:30 INFO TableWriter: Wrote 314 rows to sequencedetection.log_200000_113_set_idx in 10.175 s.
21/09/02 09:16:36 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 09:16:36 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 09:16:36 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 09:17:02 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 09:17:07 INFO TableWriter: Wrote 296 rows to sequencedetection.log_200000_113_set_idx in 31.279 s.
21/09/02 09:17:13 INFO TableWriter: Wrote 311 rows to sequencedetection.log_200000_113_set_idx in 7.431 s.
21/09/02 09:17:22 INFO TableWriter: Wrote 327 rows to sequencedetection.log_200000_113_set_idx in 7.173 s.
21/09/02 09:17:30 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 09:18:04 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 09:18:04 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 09:18:04 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 09:18:12 INFO TableWriter: Wrote 337 rows to sequencedetection.log_200000_113_set_idx in 7.452 s.
21/09/02 09:18:19 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 09:18:24 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 09:18:24 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 09:18:24 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 09:18:37 WARN RequestHandler: Not retrying statement because it is not idempotent (this message will be logged only once). Note that this version of the driver changes the default retry behavior for non-idempotent statements: they won't be automatically retried anymore. The driver marks statements non-idempotent by default, so you should explicitly call setIdempotent(true) if your statements are safe to retry. See http://goo.gl/4HrSby for more details.
21/09/02 09:18:37 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@243cefc8
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:37 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@3305503e
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:37 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@57cfc358
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:37 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@63f2889b
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:37 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@280d744d
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:37 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@175d3687
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:37 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@7524ae2b
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:37 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@6a341f17
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:37 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@658f04cd
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:37 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@6d8875d9
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:40 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@160f9842
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:40 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@1cc0cede
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@3e48544d
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2f5e8221
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:41 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@12ce9835
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 18 more
21/09/02 09:18:42 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@21f5814
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:42 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@5d4c9072
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 18 more
21/09/02 09:18:42 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@560b3562
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 18 more
21/09/02 09:18:43 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@6a42e105
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:43 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@7e2aafa5
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:43 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@22aabdb3
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:44 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@34421488
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 18 more
21/09/02 09:18:45 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@7fb2f16d
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 18 more
21/09/02 09:18:45 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@422fb12c
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 18 more
21/09/02 09:18:45 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@1b0e7d24
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:45 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@2c5b0308
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 18 more
21/09/02 09:18:46 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@40804dc0
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:46 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@62545afa
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:297)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:413)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 20 more
21/09/02 09:18:47 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@55e2bd2e
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 18 more
21/09/02 09:18:47 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@9ffd641
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 18 more
21/09/02 09:18:47 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@6f9daef5
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 18 more
21/09/02 09:18:47 ERROR QueryExecutor: Failed to execute: com.datastax.spark.connector.writer.RichBoundStatement@25465db2
com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:100)
	at com.datastax.driver.core.Responses$Error.asException(Responses.java:122)
	at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:506)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)
	at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:59)
	at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)
	at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)
	... 18 more
21/09/02 09:18:48 ERROR Executor: Exception in task 5.0 in stage 1.0 (TID 21)
java.io.IOException: Failed to write statements to sequencedetection.log_200000_113_set_idx. The
latest exception was
  Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)

Please check the executor logs for more exceptions and information
             
	at com.datastax.spark.connector.writer.TableWriter$$anonfun$writeInternal$1$$anonfun$apply$3.apply(TableWriter.scala:243)
	at com.datastax.spark.connector.writer.TableWriter$$anonfun$writeInternal$1$$anonfun$apply$3.apply(TableWriter.scala:241)
	at scala.Option.map(Option.scala:146)
	at com.datastax.spark.connector.writer.TableWriter$$anonfun$writeInternal$1.apply(TableWriter.scala:241)
	at com.datastax.spark.connector.writer.TableWriter$$anonfun$writeInternal$1.apply(TableWriter.scala:210)
	at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$withSessionDo$1.apply(CassandraConnector.scala:112)
	at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$withSessionDo$1.apply(CassandraConnector.scala:111)
	at com.datastax.spark.connector.cql.CassandraConnector.closeResourceAfterUse(CassandraConnector.scala:145)
	at com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:111)
	at com.datastax.spark.connector.writer.TableWriter.writeInternal(TableWriter.scala:210)
	at com.datastax.spark.connector.writer.TableWriter.update(TableWriter.scala:191)
	at com.datastax.spark.connector.writer.TableWriter.write(TableWriter.scala:180)
	at com.datastax.spark.connector.RDDFunctions$$anonfun$saveToCassandra$1.apply(RDDFunctions.scala:36)
	at com.datastax.spark.connector.RDDFunctions$$anonfun$saveToCassandra$1.apply(RDDFunctions.scala:36)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/09/02 09:18:48 ERROR TaskSetManager: Task 5 in stage 1.0 failed 1 times; aborting job
21/09/02 09:18:49 ERROR Utils: Uncaught exception in thread Executor task launch worker for task 22
java.lang.NullPointerException
	at org.apache.spark.scheduler.Task$$anonfun$run$1.apply$mcV$sp(Task.scala:144)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.scheduler.Task.run(Task.scala:142)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/09/02 09:18:50 ERROR Utils: Uncaught exception in thread Executor task launch worker for task 19
java.lang.NullPointerException
	at org.apache.spark.scheduler.Task$$anonfun$run$1.apply$mcV$sp(Task.scala:144)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.scheduler.Task.run(Task.scala:142)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
21/09/02 09:18:56 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 09:18:57 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_100_346.xes setcontainment
21/09/02 09:19:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/02 09:19:09 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 09:19:09 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/02 09:19:09 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 09:19:09 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 09:19:21 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 09:19:25 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 09:19:25 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 09:19:25 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 09:19:28 INFO TableWriter: Wrote 3973 rows to sequencedetection.log_100_346_set_idx in 2.832 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 3989 rows to sequencedetection.log_100_346_set_idx in 2.869 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 4025 rows to sequencedetection.log_100_346_set_idx in 2.826 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 4058 rows to sequencedetection.log_100_346_set_idx in 2.798 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 4033 rows to sequencedetection.log_100_346_set_idx in 2.889 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 4039 rows to sequencedetection.log_100_346_set_idx in 2.888 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 4045 rows to sequencedetection.log_100_346_set_idx in 2.810 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 4041 rows to sequencedetection.log_100_346_set_idx in 2.818 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 4054 rows to sequencedetection.log_100_346_set_idx in 2.873 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 4092 rows to sequencedetection.log_100_346_set_idx in 2.842 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 4115 rows to sequencedetection.log_100_346_set_idx in 2.797 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 4178 rows to sequencedetection.log_100_346_set_idx in 2.802 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 4127 rows to sequencedetection.log_100_346_set_idx in 2.909 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 4166 rows to sequencedetection.log_100_346_set_idx in 2.812 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 4192 rows to sequencedetection.log_100_346_set_idx in 2.802 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 4120 rows to sequencedetection.log_100_346_set_idx in 2.886 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.021 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.027 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.043 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_set_seq in 0.042 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_set_seq in 0.044 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.039 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.055 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.055 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.057 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_set_seq in 0.058 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 7 rows to sequencedetection.log_100_346_set_seq in 0.051 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.059 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.056 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.060 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.062 s.
21/09/02 09:19:28 INFO TableWriter: Wrote 6 rows to sequencedetection.log_100_346_set_seq in 0.069 s.
21/09/02 09:19:35 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 09:19:36 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
log_10000_740.xes setcontainment
21/09/02 09:19:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/02 09:19:42 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 09:19:42 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/02 09:19:43 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 09:19:43 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 09:19:52 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 09:20:43 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 09:20:43 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 09:20:43 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 09:20:51 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 10:49:07 ERROR Executor: Exception in task 5.0 in stage 1.0 (TID 21)
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.util.Arrays.copyOfRange(Arrays.java:3664)
	at java.lang.String.<init>(String.java:207)
	at java.lang.StringBuilder.toString(StringBuilder.java:407)
	at java.io.ObjectInputStream$BlockDataInputStream.readUTFBody(ObjectInputStream.java:3557)
	at java.io.ObjectInputStream$BlockDataInputStream.readUTF(ObjectInputStream.java:3344)
	at java.io.ObjectInputStream.readString(ObjectInputStream.java:2023)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1649)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
21/09/02 10:50:37 ERROR Executor: Exception in task 2.0 in stage 1.0 (TID 18)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/02 10:49:07 ERROR Executor: Exception in task 3.0 in stage 1.0 (TID 19)
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:158)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:188)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:185)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)
21/09/02 10:49:07 ERROR Executor: Exception in task 6.0 in stage 1.0 (TID 22)
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/02 10:49:07 ERROR Executor: Exception in task 13.0 in stage 1.0 (TID 29)
java.lang.OutOfMemoryError: GC overhead limit exceeded
Exception in thread "Executor task launch worker for task 18" java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/02 10:53:26 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 29,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/02 10:53:26 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 19,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:75)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:158)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:188)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:185)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)
21/09/02 10:53:26 ERROR TaskSetManager: Task 5 in stage 1.0 failed 1 times; aborting job
21/09/02 10:53:26 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 21,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.util.Arrays.copyOfRange(Arrays.java:3664)
	at java.lang.String.<init>(String.java:207)
	at java.lang.StringBuilder.toString(StringBuilder.java:407)
	at java.io.ObjectInputStream$BlockDataInputStream.readUTFBody(ObjectInputStream.java:3557)
	at java.io.ObjectInputStream$BlockDataInputStream.readUTF(ObjectInputStream.java:3344)
	at java.io.ObjectInputStream.readString(ObjectInputStream.java:2023)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1649)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2329)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:490)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2296)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2187)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1667)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2405)
21/09/02 10:53:26 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 22,5,main]
java.lang.OutOfMemoryError: GC overhead limit exceeded
21/09/02 10:53:26 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
Exception in thread "main" java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
auth.datalab.sequenceDetection.CassandraConnectionTrait$class.startSpark(CassandraConnectionTrait.scala:58)
auth.datalab.sequenceDetection.SetContainment.CassandraSetContainment.startSpark(CassandraSetContainment.scala:11)
auth.datalab.sequenceDetection.SetContainment.SetContainment$.main(SetContainment.scala:25)
auth.datalab.sequenceDetection.Main$.main(Main.scala:11)
auth.datalab.sequenceDetection.Main.main(Main.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)

The currently active SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
auth.datalab.sequenceDetection.CassandraConnectionTrait$class.startSpark(CassandraConnectionTrait.scala:58)
auth.datalab.sequenceDetection.SetContainment.CassandraSetContainment.startSpark(CassandraSetContainment.scala:11)
auth.datalab.sequenceDetection.SetContainment.SetContainment$.main(SetContainment.scala:25)
auth.datalab.sequenceDetection.Main$.main(Main.scala:11)
auth.datalab.sequenceDetection.Main.main(Main.scala)
sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
java.lang.reflect.Method.invoke(Method.java:498)
org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
         
	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:100)
	at org.apache.spark.sql.SparkSession.<init>(SparkSession.scala:91)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:957)
	at auth.datalab.sequenceDetection.CassandraConnectionTrait$class.closeSpark(CassandraConnectionTrait.scala:79)
	at auth.datalab.sequenceDetection.SetContainment.CassandraSetContainment.closeSpark(CassandraSetContainment.scala:11)
	at auth.datalab.sequenceDetection.SetContainment.SetContainment$.main(SetContainment.scala:53)
	at auth.datalab.sequenceDetection.Main$.main(Main.scala:11)
	at auth.datalab.sequenceDetection.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52)
	at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:845)
	at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:161)
	at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:184)
	at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)
	at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:920)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:929)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
log_10000_113.xes setcontainment
21/09/02 10:53:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/09/02 10:54:05 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 10:54:05 INFO NettyUtil: Found Netty's native epoll transport in the classpath, using it
21/09/02 10:54:06 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 10:54:06 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 10:54:14 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 10:54:14 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 10:54:14 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 10:54:15 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 10:54:21 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 10:54:50 INFO ClockFactory: Using native clock to generate timestamps.
21/09/02 10:54:50 INFO Cluster: New Cassandra host rabbit.csd.auth.gr/155.207.131.28:9042 added
21/09/02 10:54:50 INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
21/09/02 10:54:52 INFO TableWriter: Wrote 325 rows to sequencedetection.log_10000_113_set_idx in 1.868 s.
21/09/02 10:54:52 INFO TableWriter: Wrote 314 rows to sequencedetection.log_10000_113_set_idx in 0.627 s.
21/09/02 10:54:53 INFO TableWriter: Wrote 296 rows to sequencedetection.log_10000_113_set_idx in 0.508 s.
21/09/02 10:54:53 INFO TableWriter: Wrote 327 rows to sequencedetection.log_10000_113_set_idx in 0.726 s.
21/09/02 10:54:54 INFO TableWriter: Wrote 311 rows to sequencedetection.log_10000_113_set_idx in 1.002 s.
21/09/02 10:54:54 INFO TableWriter: Wrote 334 rows to sequencedetection.log_10000_113_set_idx in 1.022 s.
21/09/02 10:54:54 INFO TableWriter: Wrote 360 rows to sequencedetection.log_10000_113_set_idx in 1.032 s.
21/09/02 10:54:54 INFO TableWriter: Wrote 297 rows to sequencedetection.log_10000_113_set_idx in 0.263 s.
21/09/02 10:54:55 INFO TableWriter: Wrote 302 rows to sequencedetection.log_10000_113_set_idx in 0.431 s.
21/09/02 10:54:55 INFO TableWriter: Wrote 328 rows to sequencedetection.log_10000_113_set_idx in 0.289 s.
21/09/02 10:54:56 INFO TableWriter: Wrote 349 rows to sequencedetection.log_10000_113_set_idx in 0.879 s.
21/09/02 10:54:56 INFO TableWriter: Wrote 321 rows to sequencedetection.log_10000_113_set_idx in 0.931 s.
21/09/02 10:54:56 INFO TableWriter: Wrote 337 rows to sequencedetection.log_10000_113_set_idx in 0.933 s.
21/09/02 10:54:56 INFO TableWriter: Wrote 321 rows to sequencedetection.log_10000_113_set_idx in 0.940 s.
21/09/02 10:54:56 INFO TableWriter: Wrote 344 rows to sequencedetection.log_10000_113_set_idx in 0.824 s.
21/09/02 10:54:56 INFO TableWriter: Wrote 353 rows to sequencedetection.log_10000_113_set_idx in 0.539 s.
21/09/02 10:54:57 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.746 s.
21/09/02 10:54:57 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.749 s.
21/09/02 10:54:57 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.751 s.
21/09/02 10:54:57 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.760 s.
21/09/02 10:54:57 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.764 s.
21/09/02 10:54:57 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.767 s.
21/09/02 10:54:57 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.769 s.
21/09/02 10:54:57 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.770 s.
21/09/02 10:54:57 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.778 s.
21/09/02 10:54:57 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.777 s.
21/09/02 10:54:57 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.771 s.
21/09/02 10:54:58 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.780 s.
21/09/02 10:54:58 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.782 s.
21/09/02 10:54:58 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.782 s.
21/09/02 10:54:58 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.786 s.
21/09/02 10:54:58 INFO TableWriter: Wrote 625 rows to sequencedetection.log_10000_113_set_seq in 0.778 s.
21/09/02 10:55:05 INFO CassandraConnector: Disconnected from Cassandra cluster: Test Cluster
21/09/02 10:55:06 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
